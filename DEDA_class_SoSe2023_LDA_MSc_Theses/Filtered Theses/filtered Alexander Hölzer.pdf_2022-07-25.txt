supervise machine learn sentiment measure master thesis submit prof dr wolfgang karl hardle prof dr brenda lopez cabrera universitat zu school business economics institute statistic econometrics alexander lzer partial fulfillment requirement degree master science economics management science july would like express sincere gratitude prof hardle inspire pursue future career statistic give opportunity write master thesis international research training group also especially want thank dr rui ren bruno spilak extremely valuable advice expert field special thanks also go ivan kotik introduce outstanding research group irtg contribution thesis twofold first thesis examines ability dictionary base method supervise machine learn method estimate capture sentiment regard company related nasdaq news article publication explanatory power sentiment measure abnormal return date news article publica tion compare via panel data regression like frankel abnormal return use label sentiment supervise machine learn method sentiment measure positive significant regression analysis however sen timent measure offer weak explanatory power respect abnormal return date news article publication moreover two three supervise machine learn ing method offer improvement explanatory power dictionary base method use thesis second random forest algorithm deep finance related contextual text representation input outperforms random forest application non contextual one two gram count use feature however explanatory power abnormal return date news article publication still weak code available quantlet com content iv list abbreviation list vi list introduction literature review data methodology dictionary base sentiment measure supervise machine learn sentiment measure text representation technique random forest algorithm finbert dropout dense layer result descriptive statistic regression result dictionary method discussion conclusion iil list abbreviation bert bidirectional encoder transformer cart classification regression tree ff fama french harv harvard lm loughran mcdonald lstm long short term memory ml machine learn mse mean square error nn neural network rf random forest rnn recurrent neural network slda supervise latent dirichlet allocation svr support vector regression iv list word cloud base frequency loughran mcdonald ww ek encoder part transformer base vaswani bert transformer layer base random forest pseudocode base guo finbert encoder dropout dense layer base dropout layer dropout probability base sultan dm base sentiment measure estimate via harvard dictionary lm dic tionary show first second display rf base sentiment measure gram count hidden vector cl token input smlsmeraphs sentiment measure base rf gram count hidden state cl token input also contains sample predic tions finbert neural network architecture tual abnormal clirus date news article publication smlsmeraphs top stock ticker reg ards news article frequency exclude non feasible symbol list lo index position correspond word train test data example descriptive statistic variable use regression base frankel smlsmdescriptive ee ee correlation matrix sentiment measure use regression base frankel smlsmdescriptive regression result dictionary base method smlsmregression regression result supervise machine learn method smlsmregression definition variable panel data regression base frankel coty occa nea poo ce oa ree de introduction important aspect desire collect information deal process gain sight people think pang lee individual also firm need automatically ass sentiment costumer check product perceive public increase interest lead sudden rise activity area opinion mining sentiment analysis pang lee advancement sentiment analysis also reflect financial domain researcher adopt technique natural language processing field like computer science linguistics artificial intelligence frankel first part paper extends research do frankel compare random forest algorithm dictionary base method task ass sentiment regard financial text document frankel map count one two word phrase disclosure two day cumulative abnormal return surround date disclosure via supervise machine learn method instead use report conference call text document thesis examines whether super vised machine learn method also outperform dictionary base method nasdaq news article use text document sentiment analysis task compare supervise machine learn method dictionary base method panel data regression use examine explanatory power sentiment measure abnormal return day news article publication addition paper expands approach frankel us gram also finbert encoder rep resent text document input supervise machine learn model moreover research examines finbert encoder along neural network form dropout dense layer performs respect sentiment analysis task sentiment analysis method provide positive significant sentiment estimate panel data regression analysis however display weak explanatory power abnormal return date news article publication except random forest algorithm finbert encoder text document machine learn method offer improvement dictionary base method thesis structure follow section contains prior literature field sentiment analysis part section present previous research examines performance comparison various sentiment assessment method section contains data processing step sample description section illustrates different method use paper capture ass sentiment methodology section start description panel data regression use gain insight regard explanatory power sentiment measure abnormal return date news article publication subsection subsection illustrate method estimate sentiment measure section reveals panel data regression result thereby identifies explanatory power sentiment measure abnormal return section contains discussion result limitation study guide line future researcher section present conclusion literature review recent year sentiment analysis within accounting finance start gain traction regard advancement method identify information disclosure text document frankel rise activity reflect finance also domain desire gain insight people think feel contribute rapid increase interest area sentiment analysis opinion min ing pang lee history sentiment analysis trace way back research content mainly base survey base method earlier day change year computer base system appear research field modern sentiment analysis start gain momentum mid mantyla upwards trend popularity research topic consequence newly obtain ability automatically collect analyze large corpus text data mantyla term sentiment analysis construe different way paper assign sentiment analysis specific application classify review either bad positive sen timent analysis nowadays interchangeably use term opinion mining deal computational treatment opinion sentiment conveyed within text docu ments pang lee research field sentiment analysis categorize different problem include document level sentiment analysis sentence level sentiment analysis aspect base sentiment analysis comparative sentiment analysis sentiment lexi con acquisition feldman document level sentiment analysis assumes document contains one opinion topic sentence level sentiment analysis assumes sin gle document multipplle opoy inion ccoonnttaaiinneed witwihthiin didfifffeerrenet nt sentence aspect base sentiment analysis deal fact entity many aspect people may different opinion aspect entity comparative analysis conveys sentiment form comparison entity sentiment lexicon acquisition deal mapping word specific sentiment feldman next paragraph contains brief complete overview research domain sentiment analysis deal comparison machine learn method method task ass capture sentiment focus literature review sentiment assessment respect financial text document one earlier paper modern sentiment analysis thump sentiment classification use machine learn technique pang lee vaithyanathan deal identification movie review sentiment analysis use human produce base line machine learn method latter undeniably outperforms former product review sentiment analysis one many application within opinion mining plenty application area nowadays part sentiment analysis task within wide range domain financial market one feldman paper disclosure sentiment machine learn dictionary method frankel deal ability capture disclosure sentiment filing conference call date demonstrate like pang lee vaithyanathan suitability ml method field sentiment analysis frankel follow loughran mcdonald regard capture disclosure sentiment loughran mcdonald show word dictionary method capture sentiment specifically developed discipline analyze text else word dictionary misclassify word financial document use harvard psychosociological dictionary stone compare word list developed word categorization financial context harvard dictionary advantage composition word dictionary control researcher choose use sentiment analysis loughran mcdonald however show loughran mcdonald harvard dic tionary effectively categorize word field finance showcase word tax appear frequently filing label negatively harvard dictionary although part business operation depicts frequent negatively label word within report base harvard dictionary negative word list structure loss ap ital claim sof wv impatrmene ose unable liability liabi exp ene ar againstad rse harvard word cloud lm word cloud word cloud base frequency loughran mcdonald noticeable word cloud share small intersection word dictionary categorize negative loss adverse majority word categorize lm negative word list found top frequent negative word base harvard dictionary self design word list loughran mcdonald lm dictionary beat harvard dictionary regard reflect tone related financial disclosure document loughran mcdonald focus paper compar ative power word list assess sentiment regard specific context ix filing also provide preliminary evidence negative word list lm dictionary high correlation harvard dictionary return sample contain news article text document lm dictionary together harvard dictionary primarily use context dictionary base method create sentiment measure financial document ever since frankel nevertheless lan guage related sentiment dictionary change time costly update furthermore allow variation word importance frankel accordingly frankel ct show paper lm dictionary consistently capture sentiment form filing return study period loughran mcdonald text sentiment analysis base dictionary meth od unsupervised classification technique xu therefore use absence label data another approach document level sentiment analysis supervise learn feldman supervise learn sentiment classification simplest case assumes two class positive negative feldman approach extend introduce class discrete numeric scale target variable feldman however show frankel also possible ass investor sentiment via return target variable frankel use supervise machine learn method map disclosure text document form one two gram count cumulative abnormal turn event window surround disclosure date compare machine learn method random forest rf regression tree support vector regression svr supervise latent dirichlet allocation slda dictionary base method comparison dictionary method supervise ml sentiment measure paper frankel display machine learn method powerful robust sentiment measure earnings announcement filing conference call dictionary base measure mention supervise machine learn measure rf algorithm identifies sentiment least measurement error suggest future researcher focus random forest algorithm sentiment analysis financial disclosure document caution result paper may generalizable measurement nondisclosure sentiment proxy sentiment construction earlier paper within field finance rely heavily dictionary base method exception apply simple machine learn technique hiew however advance field natural language processing rapid last year hiew recurrent neural network long short term memory gate recurrent neural network use state art approach sequence language model vaswani vaswani propose paper attention need transformer mechanism eschews recurrence use neural network focus multi head attention compu tations approach help alleviate fundamental problem sequential compute vaswani ct devlin extend approach use multiple layer contain encoder part transformer developed vaswani combine new bidirectional training mechanism create bert current state art approach natural language processing task devlin quite natural assume success bert natural language processing task reflect use sentiment analysis task however sentiment analysis task strongly domain dependent yang yang address need financial domain specific bert model call fnbert finbert developed pre training bert model architecture large financial corpus contain total billion token financial text document yang yang show pinbert yield substantial improvement bert financial sentiment analysis task next paragraph contains research study show bert finbert use field sentiment analysis within financial domain one research study employ bert field sentiment analysis fi nancial text document paper hiew hiew demonstrate effectiveness bert estimation sentiment index stock related inter net post study bert train manually label weibo internet post categorize either positive neutral negative label stock related internet post single stock give day aggregate represent daily sentiment particular stock sentiment index conjunction option market imply financial sentiment index represent general comprehensive framework financial sentiment analysis delivers overall best performance term mse use lstm predict stock return hiew another example successful application bert financial sentiment classification task paper bert stock market analysis sousa bert use capture sentiment news article sousa estimate sentiment day base news article publish opening time market show study persyi od tt ime eessttiimmaattee enti ment consi tent dow jones index variation respective trading day bert also bert financial counterpart finbert successfully use sentiment analysis task finance domain yang demonstrate paper finbert pretrained language model financial communication finbert bert base model developed training large financial corpus outperforms bert sentiment classification task use three different datasets include ftinnea nciari pphhrraacseerb nk mal etwie demonstrate high accuracy finbert comparison bert three datasets researcher field sentiment analysis also already use bert en coder represent text document input machine learn algorithm dogra use distiibert small faster version bert sanh encoder transform text article embeddings feed vector input chine learn model random forest decision tree logistic regression hey demonstrate machine learn model benefit deep contextual pre train language representation outperform model bag word text representation use input prior research examine suitability assess sentiment disclosure document via machine learn method compare dictionary base method frankel show machine learn sentiment measure robust pow erful dictionary base sentiment measure task ass disclosure sentiment however best author knowledge comparison analysis method abnormal return sentiment label do yet finance related news ar ticles thesis start fill gap examines whether supervise machine learn also outperform dictionary base method ability capture sentiment measure regard company related nasdaq news article publication furthermore paper add literature study performance supervise machine learn method gram also deep finance related contextual language representation finbert use input supervise machine learn model data text data set use analysis contains news article nasdaq news insight publish download blockchain search center addition data financial variable provide wharton research data service subscription crsp compustat fama french database subsequent part thesis contains data preparation process sample description described data set contains information need regard sentiment analysis task drop efficiency reason date news issue correspond stock ticker symbol news article text variable data set use sentiment analysis data filter process consists keep observation single text related stock ticker symbol result removal observation multiple related stock ticker symbol news article link stock ticker symbol subsequently date format adjust non numerical entry remove duplicate within data set remove well next step make use code frankel pre process text data include cleaning overall sentence isolated word process reduce noise overall sentence mainly consists change uppercase letter lowercase replace hyphen space remove punctuation except period code also replaces number oonumberoo stopwords underscore data pre processing procedure also consists stem word help porter stemmer algorithm algorithm remove suffix word word similar meaning connect connection end stem porter result reduction regard input dimensionality random forest algorithm application case dictionary base method finbert encoder neither stem remove stopwords apply text display reduction initial data set data filter process data filter step base loughran mcdonald data filter step sample size initial news article sample size exclude news article none multiple stock ticker crsp permno match exclude duplicate initial sample size reduce data point depicts data set regard news article count company count mean word count news article text time description initial news article sample year news article count average word count company count year overall mean word count news article text approximately news ar ticles year mapped different stock ticker symbol noticeable nasdaq news article process data set publish year include far least amount obser vations reduce sparseness sentiment measure variable panel data regression size data set regard company time frame restrict news article issue top company regard news fre quency year include final data set stock ticker list select company provide result reduction initial sample size news article important note observation contain news article news article publish outside weekday news article publish stock market holiday pm merge news article next trading day subsequent depicts final data set use panel data regression examine explanatory power sentiment measure regard abnormal return description final news article sample yoar news article merge average word count pe ay year na visible mean word count final news article sample year average long text document length rather large text document length result merge news article publish outside weekday holiday one company news article related company next trading day also explains rather large text document length year year high amount news article within data set last news article sample publish august time frame set panel data regression period april august final sample size consists unique day day therefore contains average news article different company methodology follow section describes method use paper capture sentiment regard nasdaq news article publication first step deal process estimate sentiment measure base dictionary base method supervise machine learn method next step explanatory power sentiment measure abnormal return date news article issue assess panel data regression similar paper loughran mcdonald paper frankel equation use examine sentiment measure explain abnormal return date news article publication ag sentimenti aglog sizeji bt mit aaturnover prealpha ag nasdaq cit equation depicts market adjust return company day date news article publication sentiment measure variable esti mat base dictionary supervise machine learn method discuss detailed description variable regard panel data regression provide account high frequency news article data oppose filing conference call daily time index use panel data regression news article issue outside weekday holiday outside opening hour stock market give company merge news article publication next trading day basis sentiment estimation follow trading day additionally multiple news article present give company particular day news article merge well every company data set news article regard business publish give day within sample period case sentiment measure company without related news article issue give day set sentiment value assume reflect neutral sentiment diverges frankel since sample consists textual document regular release frequency report file annually trading window follow news article issue base previous research field loughran mcdonald justify event window day base result griffin filing elevate response day filing date loughran mcdonald also state could longer information absorption time cause document length frankel choose instead day window two day event trading window average news article text document length nasdaq news article sample much shorter report reduce absorption time due shorter document length lead decision even decrease event window include day news article publication follow section describe estimation process sentiment measure use explain return panel data regression dictionary base sentiment measure thesis focus use supervise machine learn sentiment measure however dictionary base sentiment measure serve benchmark comparison supervise machine learn measure similar frankel paper cover two dictio naries one harvard dictionary stone one lm dictionary harvard lm dictionary access python package pysentiment derobertis prior literature mainly harvard lm dic tionary use dictionary base measure capture sentiment frankel application case dictionary base method net tone use sentiment measure panel data regression net tone base positive negative word count dictionary thesis examine explanatory power positive tone negative tone dictionary define paper frankel positive negative word count divide total amount word sentiment measure company without news give day set value reflect neutral sentiment positive negative tone variable however relates value low bound positivity negativity respective text document equation display net tone calculate base paper frankel net tone positive worrdd ccoouunntt nneeggaattii word count positive word counti negative word count phe net tone sentiment measure variable low bound upper bound cc news article many positively categorize word negative one receive neutral sentiment measure value companie without news article give day also assume neutral sentiment supervise machine learn sentiment measure paper frankel provide evidence supervise machine learn mea sures robust powerful dictionary base counterpart role sentiment disclosure conference call filing carning announcement press lease paper closely follow approach frankel test whether random forest machine learn method also outperforms dictionary method nasdaq news article use text document like frankel abnormal return use label sentiment machine learn algorithm define return event trading period minus crsp value weight market return period however instead use cumulative abnormal return within two day event trading window label sentiment event window reduce include day news article publication first study follow research frankel employ one two gram count input random forest algorithm next finbert apply encoder derive deep contextual language representation nasdaq news article use input random forest algo rithm last research expands set supervise machine learn method model architecture feature finbert encoder additional dropout dense layer subsequent paragraph start description technique use represent text document input supervise machine learn method section follow subsequent paragraph describe random forest algorithm berdnt base neural network model use ass sent ment text representation technique gram like frankel study us gram form one two gram represent training test data form sparse matrix gram define field linguistics sequence item give text speech devika follow paragraph explains approach base paper frankel represent text document one two gram count sparse matrix contain one two gram count serve input random forest algorithm training process training process random forest regression tree us slide window three month instead two four year nasdaq news article data high release frequency filing large amount news article within training data set would lead disproportional increase feature handle computational capacity hand news article within month screen unique one two gram unique one two gram assign index one two gram occurrence count every observation training data well observation month mg test data set every observation test data set therefore represent count occurrence unique one two gram found training data set within test data set example help explain text representation let assume two observation use one training data set one test data set training data gold price currently dollar test data apple stock price rise training test data set contains one simple sentence unique one two gram training data set gold price currently dollar gold price price currently currently dollar show assign index li index position correspond word train test data example index gram gold price currently dollar approach test text data set represent follow way news article lo entry except second one zero second entry vector depicts count word price within test data set word price assign dex final training test matrix contain every sample observation respective row matrix really sparse code frankel help compress sparse matrix memory efficient format non zero entry position save sparse matrix together vector contain dependent variable serve input rf machine learn model bert embeddings bert stand bidirectional encoder representation transformer developed google ai language department de vlin ct bert key improvement alleviation disadvantage cause uni directional training language model replace bidirectional training use masked language model pre training objective devlin study us finbert finance version bert pre train large scale financial conununication corpus yang encoder pass process hidden state cl token input supervise machine learn method moreover finbert version use analysis fine tune manually annotate sentence analyst report yang subsequent paragraph start explanation encoder part transformer vaswani follow description bert architecture bert architecture corresponds multi layer bidirectional transformer encoder de vlin transformer encoder base model architecture call attention mechanism vaswani base vaswani depicts one layer bert architecture add norm feed forward add norm positional encoding input embeddings encoder part transformer base vaswani visible input embeddings together positional encode get pass multi head attention mechanism encoder contains recurrence positional encode take care feed relative absolute position word model vaswani attention mechanism described set query key value pair output output depict weight sum value weight determine compatibility query key vaswani particular attention use transformer vaswani call scale dot product attention however instead single call attention fine tion multiple attention function call do parallel concatenate project yield final value vaswani equation depicts multi attention mech anism base vaswani detail multihead concat attention attentiong attentionsw attention attention qw kw vw qw attention qw kwk vwy softmax vwy ok attention function contains query key value matrix scale factor dy use prevent extremely small gradient case large value inside softmax function vaswani vaswani state found beneficial project query key value multiple differently learn linear projection concatenate project head reduce dimensionality divide dimension head total amount tention head lead total computation cost similar single head attention full dimensionality vaswani residual connection employ sublayer initial vector add output sublayer initial vector output multi head attention mechanism layer normal ized pass next sublayer vaswani show next sublayer consists feed forward network add normalization part residual connection feed forward network include two linear transformation relu activation function equation base paper vaswani display linear transfor mations relu activation function feedforwardn max cr ee bert pase contains layer transformer encoders depict include self attention head devlin devlin use two unsu pervised task pre train bert one masked language model pre training objective one next sentence prediction devlin bidirectionally condition model mask input token random predict masked token however misimatch fine tune pre training cause mask token appear fine tune devlin therefore always replace original token mask token masked replace random token replace pre training task deal prediction next sentence time pre training next sentence actual sentence rest time random sentence devlin devlin follow approach already exist literature language model pre training mainly train english wikipedia article bookscorpus zhu approximately million million word respectively devlin demonstrate importance bidirectional training comparison standard left right model show bert outperforms model various language task finbert finance version bert pre train fine tune financial text document yang return hidden vector cl token use input supervise machine learn sentiment method represent simplify illustration architecture use sentiment analysis task supervise ml method transformer block transformer block transformer block bert transformer layer base show first token every sequence special token call cl token final hidden state token contains aggregate representation whole input sequence devlin devlin state final hidden vector cl token use classification task also display sep token use separate non consecutive token sequence devlin sentiment analysis task hidden state cl token pass input supervise machine learn method next section describe supervise machine learn method use ass sentiment news article text document random forest algorithm random forest combination tree predictor tree predictor con structed via bootstrap sample training data random selection fea tures breiman tree within random forest grown use cart method ology breiman tree sample bootstrapped whole training data set additionally introduce randomness subset feature node select consider split breiman paper gram count final hidden vector cl token use input first case tree grown exhaustively search feature split node best regard impurity within sub set randomly select count one two gram grow pre determine number tree random forest regression tree predict sample observation via average tree like frankel sample prediction abnormal return date news article publication serve sentiment measure panel data regression subsequent paragraph contains detailed overview random forest algorithm implement random forest algorithm us two source randomness develop bag pre dictor one bootstrapping one random feature selection breiman process bootstrapping training data set get multiple predictor combine aggregate predictor also know bagging breiman case regression task final prediction random forest algorithm average prediction individual tree classification task class prediction base majority voting tree within random forest breiman tree random forest grown use cart methodology addition node subset feature randomly drawn breiman depicts pseudocode random forest algorithm base paper guo algorithm random forest algorithm toc draw bootstrap sample dj create root node contain yall buildtreenj end ageregate prediction estimator ee buildtree oo pure return else select pre determine amount randomly select feature split select feature high information gain split create child node every child node set content child node accord feature split criterion call buildtree la end end random forest pseudocode base guo eudoco de basej ccda gu clearly dia splay earlier mention two instance randomness development forest process bagging plemented first loop bootstrap sample drawn second instance randomness occurs pre determine amount feature select split ch node whil tr peae iies builit pseudo code also display early stop tree also prune function build tree continue create child node long node pure split base fe ature lead high information gain follow paragraph describes hyperparameter choice number tree within random forest set case frankel etal explanatory power random forest base sentiment measure tree diminish slightly compare set number regression tree due computational demand random forest paper contains tree breiman suggests tree prune first word count one two word phrase found training data use input random forest algorithm amount randomly select feature set square root total feature data subsequently process final hidden vector cl token obtain via finbert encoder serf input random forest algorithm hyperparameter tune amount randomly select feature set two third alall ffeaasttuirsense az dense real value vector finbert dropout dense layer aft er usi ng hi dden state cl token nputs random foreacstt aallgooo rithm study examin abilcieil ty capture sent ment wit fi nbe rt enco derv along additoi ie onal dropout dense layer sentie ment analysis task fisgc urear ea depaipicc simplify representation setup use sentiment analysis dropout dense finbert encoder dropout dense layer base refers hidden state cl token next show process hidden state cl token pass two additional layer first one dropout layer pre define percentage input unit randomly drop prevent overfitting srivastava next layer fully connect layer linear activation function receive dimensional output variable next paragraph explains setup detail displ ays choice hyperparameter neural network architecture one hyperparameters neural network need adjust batch size batch size display number sample use train single forward back ward pas neural network kandel castelli choice small large batch size advantage drawback sinall batch converge faster regularization effect due high variance large batch size may reach optimum minimum may reach small batch size chosen kandel castelli however small batch size require small learn rate overshoot minimum kandel castelli neural network also let define humber epoch additional hyperparameter amount time neural network go whole training data set brownlee brownlee explain epoch batch analogy loop loop proceeds overo whole trai ing data set within loop another nesnetsteedd ffoorr loop thaatt iitteerraattee batch sample batch contains sequence pre determine length sequence length determines amount text token serf input model long sequence expensive attention mechanism quadratic respect sequence length devlin another hyperparameter neural network learn tate learn rate also related gradient estimation process influence large step direction negative gradient zeiler le rmi rate chosen model hisgth objejec ct tiivvee fi unct tii aa diverge choose learn rate low result slow learn zeiler aft efe sever performance test batch size epoch learn rate le olbisa chosen input sequence length token long first layer finbert encoder architecture dropout layer dropout regularization method prevent overfitting neural network srivastava deep learn algorithm neural network powerful machine learn algo rithms large number parameter srivastava large neural network really slow make difficult combine prediction different neural network sri vastava dropout help solve problem overfitting randomly drop unit neural network training dropout probability additional hyperparameter choice depends type input use neural network srivastava large dropout probability may require large sample size turn prolongs th wpe ia ip training time may lead underfitting low dropout probability may help reduce problem overfitting srivastava show simple example dropout layer base paper sultan input hidden output input hidden output ol dropout layer dropout probability base sultan display case input unit along connection randomly drop due dropout mechanism output layer example connect neuron hidden layer dropout value study corresponds value mean input unit randomly drop enter dense layer dropout probability chosen hy perparameter tune due fact training data size rather small next laayy er dense laayeyr er witwithh aa lliinneeaarr aaccttiviavtaiotni ffuunnccttii thweo input di mensio desnyss laayy er corresp ondingg ttoo tthhee hihiddddeenn ssttaattee ofof cl token output di mensio dense layer abnormal return prediction model uring training weight model update aim minimize mean sq uu ara edr ed ee rr rr oo rr logsinc uncti whicoy ibin diae splayed equatio msey loss yi ohn optimizer optimizer backpropagates model mino ik mi ze mse loss functiets ad whicichh algori thm rst order gradi ent base optimiz atio stochast ob le ec ct ti iv vee functioono advantageous machine learn problem wit large data sreestpstsee high dimene igh dimensional parameter space kingma ba finbert model use study fine tune pre train yang dr opout dense layer stack top finbert model train thes ame fashi fog oot ett onthe fashion random forest algorithm slide window month result section start descriptive statistic variable use panel data regression subsequently result panel data regression show int descriptive statistic final data set panel data regression analysis consists observation merge news article former news article use first training slide window supervise machine learn method observation cover trading day company time period second quarter august observation news article basis sentiment analysis sentiment measure observation therefore set display descriptive statistic variable panel data egression analysis descriptive statistic variable use regression base frankel smlsmdescriptive mean std pad nasdaq turnover log size btm prealpha harv tone lm tone roo reid refin pinnn disz play splayyss thtahtat aalll bnormcaomlm ie return vari bles except sample predic te base fi period bet pinbert neural network architecture average positive time ab ige tn im expecte tde tatbalblee hows tthhaatt tthhee meameann thte vavrariiaabblle risarpazai variable supervise machine learn method similar algo hot meine learn sentiment measure base random forest application heeite ata thet median st rd quartile sentiment measure eh gi company without news article give day sentiment measure renitive reflect neutral sentiment average net tone harvard dictionary tion aver mean base harvard dictionary sentiment measure estima taht ae sentiment capture regard news article publication within atten however lm net tone sentiment measure average negative sentimeny meas therefore display average discrepancy perceive logarithmic associate news article publication variable log sitze display market value equity average value approximately mean dollar ver age market value quity sample corresponds value billion mean value book market ratio approximately show averace meat oe company sample period almost twice high market timapaisas compare book value equity variable prealpha adie intercept fama french factor model fama french eer seitin almost therefore average excess return tad fama french asset pricing model trading window dummy asdaq average approximately display far com panies wwlh ic seleetad uw ere select regard top frequency related nasdaq news article publicat ations aa rea trraaddee tihae nasd aq exchange ti news artic le publicf ao depicts correlation matrix sentiment measure use panel data regression analysis exclude zero value sentiment measure due miss news article observation correlation matrix sentiment measure use regression base frankel smlsmdescriptive harv tone lm tone rfi rffin finnn harv tone lm tone rf refin rt finnn visible net tone sentiment measure estimate via word count base categorization harvard lm dictionary positively correlate correlation coefficient value correlation coefficient sentiment measure expect positive correlation coefficient supervise machine learn sentiment measure respect dictionary base sentiment measure rather small result similar frankel state supervise machine learn method might identify different disclosure signal compare dictionary base method also case sentiment measure estimate via random forest regression tree surprising see supervise chine learn sentiment measure display positive correlation coefficient regard supervise machine learn sentiment measure subsequent paragraph give visual representation sentiment measure estimate via sentiment analysis method described section visual representation contains data company high frequency related news article publication apple inc follow three graph depict estimate sentiment measure apple inc year eee ih hm ih iy himm iv hl dl se rapa pt sada vol wan na nl dm base sentiment measure estimate via harvard dictionary lm dic tionary show first second display rf base sentiment measure gram count hidden vector cl token input smlsmgraphs eee bly ai hh ay hy ab au da hy th ww hk nemea vn wv ry ix ry sy ae se ae ag sentiment measure base rf gram count hidden state cl token input also contains sample prediction finbert neural network architecture actual abnormal ret urn date news article publication smlsmegraphs display estimate dm sentiment measure base apple inc related news article clearly visible average harvard dictionary sentiment estiinates high sentiment measure base estimation via lm dictio naryes thhee haarrveaa ryde disceet ionaarryy sesceasescnees esaenntti imenntt wit eaggaayrt news arti le publi sc ati positively lm dictionary time period positive correlation see dm sentiment measure also visible first graph ov explain overlap word list dictionary negative lm word list overlap respect almost half word harvard negative word arvar spc list loughran mcdonald overlap word automatically lead correla tion sentiment measure second graph see sentiment measure base random forest regression tree different text representation input gram word count use represent text document input rf algorithm study also obtains final hidden vector cl token finbert aggregate text representation input sequence also serf input random forest regression tree noticeable sentiment measure seem correlate also see random forest regression tree finbert encoder predicts general extreme abnormal return value show supervise machine learn sentiment measure include actual abnormal return target variable also noticeable finbert neural network architecture seem volatile sentiment measure seem suggest none supervise machine learn sentiment measure capture abnormal return date news article publication regression result subsequent section proviid panel data regressi rr ee uu tt th een nt ti ime mn aa nn aa yy dictionary method sey cantiment mea display panel data regression result dictionar base sentiment sures regression result dictionary base method smlsmregression dependent variable harv tone lm tone const log size bi turnover prealpha nasdaq observation adjust statistic df df note show aye base ene data regression result net tone sentiment measure tone sentime count categorize harvard dictionary illustrates net dictionary ie measure base word list lm dictionary expect comin measure positive highly significant mean article onbless tumates yield average high abnormal return date news cover soxits ton confidence interval dictionary base sentiment measure result ive range however adjust square really low regression dosti cee power sentiment measure control variable hana therefore really weak also see variable prealpha regard positive significant regression past excess return hows en ff model positively correlate abnormal return date ae lcle publication variable nasdaq also indicates company pie trade nasdaq exchange time news article publica ta ion average hi gher abnormal return firm trade xchano ot vvaarirei eerr ablesse aaa sigenei icantre panel data regressi analysis dv summarar caann sseeee tthhaatt lm dicae ionary well capture nasdaq news artic le publica ta ion return turn nd tahues lei sby uperinoers measu news artic le sent ment harvard dictionary supervise machine learn method displ ays panel data regressi result three supervi si ed machin lesaayrrmninngg sample sentiment measure display regression result rf grai prediction seutiment measure show regression result rf fi nbertny ae base sentiment measure result base sentiment measure estima te via finbert neural network architecture ession regression result supervise machine learn method smlsmregr dependent variable ee rt rfl rp repin rp pinnn const log size bm turnover prealpha oar nasdaq observation adjust statistic df df df nolte xpected sentiment measure base random forest algorithm positive highly significant mean high sentiment estimate yield average high abnormal teturns date news article publication confidence interval rf base sentiment measure cover positive range furthermore sentiment measure base finbert neural network architecture also positive significant sentiment measure seem capture nasdaq news article return therefore associate sentiment regard publication news text document however result show adjust square value regression really low explanatory power supervise machine learn sentiment measure abnormal teturns therefore weak prealpha nasdaq two variable positive highly significant surprisingly adjust square value sentiment measure base random forest one two gram count input well finbert neural network architecture slightly low adjust square value dictionary base method unlike frankel rf application one two gram count input powerful dictionary base sentiment measure however see improvement explanatory power deep finance related contextual language representation use input random forest algorithm adjust square value far high value regression however explanatory power adjust square value ig still weak random forest algorithm finbert encoder cutperforms sentiment analysis method capture sentiment regard ompany related nasdaq news article publication discussion sectinl see tai hat permafrofromrem ance various sentiment analysis rather close task ass sentiment respect nasdaq news article publication sentiment measure positive si gnifsei cant nbeh rtfi ijsa use anes enco der expla na ory power rf base noed entiment measure abnormal return date news ca rt ji cl publica tht ui incr ease compare non contextual text representation tech niques supervise machine learn sentiment measure base finbert neural network architecture rf application one two gram count powerfu compare dicort ionar basseoedd sseennttiimmeenntt meaassuurleess wheny naass daq neews eartic eel eese use text document general supervise machine learn sentiment measure display weak explanatory power panel data regression analysis follow para graph contain discussion possible reason cause weak explanatory power sentiment measure first abnormal return date news article publication use label sentiment supervise machine learnm method thvo advantage need manually label text document training purpose becomes longer necessary return use depict investor sentiment however frankel state weak market reaction text document filing may lead situation improvement measurement error sentiment measure yield large improvement explanatory power weak market reaction may lead difficulty capture sentiment regard news article issue weak market reaction news article may provide suf ficient signal capture supervise machine learn method weak market reaction respect news article publication also affect explanatory power dictionary base method however supervise machine learn application case noisy signal would addition lead difficulty mapping process text document abnormal return result suggest abnormal return use label sentiment market reaction sufficiently strong supervise machine learn model use estimate sentiment moreover ikk report conference call use frankel text document information majority market see release date abnormal return respect report conference call earnings nouncements direct reaction information reveal text document also case news article issue nasdaq news sample study might also report example past event unusual high low return last day stock follow text citation part news article publish thursday th march nasdaq news article data set wall street expect open positive territory via call future market three major index prove disappoint yesterday equity negative week state nasdaq news insight example help explain major difficulty mapping news article sentiment concurrent return date news article publication clearly visible sentiment news article part rather ambiguous however issue negative component news article part refers return market sentiment past day lead problem use sentiment respect news article publication explain abnormal return date publication information often time already available market article issue make difficult ass sentiment via return kx report conference call also cover past event information disclose publicly release date addition ability capture sentiment regard company related na daq news article might impaired idiosyncratic noise even though researcher sousa show successful implementation market sentiment index base news article text document might much noise individual company level another simple reason might explain weak explanatory power sent ment measure lack data news article use basis sentiment analysis however regression contains panel data observation lead sentiment measure pose issue study setup section also show rf base sentiment measure deep finance related con textual language representation input outperforms random forest algorithm one two graim count feature finbert neural network architecture performs bad respect explanatory power panel data regression analysis subsequent part discus possible explanation result unlike frankel random forest algorithm one two gram count input outperform dictionary base method result might due technique use represent text document input rf algorithm one two grain count word count unique one two gram found training data set mean also test text data represent word count unique one two gram found training data set report might pose problem inherent structure language text document likely rapidly change one year next however news article content use word might volatile language ix report training slide window three month might occur text data contains lot one two gram present last three mouth example christmas shopping season december use test data set text document contain holiday specific one two graims present text document last three month another possible reason contextual language representation finbert use encoder rf algorithm one two gram count contain context represent text document bag word fashion finbert encodes text document context text document contain similar one two gram count differ substantially content sentiment difference ability take account context news article might explain superiority rf finbert base sentiment analysis method contrary expectation finbert neural network architecture perform well rf finbert base method contrast rf base sentiment measure whole architecture backpropagates training process adjusts weight accordingly minimize mean square error loss function average amount text document slide window corresponds approximately news article lack data training process improper neural network architecture respect gression task hand might explain weak explanatory power panel data regression luc analysis hese difficult le ass ment nt mm nt til odscitve posit lve sig ullst fo upi er vise ec marcanhce hii ne le arning nt mm vw ce su vel el es supervise bi acl ne le ning el llne nt meaassuurreess dis play ssl unilila uw ly wc ak xplanato vy pow erc oo nh abnormal return date ooff tt newwss ratrictlei cle ii issssuuee whenwhen omparareed tto didicctti ionary base sentiment measure dd conclusion thesis examine feasibility capture sentiment regard company related nasdaq news article publication two way dictionary base method su pervised machine learn method use task capture sentiment detailed assessinent via descriptive statistic panel data regression result yield follow sight first unlike frankel supervise machine learn method base random forest application one two gram input outperform dictionary base method try capture sentiment related nasdaq news article issue weak explanatory power abnormal return unsupervised supervise method might attribute inherent nature information content con tained news article information often time already available market article issue make difficult ass sentiment via return furthermore weak inarket reaction news article issue also present complication abnormal return use label sentiment moreover even though prior researcher already successfully show usefulness estimate market sentiment index via news article might useful individual company due idiosyncratic noise second random forest algorithm deep finance related contextual language rep resentations input outperforms random forest application non contextual one two graim count lack performance regard rf ngram base model might come technique use represent text input model represent test data set word count unique one two gram phrase found train ing data set result problem sudden shift language training test data set however superior performance rf finbert model might also attribute benefit contextual language representation summary sentiment measure positive significant respect explain abnormal return date news article publication however performance sentiment analysis method rather close correspond sentiment measure offer weak explanatory power research need investigate improve capture sentiment regard news article publication company base level breiman bagging predictor machine learn breiman random forest machine learn brownlee difference batch epoch neural net work retrieve july http machinelearningmast edirfyfe rcenocme batch epoch derobertis pysentiment http pypi org project pysentiment devika sunitha ganesh sentiment analysis comparative study different approach procedia computer science devlin chang lee toutanova bert pre training deep bidi rectional transformer language understand arxiv preprint arxiv dogra singh verma jhanjhi talib analyze distilbert sentiment classification banking financial news intelligent compute innova tion data science pp springer fama french common risk factor return stock bond journal financial economics feldman technique application sentiment analysis communication acm frankel jennings lee disclosure sentiment machine learn dic tionary method management science griffin get information investor response form form edgar filing review accounting study guo nguyen vu bui forecasting mining capital cost open pit mining project base artificial neural network approach resource policy song xu yu role conceptualization commonsense knowledge graph construction arxiv preprint arxiv hiew huang mou li wu xu bert base fi nancial sentiment index istm base stock return predictability arxiv preprint arxiv kandel castelli effect batch size generalizability convolutional neural network histopathology dataset ct express kingma ba adam method stochastic optimization arxiv preprint arxiv loughran mcdonald liability liability textual analysis dictionary journal finance malo sinha korhonen wallenius takala good debt bad debt detect semantic orientation economic text journal association information science technology mantyla graziotin kuutila evolution sentiment analysis view research topic venue top cite paper arxiv preprint arxiv nasdaq news insight retrieve may http www nasdaq com news insight pang lee opinion mining sentiment analysis foundation trend information retrieval pang lee vaithyanathan thumb sentiment classification use machine learn technique arxiv preprint porter algorithm suffix strip program sanh debut chaumond wolf distilbert distil version bert small faster cheaper lighter arxiv preprint arxiv sousa sakiyama de souza rodrigues moraes fernandes matsubara bert stock market sentiment analysis ieee st international conference tool artificial intelligence ictai srivastava hinton krizhevsky sutskever salakhutdinov dropout simple way prevent neural network overfitting journal machine learn research stone general inquirer harvard iv dictionary update sultan salem atabany multi classification brain tumor image use deep neural network eee access vaswani shazeer parmar uszkoreit jones gomez kaiser polosukhin attention need arxiv preprint arxiv xu yu yao li meng wu chinese text sentiment analysis base extend sentiment dictionary ree access yang uy huang finbert pretrained language model financial communication arxiv preprint arxiv zciler adadelta adaptive learn rate method arxiv preprint arxiv zhu kiros zemel salakhutdinov urtasun torralba fidler align book movie towards story like visual explanation watch ing movie reading book proceeding ieee international conference computer vision variable definition return define sale asset day base tab purchase recent time previous valid price available minus crsp value weight market return period size number share outstanding multi ply price stock day publication date bim book market ratio calculate firm book value common equity end quarter year divide size turnover number share trade firm trading window relative news article publication divide firm share outstanding news article publication prealpha fama french intercept base regres sion three factor model fama french use trading day relative news article publication date nasdaq dummy variable equal security identi fier assign list security nasdaq stock market exists wise variable definition harv tone net tone measure base positive neg ative word count categorize harvard dictionary lm tone net tone measure base positive neg ative word count categorize lm dictio nary tab rf sample abnormal return predic tion random forest algorithm one two gram input tab refin sample abnormal return predic tion random forest algorithm finbert encoder tab nnfin sample abnormal return predic tion finbert neural network archi tecture pogyit definition variable panel data regression base frankel aapl amzn tsla fb ba nflx dis efx bac intc ge gm msft sbux air aal ibm jpm cmg wfc twtr wmt mcd amd nvda jnj baba cat mu csco xom cvx bp googl gpro cost hd nke ko axp tgt atvi cmcsa dal lmt abbv pfe gild adbe crm vz avgo bx lulu blk unh kmi bby pg agi amat mrk mm bidu qcom fdx amgn bmy orcl bhp kr mo gmbp pm chk mmm bbby cop irbt fcx hal tep og ual jwn cv ea stz glw adp azn ebay acn pep top stock ticker regard news article frequency exclude non feasible symbol declaration authorship alexander holzer hereby declare previously submit present work examination write work independently source include source internet reproduce either unaltered modify form particularly source text graph image acknowledge understand violation principle result proceeding regard deception attempt deception aer flob july
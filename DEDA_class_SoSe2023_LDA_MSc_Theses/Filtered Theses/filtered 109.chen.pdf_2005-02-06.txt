multivariate risikomanagement abschlussarbeit zur erlangung de akademischen grade master science sc im masterstudiengang statistik der fakult universit zu von ying chen geboren kaifeng volksrepublik china gutachter prof dr wolfgang ardle prof dr vladimir spokoiny eingereicht th february multivariate risk management master thesis present ying chen prof dr wolfgang ardle case center apply statistic economics universit zu partial fulfillment requirement degree master science th february declaration authorship hereby confirm author master thesis independently without use others indicate resource passage literally general matter take publication resource marked ying chen th february thesis propose risk management methodology high dimensional financial portfolio instead estimate joint density portfolio high dimensional space ica todecompose dependent risk factor linear transformation independent component ic marginal density volatility process ic estimate univariate dimension thereafter joint density dependence structure ic hyperbolic gh distribution family since family posse semi heavy tail mimic adaptive methodology estimate local volatility ic base homogeneity test order check reliability propose methodology consider portfolio study dimensional exchange rate dem usd gbp usd different trading strategy empirical study show performance var forecast use propose methodology well popular delta gamma normal model calculation simulation able recalculate software xplore keywords adap tive volatility value risk special thanks professor dr wolfgang ardle prof dr vladimir spokoiny encouragement suggestion study notation norm vector generalize hyperbolic distribution parameter covariance portfolio volatility portfolio stochastic error term proportion nongaussianity explain chosen independent component expect value random variable identity matrix rd dimensional real number space gaussian distribution transpose vector matrix var probability level weight vector portfolio cum th order cumulant random variable probability density random variable entropy random variable negentropy random variable kurt kurtosis random variable profit loss portfolio genuine independent time series time series observe market independent component content introduction independent component analysis definition property ica definition ica algorithm evaluation negentropy approximation fastica algorithm negentropy approximation fastica algorithm base negentropy dimension reduction generalize hyperbolic distribution univariate gh distribution generate gh random variable adaptive volatility adaptive volatility empirical study exchange rate dem usd dem jpd conclusion list simulated independent component sin uniform variable gh vari able dependent vector linear transformation middle independent component estimate apply jade algorithm bot tom graphical comparison density estimation one independent compo dem usd gbp usd observation dot line kernel density estimate normal fit show left panel whereas hyperbolic fit right comparison true negentropy solid approximation red dash blue dot simulated gaussian mixture variable pn graphical comparison density left log density right dailydem observation density dot usdandgbp usd fx rate observation left hyp nig fitting respectively first ic bottom fitting second ic graphical comparison nig distribution line standard normal dis tribution dash laplace distribution dot cauchy distribution dot fx return dem usd gbp usd ic fx return black ofthe return ofthe exchange rate product blue hyp marginal density two ic red surface gaussian fitting covariance return exchange rate acf plot devolatilized ic base dem usd gbp usd rate adaptive volatility time series ic fx return var time plot exchange rate portfolio weight risk level respectively top var time plot exchange rate portfolio weight var time plot exchange rate portfolio weight var time plot exchange rate portfolio weight list descriptive statistic return dem usd gbp usd two ic backtesting var forecast exchange portfolio introduction breakdown fix exchange rate system bretton wood agreement sudden increase volatility observe financial market follow ing boom financial derivative accelerate turbulence market besides incoming scale loss astonish world push development sound risk management system one challenge task risk management measure manage risk properly financial risk many source typically mapped stochas tic framework various kind risk measure value risk var expect shortfall low partial moment calculate among var become standard measure market risk since morgan launch riskmetrics mak ing analysis var simple jorion var briefly say cutoff loss target horizon happen time mathematically var probability level define var inverse function cumulative distribution function cdf profit loss time franke ardle hafner var drawback sub additive risk aggregate portfolio always small sum risk individual component result inconsistent diversification also wrong risk measure allocate capital change measure capital adequacy nevertheless var still consider industrial standard risk measure widely use risk management since viewpoint shareholder andmanagement taleb importance var even reinforce use central bank govern supervise capital adequacy bank group ten country therefore thesis mainly study problem open var calculation give high dimensional portfolio note methodology propose applicable risk measure well heteroscedastic model apply risk management illustrate stochastic property return portfolio denotes return portfolio time point rd return individual financial instrument weight vector portfolio covariance portfolio rd independent identical distribute stochastic error term term generally give advance covariance stochastic term need estimate clear covariance estimation distribution assumption stochastic process great importance success var calculation low dimensional space one use non semiparametric method estimate joint density covariance becomes immediately infeasible consider high dimensional portfolio due curse dimensionality problem hand portfolio hold financial institution often consist hundred even thousand financial instrument propose easy way solve high dimensional problem univariate space two estimation var calculation joint density covariance estimation do fast easily introduce idea convenient review three model widely use calculate portfolio var current historical simulation model applies current weight portfolio historical return construct hypothetical portfolio process model actually reduces dimension portfolio hence avoids high dimensional estimation success model however require large amount historical data new hypothetical series need construct weight portfolio change sense weaken information loss risk contribution individual instrument repetition density volatility estimation monte carlo mc simulation model delta gamma normal model contrary deal multivariate data former simulates stochastic process vari ables interest estimate joint density covariance base simulated series model give precise var calculation computational time expensive delta gamma normal model speed calculation assume involve risk factor normally distribute argue central limit theorem clt support normality assumption theoretically cumulative distri however risk factor dependent feature violates least independent condition oftheclt portfolio distribution normal one especially tail empirically normal model loss accuracy underestimate risk level explore different train thought calculate var high dimensional portfolio use desirable property independence apply independent component analysis ica portfolio statistical concept independence define term probability density definition independence random variable independent yi denotes joint density marginal density yi independent variable lot desirable property joint density give definition product marginal density marginal density independent variable estimate use statistical method nonpara metric kernel density estimation covariance independent variable diagonal matrix diag dependent vector portfolio independent vector formulate wx give value dimensional matrix assume nonsingular matrix inverse matrix joint density dependent vector accord jacobian transformation ardle simar ab wx covariance dependent vector linear transformation diagonal matrix ica idea illustrate simple example independently simulate one sinus function sin one uniform random variable one gen eralized hyperbolic random variable observation time series independent vector displayed top row give time invariant matrix obtain dependent vector product matrix independent vector time series show middle row plot imagine return portfolio observe market dependent display similar patten general fact con troll hidden independent factor use ica algorithm propose cardoso souloumiac joint approximate diagonalization eigenmatrices jade timate mix matrix ic time series estimate ic give bottom example provide evidence ic found use ica exist dependent vector explain linear transformation financial market movement financial return often ignite common economic factor interest rate therefore ica economic realistic condition ic obtain calculate high dimensional var uni variate space remember still two task line distribution assumption volatility estimation ic sin ic uniform variable ic gh variable yyy yyy yyy fig simulated independent component sin uniform variable gh variable middle estimate apply jade algorithm bottom icasim xpl risk management tail density vital importance empirical stud show financial risk factor leptokurtic distribution include high peak fat tail normality obviously suitable assumption case nonparametrically estimate density stock return example obviously deviate normal density although nonparametric density timation give accurate fit average poor performance tail tion come fact quantile inverse density without form difficult compute contrary parametric estimation give density form explicitly therefore preferable capture heavy tail property forexample conditional gaussian distribution use jaschke jiang able mimic fat tail well moderate var confidence level however underestimate risk extreme event confidence level recent hyperbolic distribution attract attention researcher eberlein kallsen kristen chen ardle jeong calculate var dif ferent confidence level assume risk factor follow generalize hyperbolic gh distribution study gh density give accurate var value normal one without doubt heavy tail distribution use mimic empirical density example laplace distribution cauchy distribution distribution compare gh distribution desir able tail behavior help estimate volatility ic adaptively thus assume study ic belong gh distribution family consider daily foreign exchange fx rate dem usd gbp usd compare nonparametric density normal density hyperbolic hyp density estimation first ic fx portfolio show hyp fit almost coincides nonparametric density last least estimate covariance risk management variable independent covariance diagonal matrix thus estimate element diagonal line volatility ic separately development volatility estimation summarize briefly say volatility firstly assume constant black scholes model introduce however reject smile imply volatility volatility cluster displayed market thereafter volatility regard time dependent firstly one use time invariant function estimate volatility arch engle garch bollerslev stochastic volatility model harvey ruiz shephard model inherentweakness empirical density normal fitting empirical density hyp fitting fig graphical comparison density estimation one independent component basis foreign exchange portfolio dem usd gbp usd observation dot line kernel density estimate normal fit show left panel whereas hyperbolic fit right icafx xpl ant high possibility volatility order avoid potential miss specification problem plausible use flexible tool provide data driven local model use mercurio spokoiny introduce model estimate volatility adaptively algorithm assumes volatility constant short time interval although volatile long run theory propose local constant model however base normality assumption risk factor chen extend algorithm inthisthesis volatility summary master thesis motivate three research clue implementicatoahigh basedontheics gh distribution parameter series var portfolio return different level estimate monte carlo simulation chapter give overview ica property ica various algorithm discuss among two algorithm intensively compare example jade algorithm use example popular introduce computationally fast low dimensional data contrary fastica fast high dimensional study chapter describes property univariate gh distribution subclass hyperbolic hyp distribution normal inverse gaussian nig distribution two subclass suitable explain empirical marginal distribution financial ic gh distribution parameter estimate use maximum likelihood ml numerical optimization method furthermore tail behavior several heavy tail distribution compare one see gh distribution lighter tail others desirable property help estimate volatility adaptively chapter give detail adaptive volatility estimation base gh distribu tion time homogeneous test derive specify short homogeneous interval volatility almost constant local constant volatility estimate average value square return interval validation propose var methodology discuss chapter base one portfolio family dimensional exchange rate dem usd gbp usd different trading strategy use indicate link xplore quantlet server code data use study available http ise wiwi hu de ychen ica independent component analysis ica startedfromtheearly whenthis method first use acoustic study deconvolution signal well know exampleisthe inanoisyparty voice different people several mixed acoustic wave record voice naturally consider independent source promote success acoustic ica apply different area brain image study duann jung kuo yeh makeig hsieh sejnowski telecommunication study ristaniemi raju karhunen implementation ica financial time series comparably late early ica study finance know trace back back weigend consider daily return large japanese stock compare explanation ability overall stock price use independent component ic principal component pc respectively found ic give precise approximation pc however study ica risk management inspire outstanding achievement ica intend apply method risk management financial portfolio complete deep introduction ica refer hyv arinen karhunen oja financial related field important estimate joint distribution financial instrument appropriately since trader manager make decision base distribution portfolio lot contribution univariate density estimation one example choose heavy tail distribution mimic leptokurtic feature financial time series generally estimate density nonparametrically however becomes complicate one considers high dimensional portfolio many estimation method although successful univariate case dimensional space may result inborn feature estimation method example nonparametric kernel density estimation poor performance due curse dimensionality problem therefore two solution suggest dimension reduction normality assumption basic concept multivariate statistical analysis refer ardle simar give dimensional data large intuitive think reduce dimensionality use statistical method pca widely use choose first pc base explanation degree covariance case estimate statistical property joint density high dimensional data low dimensional space however several problem apply pca risk management risk measure concern tail joint density normally measure th moment kurtosis dimension reduction base covariance may lose important information tail secondly value still large curse dimensionality problem appear thus assumption propose dimension reduction method apply normalityofthedata clt independent identical distribute random variable converges gaussian distribution briefly say investor hold enough financial instrument portfolio ifthehigh dimensional portfolio approximately normally distribute first two moment mean covariance control joint distribution completely moreover decomposition since decompose uncorrelated normal variable independent joint density data product marginal normal density covariance diagonal matrix unfortunately normality assumption unrealistic since financial instrument highly correlate leptokurtic distribute therefore risk management model base normality assumption often underestimate risk level essence normality assumption use statistical property independence encourages apply ica pith ica find ic base observe vector ic formu lated linear function give independent portfolio assume wx nonsingular matrix firstly esti separatelyfori since independent obtain joint density product marginal density yi density obtain accord jacobian transformation yi ab wx covariance portfolio describes dependence structure port folio diagonal matrix volatility diagonal element yi covariance linear transformation diagonal matrix diag briefly say element portfolio independent high dimensional esti mations simply calculate univariate estimation basic ica assumes linear function perfectly fulfil ic dimension observe vector assumption sound optimistic order avoid possible miss specification basic ica general ica model introduce reduce ica noisy ica former involves dimension reduction ic rm model useful one knowledge ic dimension inadvance veryoften pcaisused reduce ica model specify dimension base covariance portfolio study firstly hard know dimension hidden ic secondly dangerous reduce dimension use pca risk management explain criterion pc choice depends explanation covariance matrix however risk measure value risk var quantile tail measure th moment therefore instead reduce dimension preprocess choose ic accord explanation tail afterwards another general model name noisy ica formulate wx assume noise independent ic normally distribute nongaussianity requirement discuss follow section however covariance estimation normal error make model complicate normally covariance hyv arinen basic ica computationally fast reliable thus study apply basic ica definition property section define ica model discus property basic ica assumes ic linear transformation dependent observation due ambiguity ica discuss second denote genuine independent source ic explain linear transformation notation refer ic different order sign furthermore found ica infeasible high dimensional normal variable theoretical background several ica algorithm discuss among fastica computationally efficient especially high dimensional space intensively discuss next section ica definition statistically independent word joint density must equal product marginal density element see definition dd equivalently assume nonsingular matrix alternatively formulate ica dd equivalently wx independent vector inverse distinguish due follow ambiguity ica firstly variance define uniquely since estimate two term one vector example scale increase one get mj mj term obviously new ic vector covariance hence ica different real independent source scale order avoid ambiguity convenient specify covariance independent source identity matrix decomposition observe vector apply ica influence estimation result since eigenvector eigenvalue matrix time invariant call prewhitening process prewhitening matrix becomes orthogonal matrix aa denotes identity matrix inverse matrix remind negative therefore sign ic still uniquely determine use prewhitening nevertheless financial time series less symmetric sign risk trivial effect secondly order ic ambiguous give permutation matrix obtain ap clear consists original ic different order study order ambiguity obscure furthermore ica infeasible gaussian random variable let standardize independent dimensional gaussian distribute vector joint density exp exp norm vector give matrix equation base jacobian transformation get exp deta exp matrix estimate ica disappears joint density implies ica change distribution normal vector effect explain property gaussian variable uncorrelated independent well therefore prewhitening enough find ic dependent gaussian vector risk management study data financial time series follow heavy tail distribution therefore drawback basic ica negligible ica algorithm evaluation thereare mainideastofindics give overview ica development maximization nongaussianity find ic maximally nongaussian assumption distribution ic hyv arinen oja propose fast gradient algorithm base idea applicable high dimensional space joint approximate decomposition th order cumulant tensor find matrixw cardoso souloumiac propose efficient algorithm space dimension low algorithm poor performance high dimensional space maximum likelihood estimation find ic maximizes product marginal density attractive density ic give otherwise sumption require advance minimization mutual information natural connection maximization nongaussianity since idea base information factor entropy fore eliminate discussion maximization nongaussianity base clt find ic maximize nongaussianity wx clt say sum independent variable normally distribute individual one equation equation write wx let wa denote element th row th column equation express accord clt gaussian single ic best estimate obtain one equal left implies best estimate compare alternative less gaussian hence one estimate thordercumulant negentropy definition kurtosis excess kurtosis kurt ekurt objective function ica base kurtosis max kurt kurt wx optimization problem solve use gradient method kurt wx definition th order cumulant assume real value continuous random vector zero mean first order cumulants cum yi cum yi yj cum yi yj cum yi yj use empirical value estimate kurtosis th order cumu lant two measure however sensitive outlier thus robust measure negentropy use well definition negentropy gauss logf entropy random variable term gaussian variable gauss covariance variable therefore discus property entropy give continuous random vector joint probability density function pdf differential entropy define logf entropy desirable property example give constant value matrix follow equation hold log detb vector rd independent information theory entropy use measure disorder one variable disorder say random variable large entropy prove cover andthomas negentropy scale invariant give hh since log det log gauss negentropy new variable gauss log det log detm log log detm log det log gauss give objective function term negentropy max wx one use gradient method estimate theoretically nongaussianity measure require knowledge pdf make estimation computationally burdensome recent hyv arinen propose reliable approximation negentropy without timating density function hyv arinen oja introduce fast gradient algorithm name fastica extensively shortens computational time moreover fa tica algorithm fast high dimensional space go detail next section joint approximate decomposition cumulant tensor discuss th order cumulant cum consider mea itisafour dimensional highly developed contribution cardoso souloumiac prove linear transformation th order cumulant include unit matrix inherit whole information original cumulant matrix decompose jointly common eigenmatrix eigenmatrix actually estimate equation joint approximate decomposition eigenmatrices jade algorithm simple even faster fastica one considers large dimensional data recall decomposition analogous common principal component cpc analysis see flury cpc jade suffers inability decomposition high dimensional space therefore unreliable data dimension large let prewhitened observe vector ica definition since prewhitened vector orthogonal matrix linear transformation th order cumulant define cum kl matrix th row th column otherwise kl pair matrix remember cumulant additive property cumulant sum independent variable equal sum cumulants give independent vector get nonzero th order cumulant index independent variable unique straightforwardly obtain cum kl cum io jp kq lr kl kurt iv jv kv lv kl kurt iv jv kv lv kl kurt iv jv kurt iv jv equivalently formulate equation matrix notation isadiagonalmatrix inpractice instead group decompose jointly maximum likelihood estimation maximum likelihood ml estimation fundamental method widely use statistic let denote joint density ic ica model wx easy show joint density formulate detw detw detw marginal density likelihood function observation write detw log likelihood algebraically simple xx logf log detw marginal density ic know advance knowledge distribution family marginal density give ml estimation good choice use gradient method find estimate turn independent vector knowledge however always available financial study reason semiparametric nonparametric density estimation method use specify unknown density however computationally expensive dimension independent vector high sometimes assume distribution family financial time series however still computationally slow distribution parameter need estimate simultaneously instead prefer two step procedure estimate firstly ic without consider distribution assumption parameter afterwards minimization mutual information mutual information useful tool measure independence information theory definition mutual information mutual information among random variable define denotes entropy definition term entropy give useful interpretation distance recall distance joint distribution product marginal distribution measure independence distance measure mutual information analogous remember wx mutual information formulate wx log detw since expect independent mutual information must close therefore minimize mutual information directs way find ic objective function min pd log detw exactly equal therefore information negentropy approximation fastica algorithm method especially give high dimensional data section discus detail algorithm negentropy approximation definition negentroy see pdfs ic require calculation gauss logf furthermore integral need large amount computational time therefore approx imations negentropy preferable classic approximation negentropy use high oder cumulants comon give approximation negentropy base polynomial expansion gram charlier edgeworth show ekurt recall prewhitened variable approximation simple need estimate high order moment kurtosis recall kurtosis sensitive outlier well approximation propose hyv arinen compare polynomial approximation new one simple accurate assume information random variable density dx nonquadratic function number different function equation find infinity estimate fulfil equation inotherwords theentropyofy isnotwell asdiscussed entropy reach limit large value variable gaussian distribute mean variance reason maximum entropy method use get one determine estimate cover thomas prove density maximum entropy form hexp constant determine regular condition zero mean unit variance assumption far standardize gaussian due ground maximum entropy method obtain pdf standardize gaussian equation obtain approximation differential entropy xn logf dy gauss normally two function use assume odd even negentropy approximation formulate gauss positive constant accordance different function example one approximation choose ga yexp ga exp ka use another approximation gb yexp gb kb compare true negentropy simulated mixture variable pn denotes gaussian variable mean andavarianceofv close true negentropy straight line study use approximation measure nongaussianity negentropy comparison fig comparison true negentropy solid approximation red dash blue dot simulated gaussian mixture variable pn icanegentropyapp xpl fastica algorithm base negentropy give negentropy approximation maximization nongaussianity optimiza tion problem general gradient method find ic low speed hyv arinen oja propose fast gradient method objective function ica base negentropy approximation nongaus sianity measure write maxj gauss wx wx remember prewhitened hence respective gaussian variable stan dardized term first term odd function vanish symmetrically distribute realistic financial study time series close symmetry assumption induces extreme simplification gradient method therefore easy negentropy approximation formulate gauss wx even function denote application new negentropy approximation give also good result even case symmetry hold hyv arinen propose two choice function prove useful approximation logcoshay tanh ay tanh ay denote first derivative respect second derivative often consider approximation exp yexp exp accord classic gradient method get wx xg wx computational simplification one give initial value first term wx theadaptive estimate first term obtain wx note main information give sign term example tanh function supergaussian ic moreover gradient method speed include constraint gradient formulate xg wx solve equation newton method get iteration xg wx wx hence xg wx wx practice two way estimate first one account vector one one keep estimate uncorrelated second considers vector simultaneously orthogonalize estimate together fastica algorithm set number ic set choose initial vector unit norm letw whereg thesecond derivative othogonalization decorrelated othogonalization converge go back set go back step fastica algorithm symmetric orthogonalization set number ic set choose initial vector unit norm xg symmetric othogonalization ww converge go back dimension reduction discuss choose important ic neglect others suggest measure reduce dimension original data briefly say consider ic consequently time invariant matrix reduce matrix impel idea pca measure well first pc order variance explain variation give relative proportion pm var pc pd var pc analogously use proportion measure well first ic explain tail joint distribution recall covariance ic identity matrix prewhitening since use negentropy measure tail relative proportion formulate pm pd denote ic sequence order negentropies generalize hyperbolic distribution chapter introduce fast gradient method find independent component ic give observe variable joint density product marginal density ic joint density original dependent variable obtain base jacobian transformation sense problem estimate joint density transform estimate marginal density univariate space chapter purpose find good fit marginal density ic financial market simply assume ic follow one distribution family estimate unknown distribution parameter respect one literature reason stochastic numerical simplicity often assume involve risk factor normally distribute do riskmetrics framework however empirical study show financial risk factor leptokur tic distribution include high peak fat tail display empirical distribution base daily standardize devolatilized return foreign exchange fx rate dem usd provide strong evidence empirical density deviate normality assumption heavy tail feature amplify compare log density kernel estimation normal fit although nonparametric density estimation give accurate fit average anotherdrawback nonparametric estimation come fact quantile inverse density without form difficult compute contrary parametric estimation give density form explicitly therefore preferable capture heavy tail property keen competition among various heavy tail distribution fami lie example conditional gaussian distribution able mimic fat tail well moderate var confidence level nevertheless result unsatisfactory extreme event profit loss confidence level jaschke jiang recent hyperbolic distribution attract attention researcher eberlein apply generalize hyperbolic gh distribution var calculation chen calculate var dem usd rate extreme level base two density assumption hyperbolic hyp normal inverse gaussian nig distribution two subclass gh distribution backtestings two empirical study show model gh distribution give accurate var value normal distribution estimate density nonparametric estimate log density nonparametric fig graphical comparison density left log density right daily dem observation kernel density estimate graph line normal density dot source chen fx ratesdem usdandgbp usdfrom compare nonparametric density normal density hyperbolic hyp density estimation first second ic fx portfolio show hyp fit almost coincides nonparametric density recent copula areusedtofitthehigh embrechts mcneilandstraumann amongthem distribution compare gh distribution distribution one parameter degree freedom however fitting distribution often observe example distribution degree freedom display heavy tail marginal density first ic reason prefer gh distribution distribution however flexible choose suitable marginal distribution ic base give data univariate gh distribution gh distribution introduce barndorff nielsen heavy tail distribution well replicate empirical distribution financial risk factor density empirical density hyp fitting empirical density nig fitting empirical density fitting yy empirical density hyp fitting empirical density nig fitting empirical density fitting fig usdandgbp usdfxrates observation left hyp nig fitting respectively first ic bottom fitting second ic icafx xpl gh variable ir gh np condition ir gh parameter location scale density mainly control respectively var whereas formoredetails parameter domain refer bibby rensen modify bessel function third kind index barndorff nielsen bl sild exp dy furthermore gh distribution semi heavy tail gh mean bound compare normal distribution gh distribution decay slowly however compare three heavy tail distribution student distribution laplace distribution cauchy distribution decay speed gh distribution often faster distribution formulate large value density proportional degree freedom laplace distribution also call double exponential distribution form laplace location parameter scale parameter cauchy distribution define cauchy median scale parameter compare four heavy tail distribution normal one order keep comparability distribution specify mean distributionto use one important subclass gh distribution simplicity normal inverse gaussian nig distribution introduce precisely follow text left panel complete form distribution reveal cauchy dot distribution low peak fattest tail word flattest distribution nig distribution decay second fast tail high peak tail behavior clearly displayed right panel generally gh distribution exponential decay speed show change distribution comparison tail comparison nig laplace cauchy normal cauchy laplace nig normal fig graphical comparison nig distribution line standard normal distribution dash laplace distribution dot cauchy distribution dot icatail xpl gh distribution family cover wide range tail behavior example parameter introduces heavier tail double exponential one may therefore think tail control parameter loosely speak one may model range normal cauchy tail moment generate function gh distribution gh distribution property infinitely many time differentiable near result every moment gh variable exists section feature tail behavior gh distribution use adaptive volatility estimation methodology hyp normal inverse gaussian nig distribution frequently use motivate fact four parameter simultaneously control four moment function distribution trend riskiness asymmetry likeliness extreme event eberlein keller barndorff nielsen show subclass rich enough model financial time series benefit numerical tractability therefore study concentrate two important subclass gh distribution hyp nig distribution correspond density function give hyperbolic hyp distribution hyp ir normal inverse gaussian nig distribution nig ir order estimate unknown parameter maximum likelihood ml numerical optimization method use hyp resp nig distribute variable log likelihood function log log log log logk hyp xt log log log nig xt logk log show estimate hyp nig density correspond ml estimator two ic fx portfolio see estimate density almost coincide empirical density financial risk factor empirical density line estimate kernel estimation xn nh number observation kernel function give weight observation accord distance fix point observation fix point small weight give chose quartic kernel function close form indicator function value condition parenthesis exists value otherwise addition use silverman rule thumb select bandwidth rot empirical standard deviation variable since rule thumb assumes unknown density belongs normal family chose quartic kernel bandwidth adjust use canonical rot bandwidth seechapter inh ardle mu ller sperlich werwatz compare normal distribution convincing gh distribution family represent empirical distribution financial risk well generate gh random variable section discus one algorithm generate gh random variable gh variable construct generalize inverse gaussian gig random variable standard normal random variable cont tankov gig density function exp gig sample gh formulate gh gign gig denotes standardize normal constant firstly discus algorithm generate gig variable atkinson propose algorithm generate gig use envelope rejection technique density assume sample exponential function range divide two part rejection function respect value generate inverse gig density construct algorithm generate gh summarize set generate gig gig generate standard normal get gh xz adaptive volatility heteroscedastic model estimation covariance matrix play important role variable independent covariance diagonal matrix thus estimate element diagonal line volatility ic separately covariance original variable linear transformation diagonal matrix hence covariance estimation simplify volatility estimation respect ic development volatility estimation summarize briefly say volatility firstly assume constant black scholes model introduce however violate process span long time period call volatility cluster observe volatility smile option market provide enough evidence reject constant assumption thereafter volatility regard time dependent firstly one use time invariant function estimate volatility arch engle garch bollerslev stochastic volatility model harvey model inherent weakness long time series form volatility model may variant volatility high possibility therefore plausible use flexible tool provide data driven local model avoid potential miss specification problem use mercurio spokoiny introduce model estimate volatility adaptively algorithm assumes volatility constant short time interval although volatile long run theory propose local constant model however base normality assumption risk factor chen extend study base gh distribution give accurate var estimation chapter introduce adaptive estimation algorithm apply estimate volatility ic adaptive volatility basic idea adaptive volatility estimation come observation although volatility heteroscedastic long time period change short time interval call time homogeneous interval small evidence argument give mercurio spokoiny accord time homogeneity one specifies interval fix time point volatility almost constant one may example estimate case local constant volatility average past square return cardinality two question arise procedure well estimate work specify homogeneous interval square return always nonnegative stochastic error gh hyp nig skewed distribution order apply interval selection procedure use power transformation return arestandardizedi innovation conditional mean conditional variance additionally lighter tail obtain power transformation tail behavior require later derive theoretical property estimate later let denote conditional mean transform return since constant give fix estimate volatility proportional time homogeneous interval local parameter constant estimate write one one see multiplicative error structure turn via additive one random variable distributes evenly straightforwardly one calculate conditional expectation variance estimate var ex therefore consider estimate time point therefore estimate word volatility estimate induced estimate however specification local homogeneous interval still open mercurio spokoiny derive homogeneity test supermartingale process show supermartingale gh distribute variable obtain follow lemma therefore lead homogeneity test theory lemma every exists constant loge eu transform gh distribute variable proof lemma give consider predictable process volatility local parameter information set exp supermartingale since exp exp exp exp exp exp exp exp exp exp lemma supermartingale property statistical property give follow theorem theorem obey heteroscedastic model residual satisfies lemma furthermore volatility coefficient satisfies condition bb positive constant hold estimate logb exp square bias define theorem indicates estimation error small relative high probability time homogeneous interval therefore square bias isnegligible straightforwardly hypothesis interval test split two subintervals time homogeneous interval estimate base two subintervals must close homogeneity condition state provide sufficiently large condition violate homogeneity hypoth esis interval reject test procedure start initial small interval consists step step enlarge interval split new interval two subintervals parameter integer specify accord data paper chose step start homogeneity test interval homogeneity hypothesis reject enlarge one point repeat homogeneity test loop continue left point subinterval reach point choice come fact right part test last homogeneous interval left one third test next homogeneous interval mercurio spokoiny step isviolatedatpoints specify point point step time homogeneity hold interval go back step thelargestintervali basedon local volatility estimate however still two threshold parameter specify power transformation homogeneity test condition accord lemma parameter bound study chose model base normal distribution satisfy comparability value similar smooth parameter nonparametric regression thus propose nonparametric way pick global give start point provide enough past observation estimate value minimizes forecast error argmin proof lemma proof firstly show moment generate function eu exists suppose gh density function transform variable dx dx density dz since follow gh euzg dz hold since lim uz lim uz since integration depends exponential part hold also zneuzg dz euz dz euy un un show moment generate function log euy smooth hold every euy eu eu eu eut ut without loss generality assume gh xdx press teukolsky vetterling flannery arbitrary fix ut hold xdx ut ut ut consequently eu eut xf dx eut xx xdx ut xdx ut xdx ut ut ut large uc hold true since ut uuc give get eut get log eut log log eut also bound analogously show bound log eut therefore whole term eu bound give eut log eut constant thus log eu log eut log eut bound sufficient large exist constant eu uu empirical study chapter use propose method independent component analysis chap ter generalize hyperbolic gh distribution chapter adaptive volatility timation chapter calculate multivariate value risk var one portfolio dimensional exchange rate dem usd gbp usd var one often use risk measure give distribution portfolio return var quantile measure possible loss level give horizon pre set horizon research var model ignite prompt rule basel committee banking supervision financial institution may use internal var model selection internal var model well volatility estimation essential var base risk management mathematically var define var inverse function conditional cumulative distribution function return portfolio time franke moment three method mainly use practice measure multivariate var riskmetrics also name delta gamma normal method assumes ele ments portfolio follow gaussian distribution portfolio give weight element forecast var level var estimate use exponential move average ema method see franke riskmetrics definitely easy implement desirable statistical property normal distribution asymptotically dimension portfolio large enough portfolio converges gaussian distribution concurs diversification effect large portfolio sense riskmetrics method give approximation quantile portfolio return however method often underestimate market risk portfolio since financial timeseriesareheavy taileddistributed financial industry compare accuracy var forecast base propose methododlogy riskmetrics one monte carlo simulation give precise var calculation simulates time series element include portfolio estimate covariance matrix base simulation however implementation method jeopardized expensive computation historical simulation claculates var construct univariate hypothetical portfolio return therefore avoids estimation covariance possibly im mune fault pron distribution assumption give univariate time series forexample anonparametric fittingoraheavy risky element moreover new hypothetical series need con structed weight portfolio change case riskmetrics monte carlo simulation method neither method propose give dimensional portfolio propose var calculation process use fastica get ic large dimension reduction base measure consider see equation suppose ic chosen estimate adaptive volatility process ic since volatility process supermartingale natural use estimate today forecast tomorrow assume ic follow gh distribution subclass hyp nig calibrate distribution parameter respectively instead calibrate ic series handle devolatilized ic comparably auto uncorrelated apply monte carlo mc simulation estimate quantile portfolio give weight vector portfolio return predict md md independent stochastic variable simulate time gh average quantile pn portfolio return consider var forecast influence estimation ic marginal density volatility evaluate validation var calculation consider backtesting proce dures present christoffersen since riskmetrics regard industrial standard measure portfolio risk compare forecast propose method base riskmetrics method reliable var calculation let true loss var forecast proportion exception much large mean possible loss happen often fix level case var model reject one construct hypothesis binomial random variable parameter likelihood ratio test statistic derive lr log nan log asymptotically distribute jorion addition var model yield exception cluster also reject cluster var exceedance mean exception today exception may also occur tomorrow high probability prescribed level therefore second backtesting test independence let denote transition probability independence null hypothesis give one test hypothesis use likelihood ratio statistic lr log log lr asymptotically distribute well jorion time series mean variance skewness kurtosis dem usd gbp usd ic ic tab descriptive statistic return dem usd gbp usd two ic icafxdescriptive xpl exchange rate dem usd dem jpd first portfolio consider consists two daily exchange rate dem usd gbp usd series observation data available md base www mdtech de firstly use fastica find two ic base daily return exchange rate descriptive statistic report see four time series return dem usd gbp usd two ic standardize symmetric leptokurtic distribution assumption make study sound moreover autocorrelations insignificant dependent structure two time series illustrate display strong positive linear relation two return process left plot dependence eliminate linear transformation ica right panel two ic seem linearly uncorrelated convincing result illustrate comparison joint density return two exchange rate show nonparametrical kernel density estimation left product hyp fitting two ic right firstly nonparametrically estimate joint density return red surface deviate riskmetrics assumption bivariate normal density blue surface emphasize tail joint density crucial var calculation nonparametrically density high peak important heavier tail normal one therefore riskmetrics framework one often underestimate probability extreme value right panel product marginal density ic imitates whole surface empirical joint density especially tail case provide evidence propose methodology well time series two ic obtain base ica model estimate matrix ica fx dem usd gbp usd fx ic ic dsu pbg ci dem usd ic fig fx return dem usd gbp usd ic fx return icafxdescriptive xpl ic use adaptive constant model estimate time variant volatility process display time series two adaptive volatility process interest observe seasonality volatility process second ic implies asdiscussedbefore ic process show two process auto uncorrelated base devolatilized return process estimate gh distribution parameter study consider four trading strategy var forecast five extreme risk level portfolio forecast backtested last year forecast var time plot exception displayed portfolio return plot dot one step ahead var forecast base propose methodology drawn line forecast base riskmetrics plot dot line exception portfolio loss var forecast marked cross cross denote exception propose methodology bottom exception observe riskmerics framework empirical risk level correspond backtesting result different trading strategy report different trading strategy fix var risk level calculate empirical risk level proportion exception value two test lr lr riskmetrics underestimate market risk level test reject bad case happens one hold unit dem usd unit gbp usd portfolio empirical risk level time joint pdf fx return joint pdf ic fig comparison nonparametrical joint density black return exchange rate product blue hyp marginal density two ic red surface gaussian fitting covariance return exchange rate xpl fx acf plot ic fx acf plot ic fca fca lag lag fig acf plot devolatilized ic base dem usd gbp usd rate icafxdescriptive xpl expect one contrary propose method provide accurate var forecast empirical level underestimated close level expect benefit financial institution want control risk time avoid unnecessary capital deposit however observe propose var model give deep value especially large loss extreme risk level turbulent var forecast fx adaptive vola ic alov alov time fx adaptive vola ic time fig adaptive volatility time series ic fx return icafxdescriptive xpl propose methodology riskmetrics method lr lr lr lr nan nan nan tab backtesting var forecast exchange portfolio icafxvarplot xpl var plot var plot var plot var plot var plot fig var time plot exchange rate portfolio weight risk level respectively top icafxvarplot xpl var plot yy var plot var plot var plot var plot fig var time plot exchange rate portfolio weight icafxvarplot xpl var plot var plot var plot var plot var plot fig var time plot exchange rate portfolio weight icafxvarplot xpl var plot var plot var plot var plot var plot fig var time plot exchange rate portfolio weight icafxvarplot xpl conclusion master thesis propose multivariate risk management model study mainly base independent component analysis ica heavy tail dis tribution assumption ica avoids estimation dependence structure high dimensional data joint density multivariate case linear trans formation found ica help find independent component ic joint density product marginal one covariance diagonal matrix thissense density estimation ic gh distribution preferable since mimic em pirical density ic accurately furthermore adaptive methodology use estimate dynamic volatility process implementation three method per form outstanding var study base dimensional exchange rate portfolio study summarize follow adaptive volatility estimation methodology mercurio spokoiny applicable generalize hyperbolic distribute process threshold parameter use specify time homogeneity interval estimate nonparametric way distribution devolatilized return adaptive volatility estimation found leptokurtic perfectly model hyp nig distribu tions subclass generalize hyperbolic distribution propose approach easily apply calculate forecast risk measure several trading strategy show propose approach performs much well widely use riskmetrics model bibliography atkinson simulation generalize inverse gaussian hyperbolic random variable siam journal scientiffic compute back weigend first application independent component analysis extract structure stock return international journal neural system barndorff nielsen exponentially decrease distribution logarithm particle size proceeding royal society london barndorff nielsen model scandinavian journal statistic barndorff nielsen bl sild hyperbolic distribution ramification contribution theory application taillie patil baldessari ed statistical distribution scientific work vol reidel pp bibby rensen hyperbolic process finance technical report aarhus aarhus school business bollerslev generalied autoregressive conditional heteroskedasticity engle ed arch select reading oxford press pp cardoso souloumiac blind beamforming non gaussian signal ieee proceeding chen ardle jeong nonparametric risk management general ized hyperbolic distribution sfb discussion paper christoffersen evaluate interval forecast international economic review comon independent component analysis new concept signal processing cont tankov financial model jump process chapman hall crc cover thomas element information theory john wiley son duann jung kuo yeh makeig hsieh sejnowski single trial variability event related bold signal neuroimage eberlein andkeller bernoulli eberlein kallsen kristen risk management base stochastic volatility journal risk embrechts mcneil straumann correlation dependence risk management property pitfall dempster ed risk management value risk beyond cambridge press engle autoregressive conditional heteroscedasticity estimate variance united kingdom inflation arch oxford press flury common principal component related multivariate model john wiley son inc franke ardle hafner statistic financial market springer verlag heidelberg new york ardle simar apply multivariate statistical analysis springer verlag heidelberg new york ardle mu ller sperlich werwatz nonparametric semi parametric model springer verlag harvey ruiz shephard multivariate stochastic variance model engle ed arch select reading oxford press pp hyv arinen new approximation differential entropy independent com ponent analysis projection pursuit mit press pp hyv arinen gaussian moment noisy independent component analysis ieee signal processing letter hyv arinen oja fast fix point algorithm independent component analysis neural computation hyv arinen oja independent component analysis algorithm ap plication neural network hyv arinen karhunen oja independent component analysis john wiley son inc jaschke jiang approximate value risk conditional gaussian model ardle kleinow stahl ed apply quantitative finance springer verlag jorion value risk mcgraw hill mercurio andspokoiny model submit press teukolsky vetterling flannery numerical recipe cambridge press ristaniemi raju karhunen jammer mitigation cdma use proc ieee int conf communication taleb fool randomness hidden role chance market life texere publishing
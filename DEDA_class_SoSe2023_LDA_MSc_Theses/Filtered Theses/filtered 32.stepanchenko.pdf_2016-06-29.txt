github api driven cluster level text mining validation pipeline base approach master thesis submit prof dr wolfgang ardle supervisor lukas borke universit zu school business economics institute statistic econometrics ladislaus von bortkiewicz chair statistic case center apply statistic economics anastasia stepanchenko partial fulfillment requirement degree master economics management science june would like thank lukas borke theoretical initiator technological driver sug gested lot valuable idea give many piece helpful advice responsible support github repository rdc server via framework large project generously provide githup api data quantlets result massive parallelization rdc crc system resource server let work complete nite time imagine scienti world today without big data although er wide possibility nding pattern give matter also pose problem process huge amount raw data statistical challenge de ning best model introduce opti mal algorithm prove consistency apply method cluster play major role deal high dimensional data aim research implement initial processing massive text sample present result text mining consider lsa model dimensionality reduction precisely try di erent cluster vali dation method software environment apply technique collection numerical method call quantlets keywords big data text mining cluster cluster validation high dimensionality dimensionality reduction lsa svd content content list abbreviation list list introduction big project current research outline paper theory basic theory vector space model cluster useful de nitions validation index data get data set data statistic sample con guration research validation pipeline lsa anatomy cluster validation result preliminary result result clustercrit package result nbclust package conclusion content example metainfo txt technology use web link list abbreviation list abbreviation order appearance adj adjust api application program interface appr approximately bvsm basic vsm comfortable customizable controllable data driven document dom document object model ei easy interpret alia gvsm generalize vsm hca hierarchical cluster analysis hi hard interpret lsa latent semantic analysis ql quantlet qn quantnet svd singular value decomposition tt term term correlation model vali pp validation pipeline vsm vector space model wrt respect yaml yaml markup language list list big project number document contain give eld number document contain give eld merge number document contain give eld clean merge number char symbol di erent eld vali pp weight singular value error approximation matrix form distribution svd shakespeare work md plot shakespeare work chart take beta version quantnet xie beni index minimize calinski harabasz index maximize quantnet chart take beta version quantnet list list main result clustercrit main result nbclust introduction today modern technology come power imagine scienti world without big data although er wide possibility nding pattern give matter also pose technical statistical problem computational point view task could process huge amount raw data minimize storage cost make decision permissible error statistical challenge however de ning best model invent new optimal algorithm prove consistency apply method moreover one always aware nal goal research achieve result might helpful investigation whether useful application could found big project research part big project manage execute lukas borke struc ture objective easily described diagram big project github provide user web base graphical interface well know version control system also allows high level feature access control collaborative work rst step large scheme adjust application program interface api github software environment implement di erent parser extraction data various repository program project big data obtain stage thus constitute large corpus text document corresponds meta information particular program code next step get smart data raw text collection task case complete mean data serialization language call yaml design human readable data orient language easily apply widely use data frame list array make yaml also rather user friendly maintain hierarchical data avoids excessive use bracket tag enclosure could make document structure less comprehensible thus derive smart data pass complex chain processing data mining cluster result form brought life visualization via opportunity provide javascript library stand data driven document concept perform cient manipulation document object model dom base data web orient fast ciently operates massive datasets beta version quantnet see link good example power base chart library make integration diagram application comfortable customizable controllable clear abbreviation hidden name information big project found presentation borke ardle current research parser end point smart clusterization node aim rst stage implement initial processing massive text sample obtain github mirror quantnet see link later collection numerical method call quantlets illustrate data statistic second stage base cluster play major role deal high dimensional data idea combine similar object homogeneous group originate dawn humanity rst use simple classi cation cluster end integral part totally di erent discipline among archeology linguistics bioinfor matics genetics others see everitt landau leese stahl information nowadays vast amount various numerical method introduce order make retrieval information partition easy cient also ass cient main goal try di erent cluster validation method software environment de ne optimal combination data con guration vector space model cluster method appropriate way validate quality result partition eventually de ne reasonable num ber cluster element combine call level validation pipeline vali pp discuss detail separate chapter cluster generally perform well kind data consider study outline paper paper organize follow next chapter describes main theory behind research section data describes data set obtain present statistic text corpus hand chapter research result describe step investigation outcome accordingly finally last section concludes theory basic theory chapter brie describe basic theory suppose set document collection text case set term whole corpus let de ne tf absolute frequency term document number occurrence term give text document familiar linear algebra may notice tf homomorphism space word string set non negative number respect concatenation addition operation accordingly since tf tf tf natural approach would represent text vector vector space number dimension equal number element vector component associate particular term entry frequency term give document corpus represent matrix column vector document call matrix term document matrix since column toaparticularterm aswillreadily beobserved inmostcasessuch text zerocomponents mean matrix sparse another important notion use similarity measure function de ned pair document general form write pd pd dtptpd matrix de ne call vector space model vsm mp dt ptp similarity matrix interested algebraic interpretation view original vector space space non euclidean metric construct similarity measure follow way tptp orig mapping pd another vector space base word frequency also preserve semantical structure word cooccurrences word importance furthermore new space original metric becomes euclidean point mao balasubramanian lebanon tp kp kpd pd orig vector space model depend matrix consider three model mention cristianini shawe taylor lodhi basic vsm bvsm mtf dtd bysaltonetal although bvsm appear show good result supposes term completely uncorrelated operate document share synonym model treat unrelated hence perform well document lot common term term term correlation gvsm tt dt mtt dt ddt bywongetal semantics mean statistical information obtain text database gvsm considers two term related proportional often cooccur document new metric de ned ddt call term term correlation matrix pq entry equal zero document share th th term contrast basic model one detect similarity related text even common term latent semantic analysis lsa ut mlsa dt ui ut itwas propose deerwester base singular value decomposition svd term document matrix vt orthogonal matrix diagonal matrix model set projection operator onto rst dimension ut rst one main diagonal zero elsewhere fact lsa represent set model variation depend particular default data later test several value number dimension order get require result model perform well others current research devote separate section later cluster compare three di erent method hierarchical cluster mean medoids algorithm pam partition around medoids rather well know often use essential aspect method point detail see everitt landau leese stahl meansandk climb algorithm thatassumethe existence initial partition desire number cluster seek nd best cluster iteratively rearrange original partition process converges mean whereas medoids takesmedoids insteadofmeans operates real element observation set algorithm depend initial partition data structure well enough one expect nal result cluster procedure almost always thus independent rst condition one nd ql link interest application mean cluster contrast mean medoids method result number cluster hierarchical procedure de ned beforehand algorithm rather number successive partition terminates optimum chosen criterion achieve method call agglomerative rst stage observation form cluster united step step divisive method opposite start one cluster contain individual successively divide group within agglomeration hierarchical cluster use method call average ward ward number cluster research document work possible number varies text constitute one big cluster case obviously interest text constitutes cluster however make sense consider large number cluster since would rather unite possible document order nd describe general similarity reason upper limit cluster number current paper set useful de nitions use basic de nitions take desgraupes suppose observation variable divide cluster element th cluster gfkg barycenter geometrical interpretation associate observation vector coe cients point coordinate rp coordinate barycenter simply coe cients vector pn denote number pair di erent point set cluster number pair point belong cluster let sum distance pair point inside cluster sum min small distance pair point full data set max sum large distance pair point full data set characterize quality cluster follow notation useful denote total scatter matrix equal time covariance matrix entire data set let wg within group scatter matrix sum within group scatter matrix cluster proportional cluster covariance matrix later upper index fkg mean variable take computation element th cluster denoteby wgssthepooledwithin clusterdispersion thesumofwithin cluster dispersion wgssfkg cluster wgss wgssfkg wgssfkg jjmfkg gfkgjj hand de ne bgss group dispersion geometrically sum square distance cluster barycenter global barycenter weight number observation correspond cluster bgss jjgfkg gjj denote vector dimensional space coordinate constitute value th variable observation total sum square tss equal tss var vj validation index validation cluster method di erent measure introduce consider implement package clustercrit nbclust optimal number cluster derive maximize minimize index value di erence two successive slope last mean plot indexvalues thebestvaluefor correspondsto elbow suppose example need maximize di erence two successive slope let denote de ned arg max km km internal index ered package exceptional interest allow rather clear interpretation follow list contains main formula additional information measure consider research de graupes brock pihur datta datta ball hall index ball hall index mean cluster mean dispersion kmfkg gfkgk inordertode erencebetween two successive slope range index index show give cluster fraction maximal possible increase minimal distance constitutes increase within cluster distance pair point minimal distance min max min order de ne optimal number cluster one minimize index range calinski harabasz index calinski harabasz index proportional quotient group dispersion pool within cluster dispersion bgss wgss order de ne optimal number cluster one maximize index range davy bouldin index davy bouldin index deal cluster close term barycen ters distant point within max kk kmfkg gfkgk kgfk gfkgk kk order de ne optimal number cluster one minimize index range dunn index dunn index deal cluster contain closest point belonging dif ferent cluster also cluster distant point within index equal ratio small distance observation cluster large intra cluster distance min min dist max diam cm diam de ned maximum distance observation cluster order de ne optimal number cluster one maximize index range mcclain rao index mcclain rao index quotient mean within cluster cluster dis tances sw nw sb nb sum within cluster distance sum cluster distance order de ne optimal number cluster one minimize index range ratkowsky lance index ratkowsky lance index base mean quotient bgss tss variable data tss nvar vj bgss fkg bgss tss order de ne optimal number cluster one maximize index range ray turi index ray turi index quotient two quantity mean square distance cluster barycenter wgss min kk order de ne optimal number cluster one minimize index range silhouette index silhouette index operates quantity depend average distance give observation observation inside also inside near cluster max min order de ne optimal number cluster one maximize index range trace index trace index simply pool within cluster dispersion tr wg wgss inordertode erencebetween two successive slope range wemmert gancarski index wemmert gancarski index base quotient distance point barycenter cluster maxf km gfkgk minkm gfk gk order de ne optimal number cluster one maximize index range xie beni index xie beni index quotient mean pool within cluster dispersion minimum minimal square distance point cluster wgss min mind order de ne optimal number cluster one minimize index range data whole process obtain data divide follow stage decision big data step smart data text database collection choice sample con guration text preprocessing weight discus stage follow section get data set big data initial source data github mirror quantnet later qn online repository numerical method call quantlets later qls qls consist document related various scienti topic create di erent author professional researcher student document may contain source code create software environment matlab sa python gauss stata xplore research deal write matlab sa python smart data big data processing new format ql metadata introduce order standardize document supply ql individual meta information text le format yaml serialization language meta info le con tained mandatory eld see link styleguide meta information example well make metainfo txt name quantlet publish title original book paper description least word keywords least word chosen global qn keyword list author chosen global qn author list among optional eld see also qls related topic data le data le global qn data le repository use code example list generate plot description textdatabase api parser implement although work eld mention parser include technical information data set type eld expose initial preprocessing derive basic statistic text preprocessing order make text comparable hence obtain unbiased result corpus clean follow item punctuation white space number capital letter change lowercase pre ending stem base porter gorithm stopwords word commonly use characterize text properly weight aterm ed component weight schema term frequency set natural weight schema document frequency set identity schema normalization set cosine data statistic initial preprocessing stage want identify eld equivalent although formally write di erent way bar chart show many document give eld begin distribution name horizontal axis clear eld merge result eld receive name correspond maximal number document include namely author new author update become author data le data le example become data le keywords new become keywords name quantlet become name quantlet subfunctions become subfunction number document contain give eld result see follow diagram sort alphabetical order number document contain give eld merge another idea follow though eld formally include meta information le could actually appear empty negligence person submit quantlet next step category exclude nal state data set show one see three eld less axis next step want count many char symbol eld embrace gurationforthe computation present require histogram one derive signi cant cluster eld could description keywords see also example data le author number document contain give eld clean merge number char symbol di erent eld sample con guration con guration mean combination eld left whole meta information combination stand document frame study de ned three sample con gurations two extreme case one choice con guration text document represent description keywords case thus minimum could reasonable text mining con guration nottechnical eldsofmeta info unimportant information con guration iii text document represent weight combination signi cant eld determine previous section weight chosen eld description keywords see also example data le author correspondingly logic behind choice description biggestcontribution data le sinceseveral qls related observation set less close slightly less signi cant author example author also submit qls completely di erent area example often copy description end come see also name similar document research validation pipeline summarize already say research deal follow feature sample con gurations form chapter data vector space model determine chapter theory bvsm gvsm tt lsa automatic choice dimension lsa choice dimension index validate quality cluster de ned chapter theory di erent cluster method hierarchical cluster average ward ward algorithm mean cluster medoids cluster number cluster main goal work nd combination component list would give best cluster apply smart data visual interpretation idea could pipe gear wheel represent one component take smart data input return smart clusterization output let call newly invent device validation pipeline vali pp main purpose analogy determine best angle rotation gear wheel together combination let smart data pas pipe ective way ectiveness mean try nd maximal amount information validation technique omit storage computational cost without change global result conclusion nice illustration described process found vali pp lsa anatomy lsa model since initial hypothesis theoretically perform well eventually turn true remind main idea model reduce dimension leave large term absolute value singular value diagonal matrix svd decomposition mathematical de nition lsa see chapter theory therefore rst thing come mind ect singular value way represent clear understand many dimension kept result space follow weight singular value data plot derive rst six element particularly large singular value start seventh one form almost continuous curve leave small number dimension would lead great loss data infor mation lsa always compromise reduction error also take consideration automatic mode lsa procedure us dimcalc share function determine optimal number cluster method take singular value sort descend order calculates step step sum rst element terminates sum constitutes give share total singular value sum thisshareequals dimension illustrates weight singular value distribution matrix follow order original term document matrix truncate one automatically create lsa space di erence matrix rst two matrix error approximation matrix form could also interest make visualization lsa component self show distribution heatmaps correspond order oftheoriginalterm documentmatrix ofthe whosecolumns represent semantic component diagonal matrix descend singular val documentcoe cients regard product new basis lsa space form semantic com ponents although distribution matrix entry close normal structure recognizable example left column column correspond large singular value show clearer concentration several term tends right di use chaotic becomes behavior term frequency intuitive explanation could right component less weight singular value contribute consistently contribution small besides lot term value left component actually represent row coordinate matrix close zero thus conclude left component uence term especially strong document distribution svd picture related diagonal matrix slightly noticeable change color see top left area corresponds signi cant singular value matrix vt right matrix svd distribution entry also close normal structure identi able reason entropy row isthesameandsoisthe documententropy since distribution row even close normal distribution maximal entropy could reach cluster validation cluster validation part research two package use clustercrit nbclust rst library calculate validation index de ned theoretical part paper except silhouette second package seven measure take intersect measure clustercrit namely ball hall index calinski harabasz mcclain rao ratkowsky lance davy bouldin dunn also silhouette three reason include another library study compare result validation method obtain di erent pack age clustercrit implementation test whether measure give clear result clustercrit could easy interpret another package frame package clustercrit compare mean medoids average hi erarchical cluster method whereas nbclust method ward ward mean select among package use calculation tm text mining library provide mean data import corpus handle preprocessing construction term document matrix snowballc give access porter word stem algorithm thus oppor tunity operate di erent form word lsa create latent semantic space give term document matrix snowfall package present method development parallelize process cludes extend error check function cluster auxiliary library cluster analysis abind help merge multidimensional array obtain parallelization single one ggplot produce plot since calculation time consume case nbclust sometimes take hour compute result single index execution clustercrit ran slightly faster still last appr hour index whole process parallelize cpu terminate altogether less day consideration conclusion make base plot curve curve vector space model show value give validation index axis number cluster axis plot create combination cluster method sample con guration nine picture measure give picture package clustercrit another package nbclust result dealt plot demonstrative present next chapter rest follow link project source result preliminary result already mention priori hypothesis imply lsa model case lead best cluster prediction base preliminary study techniquestow shakespeare scollectionofworks relatively small consist poem almost time less element current data set time text strongly pronounce semantical structure make interpretation cluster clearer cluster time package clvalid involve vector space model cluster method however library make three internal measure available connectivity silhouette width dunn index shakespeare work md plot appropriate combination model method appear lsa mean document even possible present nice visualization cluster also nd good opportunity demonstrate advantage chart md multidimentional scale plot see correspondingly shakespeare work chart take beta version quantnet result clustercrit package show best cluster method best model best con uration index last two wheel vali pp best index optimal number cluster consider particular case separately however davy bouldin ray turi xie beni dunn case necessary remark provide ei easy interpret hi hard interpret plot hi index look chaotic unstable see example show picture correspond xie beni index row relate di erent sample con gurations hierarchical cluster right column leaf chance determine best model xie beni index minimize compare di erent look picture ei index also want present set plot calinski harabasz index one easily derive best model lsa dimension later lsa best method medoids hierarchical cluster comparable certain cluster number size nally best con guration ii since index maximize curve lie high second row calinski harabasz index maximize give comment main result hca third column obviously stand hierarchical cluster analysis footnote discuss later index best model best cluster method best conf ball hall ei tt lsa hca ii index ei tt lsa hca iii calinski harabasz ei lsa medoids ii mcclain rao ei lsa mean medoids iii ratkowsky lance ei tt lsa ii trace ei lsa lsa hca ii iii wemmert gancarski ei lsa mean medoids iii davy bouldin hi lsa medoids ii ray turi hi lsa hca iii xie beni hi bvsm hca ii dunn hi bvsm hca ii main result clustercrit tt model best wrt optimal cluster number selection whereas lsa model best wrt global behavior curve medoids method well hca comparable certain cluster number size hca also comparable lsa best model index hca comparable wrt global behavior curve hca show stable behavior model model close hca particular lsa bvsm model particular bvsm lsa relatively close also quite small interval regard value range index overall conclusion make base even advan tage lsa hca separately sometimes obvious combination never bad combination similarity model cluster method sample con guration hard decide whether ii iii well thing becomes clear include minimum information cluster good decision result nbclust package show similar gathering result nbclust package comment footnote overall conclusion almost index best model best cluster method best conf ball hall ei tt lsa ii iii index hi lsa ward ii iii calinski harabasz ei lsa ward ward ii mcclain rao ei lsa ward iii ratkowsky lance ei tt lsa ii iii davy bouldin ei lsa mean ii iii silhouette ei lsa ward ward iii dunn hi bvsm ward ii main result nbclust tt model best wrt optimal cluster number selection whereas lsa model best wrt global behavior curve model particular bvsm lsa relatively close also quite small interval regard value range index summarize say even separately obvious lsa model hierarchical cluster analysis well model cluster method con easy hard interpret depends de nitions implementation conclusion summarize do frame current study say main goal research achieve introduce developed call validation pipeline functional multi stag instrument cluster analysis determine help appropriate way represent data namely lsa model together su cient set eld ect core semantics text corpus time make decision optimal cluster algorithm ective application ndings already exist show earlier men method illustrates work quantnet chart take beta version quantnet also worth point whole organization project include version control source le update latex draft paper keep result relevant stage investigation do use high possibility provide github suitable introduce technology procedure driven meta information le beforehand speci ed format consequence parser universal adapt every particular case base thought several direction develop current research couldbeissued oneof possible would di erent github organization also extend smart text structure thus theoretically allow cluster result well ect reality another interest issue could investigate error due dimensionality reduction lsa model depends number result dimension example choice appropriate matrix norm might helpful estimation error matrix form sphere experiment text data would useful test behavior result set term randomly change example get rid word contrary add new term could give answer question whether mistake cause negligence really signi cant desgraupes cluster index paris ouest lab modal everitt landau leese stahl cluster analysis uk king college london th ed brock pihur datta datta clvalid package cluster validation department bioinformatics biostatistics louisville borke ha rdle lsa quantnet github ladislaus von bortkiewicz chair statistic center apply statistic economics universita zu cristianini shawe taylor lodhi latent semantic kernel london mao balasubramanian lebanon dimensionality reduction text use domain knowledge georgia institute technology example metainfo txt name quantlet mvasirdata publish apply multivariate statistical analysis description generates data set applies slice inverse regression algorithm sir dimension reduction keywords edr direction dimension reduction estimation sir regression plot graphical representation see also mvappsib mvasimdep mvasir data mvasimdepex mvappexample ppsib ppsibexample author zografia anastasiadou submit fri august awdesch melzer example left plot show response versus estimate effective dimension reduction direction edr direction upper right plot three dimensional plot first two direction response low right plot show eigenvalue cumulative sum plot true response versus first true index monotonic convex shape clearly see plot true response versus second true index monotonic convex shape clearly see technology use chart draw io program edit latex project organization github web link quantnet http quantlet de beta version quantnet http quantlet de beta github quantnet mirror http github com quantlet styleguide meta information http github com quantlet styleguide faq blob master styleguide md http org http org example qls cluster http github com quantlet mva ready tree master qid mvaqnetcluskmeans http github com quantlet mva ready tree master qid mvaqnetcluskmeansb http github com quantlet mva ready tree master qid mvaqnetcluskmeanst source research http github com net cluster validation pipeline declaration authorship hereby con rm author master thesis independently without use others indicate source passage literally general matter take publication source marked june anastasia stepanchenko
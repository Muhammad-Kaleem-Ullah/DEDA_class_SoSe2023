graphical model statistical learn sex related homicide masterarbeit zur erlangung de grade master science im gemeinsamen masterstudiengang statistik der universit zu freien universit technischen universita und charit universita tsmedizin vorgelegt von stephan stahlschmidt pru fer prof dr wolfgang ha rdle september present twofold analysis domain sex related homi cides police profilers often help criminal investigation high pro file case empirical evidence domain incomplete therefore first apply structural learn approach secondly try explicitly predict age unknown offender informa tion obtain crime scene apply graphical model obtain factorisation prob ability function governs domain factorisation allows infer dependency independency variable therefore describes domain apply several structure learn ing algorithm bayesian network combine final graphical model second part compare several prediction technique concern error rate predict offender age graphical model broadly present distinction fender situation driven crime situation driven crime may characterise offender lack preparation typically attack ing know victim familiar surroundings offender tends apply blunt force gain control victim show identify high level forensic awareness demonstrate tim furthermore graphical model indicates offender likely attack unknown victim unfamiliar surround ings prepare attack apply several prediction technique date result sig nificant decrease root mean square error compare simple baseline model however actual performance best model namely lasso still applicable criminal investiga tion average error year high content content introduction note criminological theory data bayesian network technique structure learn algorithm parameter learn implementation result statistical learn model selection technique linear regression ridge regression lasso regression tree near neighbour random forest support vector regression implementation result discussion introduction introduction sex related homicide tend arouse wide medium coverage thus raise urgency find prosecute responsible offender pecially involvement child victim result broad discussion public sphere police confront close attention however homicide clear rather quickly case require profound effort police special case call profilers may assist ordinary criminal investigation criminal profile define process identifiying sus pect behavioural characteristic principal personality crime scene police profilers firstly analyse crime scene carefully try discover thesis event occur finally type person could commit act method thereby relies certain assumption notably belief criminal personality retrieve crime scene gain psychological social profile suspect several advantage police know characteristic offender narrow number potential suspect exclude show ing specific trait hopefully lead faster arrest criminal also reduces cost police society knowledge may lead certain investigative strategy people show different reaction police interrogation approach prove useful question suspect wide successful application offender profile en hanced scientific background knowledge beauregard give overview apply technique however study concen trate rather broad typology predict single variable davy salfati canter consequently empir ical knowledge cover whole domain sex related homicide introduction scarce also result low frequency case average case every year germany transfer thesis case data observation subsequent analysis labour intensive necessary information may gather via retrospective analysis reading important document result criminal investigation judicial proceed ings last term sex related homicide include wide range homicide could diverse paedophiliac fender assault child kill victim happens naked surprise attack plicate still miss substantial effort enlighten field research german federal criminal police office recognize need information conduct research offender geographical behaviour dern know distance crime scene offender personal hub sub stantially narrow geographical space cover search offender knowledge reduces number potential sus pects consequently accelerates criminal investigation less potential suspect inspect thesis hand like contribute topic concen trating offender age know potential age group offender also reduces number potential suspect fore speed criminal investigation firstly report structure domain sex related homicide afterwards ap technique topredict offender age structure learn part concentrate extract dependency data actually present data generate process obviously many bivariate dependency may found via sta tistical test subset present data generate process like identify structural form joint probabil introduction ity function denotes offender age rp describes variable domain approach know unsupervised learn machine learn literature ripley second part concentrate supervise learn like infer knowledge value observe information crime scene add information prediction model obtain prediction offender age obvi ously model learn facilitate prediction furthermore prediction limit variable deduce crime scene limitation would obstruc tive structure learn part need include relevant factor observe actual structure however factor may hidden police criminal investigation therefore apply realistic approach prediction indetail bn relatedhomicides abnisa dependency variable graph mark intuitive illustration probability function facilitates easy inspection dependency furthermore node may endow local probability function detail variable influence allows statistical inference introduce evidence example trace crime scene may introduce bn set variable value structure local probability function information may pass bn alter local probability function along way effect enter evidence may read alter probability func tions bn may generate via expert knowledge learn data due lack domain knowledge learn structure data combine several learn algorithm final graph ical model subsequent step conduct parameter learn introduction obtain local probability function data supervise learn function approximation found generates prediction prediction differ large extent true value stay useful far pre diction differ true value determine via loss function return indication far two value di verge exist several function approximation predict obvious procedure would consists choose one im ply low loss detailed loss function order model apply successfully new data important ass loss new observation apply therefore cross validation obtain estimate expect loss present performance diverse function approximation accord loss result ing cross validation cross validation also apply identify value tune parameter apply linear regression step procedure ridge regression least absolute shrinkage selec tion operator lasso support vector regression near neighbour regression tree random forest graphical model broadly present distinction fender situation driven crime situation driven crime may characterise offender lack preparation typically tack know victim familiar surroundings offender tends apply blunt force gain control victim show high level forensic awareness hand offender driven crime may identify high level forensic awareness demonstrate offender sophisticated measure apply control victim furthermore graphic model indicates offender likely attack unknown victim unfa miliar surroundings prepare attack prediction result indicate prediction method could introduction enhance criminal investigation large extent whereas sim ple base model entail root mean square error rmse predict log offender age lasso archive model generate rmse value translate decrease average failure predict offender age year year although difference base model best perform lasso significant test level hardly matter criminal investigation gain performance one year much use estimate still imprecise poor performance result may arise two reason firstly information crime scene may sufficient determine theoffender related homicide data may need collect account com plexity arise diverse homicide thesis organise follow next chapter present information criminological theory allows well un derstanding motivation approach unsupervised supervise learn afterwards section report data collection process section explains technique bn ex plain implementation structure parameter learn end section final graphical model discuss section dedicate statistical learn first give detail model selection explain apply function approximation afterwards correspond result discussion thereof follow finally section concludes note criminological theory note criminological theory criminologist often refer call criminal event perspec tive miethe regoeczi analyse crime schematic overview give present three mayor factor influence crime offender victim underlie situ ation whereas offender may thought drive force crime victim also influence action crime scene example victim willingness defend fender lead less fight crime scene furthermore underlie situation described geographical temporal structure exhibit influence crime criminal may want leave current location start assault victim order avoid potential witness geographical influence may affected temporal one example possibility encounter potential witness park may different day time night time event crime scene therefore depend component crime may understood result interaction three component consequently observable variable actual crime arise interaction mention offender obviously exhibit great influenceonthecrime indetail offender first offender need gain control vic tim impose sexual activity victim murder victim offender victim underlie situation crime schematic overview factor influence crime note criminological theory schematic overview structure exploit prediction finally offender may try hide crime hinder disclo sure however form apply offender may interpret expression personal characteristic criminologist therefore assume offender crime scene trace found crime scene offender personality may also deduce crime scene however victim behaviour underlie situation also affect crime consequently trace crime scene know offender characteristic influence crime scene influence may exploit criminal investigation observe information may apply infer characteristic unknown offender procedure present form basic idea offender profile although importance crime scene widely acknowledge clages assumption homology offender characteristic crime scene lack verification alison data data part section appear stahlschmidt data use base upon support german police drew sample sex related homicide inter nal documentation provide access correspond prosecu tor file file count page crime scene report autopsy report psychiatric examina tion offender sentence contain almost essen tial information among example victim injury offender age information contact location although document cover important aspect crime offender characteristic indirect access information crime result distortion obviously police officer arrive crime scene crime commit fore may collect trace crime without observe directly furthermore police judicial system act princi ples importantly trace found crime scene consider genuine seldom sufficient testimony witness offender take account recon struct detail crime study concerned homicide especially statement offender checked trace crime scene may leave room specu lation misinformation require comparable information throughout case therefore prosecutor available empirical analysis comparative text analysis strauss corbin popular technique select infor mation satisfy requirement variable present study result comparative text analysis case however data available information use amount information transfer variable restrict consistent set important factor domain sex related homicide result variable selection guide sociological psychological theory extend bythepolice shands onexperience predominantly soft factor offender disposition commit crime influence action crime scene mokros alison factor measure directly due complexity may express via proxy variable occurrence several offender victim crime scene single crime pose challenge storage analysis correspond data hold serial crime every single crime enters data separately though marked dummy variable information analyse transfer variable focus four main element offender victim underlie situa tion actual offence offender described social psychological economic characteristic furthermore information regard medium term short term disposition commit crime include criminal record preparation commit crime collect information victim widely avail able however indicator social economic status well prior relationship status offender present throughout case underlie situation geographical tempo ral information provide general set crime actual offence split several category first pre attack event regard offender share activity offender victim attack take account afterwards sattackonthevictim differs example time need victim resistance level apply violence result injury include fatal one record sexual activity impose victim observe data finally offender forensic awareness measure broadly di vided activity hide identity activity hide crime detail variable available tausendteufel raterreliability fleiss crimesresult value asseveralfac tor deduce trace alone furthermore high rate miss value accompany relatively low level inter rater reliability raters seem handle vague information differently general data include miss value fleiss meassure inter rater reliability four raters amount percental match overview variable give bayesian network bayesian network part section bayesian network appear stahlschmidt base tausendteufel bayesian network bn may serve three purpose identification anunknown probabilityfunction illustratingit anddrawinginference probability function learn bn data identify correspond pdf domain structure domain know analysis bn may generate expert knowl edge apart identify probability function bn serf node dependency via edge domain structure easily read graphical model finally bn may exploit draw inference graphical structure local prob ability function node describe system cause effect enter evidence node alter probability node bn therefore statistical inference result intro duced evidence may recognise forexam ple wright obtains graphical model crop failure whereas recent example include heckerman applies bn medical diagnosis friedman use bn detect structure biological network criminology bns mark rather new tool especially bns driven data derive ex pert knowledge several statistical technique apply forensic data beauregard however study concentrate davy salfati canter therefore aitken propose application bn derive expert knowledge dag andprobabilityfunc tionsinthenodes bayesian network season sprinkler rain wet slippery bn describe structure five variable thedagrepresentsthe factorise probability function node represent variable domain direct edge represent dependence correspond variable conditional independence vari ables result sparse graph edge persist node point via direct edge towards combination dag local probability function describes possibly causal lations domain therefore facilitates statistical inference via enter evidence bn therefore resembles bayes theorem also calculates posterior distribution local prob ability function enter information prior state bn describes classical example pearl describes artificial system season state ground slippery season directly affect bayesian network use sprinkler summer raise probability rain autumn winter bn account dependency via direct edge use sprinkler observation rain directly influence ground wet consequently state ground determines ground slippery conditional dependence season wet ground account fact although may summer ground wet sprinkler apply simple example illustrates type connection available bn information may transfer across connection serial connection include three variable connect chain season rain wet information may pass accordingly edge direction knowledge season influence probability rain information lead date probability wet floor example illustrates causal reason however information may also follow diagnostic reason contradict edge direction know floor wet alters probability rain notice rain fluence probability winter serial connection edge direction may show cause affect effect however formation flow limited direction hold diverge connection diverge connec tion node point via direct edge two variable information may transfer either direction observation rain influence probability season however update probability season also influence probability use sprinkler observe rain rise probability winter winter lower probability use sprin kler observe value variable middle serial diverge connection block information flow knowl edge season longer affect probability observe bayesian network wet floor know rain furthermore observe season block information flow diverge connection sprinkler season rain observe rain longer affect probability use sprinkler know winter converge connection also call collider follow reason type connection two non adjacent node point via direct edge node sprinkler example node sprinkler rain point node wet know summer block dependence sprinkler rain however wet floor observe therefore node middle converge connection know information one end connection may influence path open knowledge summer block diverge connection rain season sprinkler observe state floor state rain influence state sprinkler observe wet floor knowledge rain affect probability sprinkler use information wet floor rain low prob ability use sprinkler two independent variable may become dependent via third variable berkson bns offer several advantage analysis forensic data describe structure pre specify domain hence building bn mainly data may use learn structure unknown domain certain type homicide furthermore bns may also employ prediction prediction offender age could example obtain enter evidence found crime scene appropriate bn furthermore crime scene often lack certain information render one course event plausible several compete one nature bn give fact allow inclusion soft evidence bayesian network technique graph define set node set edge connect node lauritzen solely direct edge set edge bn include entry entry todenote direct edge node node undirected edge express entry direct edge node know parent node recursively node say child set parent child node describe adjacency also call neighbour extend adja cency parent child markov blanket specify example adjacency node rain consists parent node season child wet whereas markov blanket node also include node sprin kler constitutes parent node joint child wet descendant de node define child subsequent child order distinguish clearly de scendants non descendant require graph omit circle consequentially structure bn know dag direct acyclic graph skeleton dag without arrow head itincludes several path describe chain node consecutively connect edge chain direct edge point direction know direct path two node point via direct edge node without adjacent collider arises include single collider namely node wet path dag say block set node path collider collider path exit de two disjoint subset separate path block pearl node season slip bayesian network pery separate set sprinkler rain single node wet however node rain alone separate node season slippery direct path season sprinkler wet slippery block probability function random vector rp arbitrary order variable may factorise assume conditional probability variable af fected markov parent pa de scribe subset predecessor shorten pa assumption implies conditional markov parent pa independence non markov parent predecessor pa pa probability distribution function represent dag establish tie probability distribution function graph variable displayed node edge drawn markov parent pa towards child return factorise joint pdf certain inde pendence statement express season sprinkler rain wet slippery season sprinkler season rain season wet sprinkler rain slippery wet draw five node correspond edge markov parent child denote dag bayesian network obtain dag describes probability distribution function graphically en cod dependency distribution edge however probability function allows factorisation accord relative dag may call markov compatible dag describes call perfect map consequence conditional independence probability function infer separation compatible graph lauritzen necessary sufficient condition markov compatibility call local markov condition require every variable may independent non descendant conditional parent lauritzen form perfect map may still obtain valuable approximation detail must met two requirement described perfect map correctness completeness de andx withcorresponding node correctness respect define completeness respect may deduce correct graph contains separation independency pdf separation complete graph mirror dependency pdf correct complete graph describes perfect map correspond pdf correct graph also know independence map map complete graph may also call dependence map map several dag may exist markov compatible dis tribution correspondingly member equivalence bayesian network class equivalence class characterise skeleton set collider across member whereas direction non collider edge differs across dag equivalence class vermaandpearl limited find correspond equivalence class graph may drawn complete partially direct acyclic graph structure learn structure learn refers identify edge graphical model assume data model sparse bn subsequent step parameter learn endows node lo cal probability function order transfer dag bn space dag grows exponentially number variable chickering show find correct struc ture bn np complete still several heuristic idea exist obtain structure observational data classify constraint base score base hybrid approach constraint base approach infer existence edge conditional inde furthermore repeat application independence test inhibits statement unknown li wang developed constrain base power disclose exist edge hand score base method return dag posse high score among consider dag apart choose appropriate score algorithm artificially narrow search space order stay usable large data set finally hybrid method combine element constraint base score base method node consequently direct dependency cor respond variable notoriously difficult constitutes indis bayesian network pensable step reach final structure graphical model evaluation step compare error rate across diverse algorithm predict variable turn fea sible option optimise prediction model may resemble exist dependency independency data generate pro ce meinshausen bu hlmann furthermore available data limited much potential edge ob servations variable would lead complete graph undirected edge existence determine analyse ob servations case require well know structural learn algorithm zuk number potential edge bn grows expo nentially number variable robinson although observation variable considerably few observation potential edge situation lead realm address combine several algorithm find edge persist throughout result graph apply combinatorial approach loosely related en semble learn detail apply different structure learn algorithmstothedata describ ji ing edge include bn result algorithm combine indicator ed via committee rule ji edgen ed ji denotes indicator function edgen determines clusion edge final graphical model show consequently edge include detect least one single algorithm obviously stricter committee rule lead sparser combine graph edge found several sin bayesian network gle algorithm persist meinshausen bu hlmann propose related approach structure learn generates variation sub sample via application single penalize structure learn technique sub sample allows false discovery con trol final result apart inclusion edge also report thisfrequency edfre ed ji determines thickness edge combine graph instead decide result via committee rule graph offer displayed frequency edfre degree confidence existence edge guide result discussion graph algorithm weapplytwoscore basedalgorithms fiveconstraint basedalgorithms one hybrid algorithm description thesis restrict obtains undirected skeleton refrain give detail algorithm orientate edge two reason firstly examine observational data may lead observe skeleton collider edge direction may deduce observational data alone sec ondly algorithm restrict analysis find call partially direct acyclic graph edge direction across algorithm contradict therefore restrict analysis detail algorithm set orientation may found quote literature plain hill climb greedy search algorithm heckerman selects bn maximises score criterion step iterative process algorithm evaluates bayesian network feasible step executes step improves score stop improvement score exceeds threshold start random structure edge algorithm may add edge erase edge change edge direction find action implies large increase score reiterates hill climb algorithm algorithm may stop local maximum fail transcend plateau score function sparse candidate algorithm friedman also relies score measure present final bn limit number possible step point iteration pre processing step selects set potential markov parent every variable thereby limit number po tential bn structure subsequently evaluate score potential markov parent chosen via mutual infor mation however restrict set markov parent may result suboptimal score algorithm therefore reiterates procedure choose set potential markov parent information utilised generate bn bn present set markov parent every variable set po tential markov parent modify accordingly afterwards modify set employ generate new bn process reiterate convergence pc algorithm sprite minimise score generates bn via independence test form constraint base algorithm start complete graph ev ery edge test conditional set neighbour test negates edge existence directly remove therefore set neighbour reduce algorithm reiterates per sisting edge increase every iteration set neighbour start empty set increase set neighbour use independence test one node contains neighbourhood large set condition bayesian network three phase dependency analysis algorithm cheng pass three phase firstly mutual infor mation calculate every possible combination two vari ables correspond path include model whenever secondly direct edge include two variable whenever mutual information exceeds threshold mutual formation condition set direct neighbour two variable path two variable lastly reduction phase execute rechecking mutual information two directly connect node conditioning set direct neighbour path two variable hiton parent child algorithm aliferis divide two step every variable set potential neighbour construct variable admit set maximise measure association conditional actual state set potential neighbour reduc tion step association every potential neighbour variable examine conditional final set po tential neighbour potential neighbour exclude completingthislast step result set direct neighbour every variable information may exploit construct bn grow shrink markov blanket algorithm margaritis thrun may also classify constraint base ap proach concentrate entirely detection markov blanket every variable base upon information gen add every variable variable set long variablesdon giventhepresent state test variable set mark bayesian network terim selection markov blanket subsequent shrinkage phase algorithm retests independence single variable give variable whichforms themarkovblanketofx constitutes direct neighbour separate parent joint child independence test give subset markov blanket incremental association markov blanket algorithm tsamardinosetal ket combine single markov blanket bn ba sically follow grow shrink markov blanket algorithm blanket afterwards repeat independence test exclude variable admit erroneously however contrast previous algorithm include variable set potential markov blanket accord strength mutual information tual information second variable admit contains grow long pass independence test account strength dependence max min parent child algorithm tsamardinos aim find direct neighbour variable parent child build candidate set find subset every potential candidate minimises mutual information include variable show high mutual formation obviously name min max originates procedure first tire minimise association minimise association chooses maximal one af ter grow phase subsequent shrink phase attempt bayesian network exclude erroneously add candidate therefore subset search render potential candidate markov blanket independent direct neigh bours determine bn may generate algorithm determines orientation edge via hill climb last step make max min parent child algorithm hybrid algorithm employ mutual information inde pendence test generation skeleton afterwards refers score metric orientate edge parameter learn parameter learn describes endowment node bn probability function conditional markov parent de cided neighbour actually parent neighbour child variable skeleton transfer dag pearl verma pearl proposes follow rule transfer skeleton dag pair nonadjacent variable common neighbour test separate collider may drawn neglect set direction undirected edge edge adjacent set direction undirected edge chain set direction undirected edge two chain adjacent set direction undirected edge chain adjacent adjacent bayesian network whereas first rule result partial direct acyclic graph pdag meek show repeat application rule generates correspond maximally direct pdag maximal direct pdag may transfer dag ori acyclic character graph procedure may encourage fact information may flow accord edge direction contrary edge direction however randomly set direc tions may contradict domain knowledge alternative set edge result orient edge markov parent every vari bility function may learn available data two approach maximum likelihood estimation bayesian estimation numeric nominal data restrict analysis maximum likelihood approach nominal data characterises data maximum likelihood approach discrete data make use two feature firstly general likelihood function decompose product independent local likelihood function secondly tabular probability function local likelihood function may solve efficiently via sufficient statistic start general likelihood function first demonstrate decompose af terwards derive actual maximum likelihood estimate via sufficient statistic xp pa pap variable correspond markov bayesian network parent pa pa pa may decompose pa xp pap factorization probability function structure bn rewrite pa xp pap equation state via definition likelihood local pa rameters xp pap pa xp pap xp pap product local likelihood function xp pap uct independent local likelihood function facilitates maximisa tion local likelihood function may maximise independently solution combine reveal general maximum likelihood estimator local likelihood function may rewrite sufficient statis tic pa pa pa denotes often combination specific value pa variable andpa ables pa combination defines length may factorise local likelihood xp pap xp pap xp pap xp pap pap papxp xp bayesian network constraint sum refers xp pap value pa obtain familiar estimate pa pa xp pap pa pa parameter estimate specific value pa pa may obtain value pa observe xp pap result vector length pa denote parame ter estimate combination nominal variable markov parent pa obtain parameter dag turn dag bn may analyse enter evidence node observe ev idence refers set node specific value observe effect via inference algorithm although mechanism may ex define adjust probability variable observe conse quences restrict analysis bn dag structure two reason firstly due low number obser result bn probability distribution remain informa tion test set second enter fictive simulated data bn help assess value real data therefore restrict analysis dag implementation generate final graphical model apply several structure learn algorithm data combine result graphi cal model single skeleton grow shrink markov blanket incremental association markov blanket max min parent chil dren hill climb algorithm obtain im plementation package bnlearn scutari sparse bayesian network candidate pc three phase dependency analysis hiton gorithms use via implementation matlab package causalexplorer aliferis apply two different constraint base algorithm bnlearn implement test however expect difference test result great importance furthermore apply package pcalg kalisch bu hlmann direct edge joint graph set bayesian information criterion schwarz score nificance level independence test use constraint base algorithm miss value treat via multiple imputation detail use chain equation base gibbs sample implement package mouse van burren groothuis oudshoorn use five imputation join diverse graph firstly gorithm level obtain final graph algorithm edge ical model respective algorithm afterwards graphical model eight algorithm joint final graphical model present result application algorithm data yield several distinct graph combine graph single one edge thickness determine often edge found across algo rithms indicates confidence actual dependence correspond variable data generate process omit result edge direction concentrate skeleton bayesian network segde fo ycneuqerf algorithm indicate edge bar chart state many algorithm indicate edge frequency edge algorithm agree uniformly edge direction however nearly direction may deduce sociological psycholog ical theory may examine via cross present result graph consists node edge single algorithm find edge completely agree edge bar chart frequency edge one algorithm agree uponisgiveninfigure maximal size adjacency final graph whereas single algorithm provide adjacency large graph considerably sparse take account maximum poten tial edge could arise variable graph may interpret show plain topology bayesian network alcohol consumption victim brute force alcohol consumption offender serial crime sadism enquiry period suffocation without implement age offender sadistic offender preparation offender active resistance forensic awareness tie victim excerpt show variable mark difference offender situation driven crime extensively organise offender offender lack organisation mixture type ressler however categorisation criticise focus solely offender consequently enlarge criminal event perspective miethe goeczi theory stress influence victim underlie situation crime thereby illustrates example well prepared offender may also show chaotic behaviour face unforeseen obstacle approach broadens perspec tive analyse crime adapt include several variable describingthevictim trated hence interpretation graph account extend perspective start node preparation offender define level preparation gain control victim hide weobserve edge thenode bayesian network may locate fourth row right low centre emerge edge node preparation offender edge towards node sadistic offender stick thickness state node define sadistic action offender crime include node sadism graph examine correspond mosaic plot show may conclude sadistic offender much likely behave sadistically show serial crime often non sadistic offender node se rial crime dummy variable indicate specific crime part wider series exhibit profound edge offender age enquiry period serial criminal usually belong age group apart sadistic offender serial criminal mark sec ond ideal example offender driven crime hand situation driven crime crime show low level sadistic serial criminal rather display strong influence preparation offender node alcohol consump tion offender negative interaction expand node alcohol consumption victim state victim con sattack offender victim voluntary offender tack engage drinking often either victim offender consume alcohol often lead situation driven crime neither victim offender consume alcohol characterises offender driven crime detail may found present apart alcohol situation bayesian network gain maintain control victim graphical model illustrates interaction edge alcohol consumption offender node brute force reflect injury victim due application blunt force serial criminal high level preparation generally rely blunt force apply sophisticated measure control victim negative interaction read mosaic plot correspond edge brute force serial crime inal driven crime described edge preparation offender node tie victim node indicates victim tie offender correspond cross reveals offender characterise high level preparation likely tie victim furthermore offender suffo cate victim less often hand highlight cross correspond edge preparation fender suffocation without implement general criminal high level preparation apply instrumental mode gain maintain control whereas low level preparation lead expressive crime offender likely applies blunt force however likelihood suffocation offender rise case whenever victim strongly resists attack general influence victim crime specify edge node suffocation without implement active resistance active resistance define resist assault physically try escape call help crime level plan carry criminal behaviour high level plan accompany high level forensic awareness forensic awareness describes measure hide crime example use glove cleaning crime scene ward correspond node forensic awareness connect bayesian network enquiry period offender victim relationship distance hub contact location contact location forensic awareness different assault location movement corpse excerpt show geographical variable ad jacency mark difference offender situation driven crime node preparation offender highlight positive interac tion correspond mosaic plot provide node forensic awareness link degree planning fender certain geographical characteristic crime node may found third row right left firstly criminal show high level forensic awareness likely hide corpse separate location serf solely purpose complicates pro ecution interaction reflect edge forensic awareness movementofcorpse furthermorethenode foren sicawareness contactlocation thisnode victim assault distinguishes location indoors victim flat offender flat share flat loca tions outdoors bayesian network correspond mosaic plot reveals offender less likely show high level forensic awareness contact take place familiar surroundings share flat contrary offender meeting victim rather unknown sur round like victim flat location outdoors show high level forensic awareness correspond crime therefore likely offender driven node contact location exhibit profound edge node offender victim relationship de tail pre attack relationship offender victim examine correspond cross reveals contact tween offender unknown victim mostly establish door whereas offender meet know victim rather indoors ness outdoors contact offender unknown victim may attribute offender driven crime whereas indoor contact exhibit characteristic situation driven crime likely include victim know offender offender meet ing victim familiar surround obviously travel great distance personal hub contact location hub define location offender perfectly familiar flat work place graph therefore include edge two node furthermore node distance hub contact location connect node enquiry period correspond mosaic plot detail great distance offender personal hub contact location complicates pro ecution enquiry period rise general may conclude differentiation offender driven crime situation driven crime carry geographical variable well organise offender meet victim general familiar surround rather travel bayesian network longer distance hide corpse separate location impede exposure crime less organise offender meet victim likely know rather familiar surroundings travel great distance furthermore show high level forensic awareness hide corpse separate lo cation however actual crime solely influence criminal examination edge node contact location different assault location depicts injustoverhalfofthe crime ensue attack conduct different location offender may feel confident contact location outdoors allows conduct crime therefore force change location change location occurs less quarter crime contact location indoors provide correspond mosaic plot statistical learn statistical learn statistical learn may divide unsupervised supervise learn unsupervised learn refers infer information rp andbnsareone apply method unsupervised learn supervise learn refers predict response variable via predictor data set predictor correspond response gather approximation function governs lationship predictor response variable real look regression task nominal ordinal deal classification task hastie regression task characterise adaptive error ex pectation variance var square error loss function optimal functional approxi mation conditional expectation also know regression function want infer function training data set may chose function passing training point obviously function perform well new un see data point search space must therefore restrict promising function generalise well new data restric parameter degree model adapts spe cific characteristic training data often accomplish impose regular behaviour small neighbourhood input space however number predictor grows curse dimensionality affect approach constitute obstacle statistical learn model selection natural choice model predict offender age apply several model choose best one among decide best one via loss function describes far prediction true value offender age mark response variable like predict via predictor rp prediction model arises analysis training set govern unknown joint probability function typical choice loss function consists square error return loss quadratic term popular choice clude absolute loss loss classification task loss function hand one may compare fit value actual observation err statistic describes training error may decrease increase model complexity model exploit formation training data set large extent adapts specific structure data sample model may charac terised small bias large variance generalise well new data tie specific form model close available training data set overfitting occurs train model fails predict unobserved observation call test error measure prediction performance model observation include training data set therefore new model errt statistical learn pair refer random draw population indicates model set via explore training data therefore mimic error rate one would expect set model specific training data set observe prediction performance new observation expect test error err errt average test error training data set therefore elimi nates influence training data set model analyse well model build specific training data set performs new data serf however illustrate effect sgeneralisation performance assume additive error model var apply square error loss function expect test error may broken element bias var irreducible error bias variance increase model complexity low bias increase variance optimise training error strong adaption training data set result high model complexity high variance low bias model therefore show decreas ing prediction error training data set perform poorly new observation prediction performance model optimise test error also start improve model complexity increase however reach minimum thereafter predic tion performance start decrease optimal model apply right amount model complexity reach minimum test statistical learn error minimum also hold new observation follow definition test error one could set apart chunk training data obtain test error apply model obtain without chunk data separate observation butdataonsex exclude valuable observation model building process therefore apply cross validation obtain indication model performance divide training data set folder build model exclude one prediction performance model afterwards evaluate data observation folder repeat process every ten folder return cross validation estimate prediction error cv describes index function splitting training data set folder denotes model generate without part training data although cross validation feasible approach obtain prediction error without exclude data observation model process come cost cross validation estimate prediction error estimate expect test error actual test error define apply cross validation therefore trade use whole training data set imprecise estimate test error apart obtain estimate test error cross validation may also serve determine value tune parameter value tune parameter chosen optimise predic tion performance parameter may include calculation prediction error cv statistical learn denotes model obtain set spe cific value cv report estimate prediction error may chosen minimise technique linear regression simple linear model assumes regression function linear predictor rp assumption may justified describ ing reasonable approximation true model mayor benefit dictors influence response variable model may denote parameter describes influence variable theresponsey term least square residual sum square describe well model fit data square term min imised choose appropriate value unique solution give apart form least square criterion solution may also obtain via maximum likelihood estimation approach deter mine appropriate parameter value via likelihood function indetail tion log transformation log case linear statistical learn model result log likelihood function log log maximise log likelihood function parameter affect last term first two term include pa rameters last term equal statistic minimise least square scalar multiplier highlight connec tion two method linear model general application least square linear model additive error error distribute result parameter value application maximum likelihood gaussian conditional likelihood spirit machine learn technique apply section generate linear model via automatic model selection process detail apply aic criterion akaike stepwise selection procedure simple model constant bound search space start random model step variable add clear form list predictor aic criterion improve step variable add clear active predictor list one result high improvement aic criterion point iteration result give ridge regression either include variable set predictor clean list active predictor mark discrete process often ac companied high variance therefore dissatisfy prediction statistical learn estimate std error value pr intercept gefaengnisvor normnein tv sozsit knein tatalter toi krim spur kondnein toie dauer kue xu zerlaubnisnein xu zlistnein toit sex mannein spurendnanein loksons tatorte drinnen xl vgeschlecht norm nein xl spositionnein xl vextremitaeten norm nein coefficient standard error value grade stepwise procedure generate linear model variable name explain performance shrinkage method like ridge regression lasso mark continuous process therefore exhibit less variance ridge regression hoerl kennard shrink regression coefficient impose penalty size detail pa rametervalues ridge term ridge arg min np parameter control amount shrinkage mark tun ing parameter determine via cross validation large value statistical learn decrease parameter value ridge coefficient shrunken towards zero towards ridge regression may classify proportional shrinkage method small principal component shrunken large extent large principal component reason behind behaviour ridge regression lie assumption response variable vary direction high variance predic tor vary less direction small variance predictor apply strong shrinkage small principal component ridge regression decrease noise result low amount data small principal component rewrite residual sum square criterion matrix form solve actual parameter value ridge may deduce ridge notation may observe positive constant add diagonal facilitates inversion even may singular main motivation ridge regres sion present report coefficient ridge prediction model log offender age standard error report bias ridge regression integral welcome part model lasso lasso tibshirani also applies penalty penalty however isal correspond parameter value lasso detail parameter statistical learn estimate normnein tv sozsit knein tatalter toi krim spur kondnein toie dauer kue xu zerlaubnisnein xu zlistnein xu zoffentlichnein toit sex vaginalnein toit sexnein toit sex mannein spurendnanein spurenpersdingenein loksonstige tatorte drinnen lokwohnung taeter loksonstige tatorte draussen lokwohnung taeter loksonstige tatorte draussen loksonstige tatorte drinnen kungleichunein ort fallgemischt xl vgeschlecht norm nein xl spositionnein toi enteigennein xl vextremitaeten norm nein regression coefficient result ridge regression variable name explain statistical learn value solution lagrangian form lasso arg min np lem solution determine numerically penalty may also denote lasso translates coefficient constant factor truncat ing zero therefore sufficient small value set coefficient zero perform thereby subset selection hand choose result shrinkage coefficient lasso differ ordinary ols coefficient set shrink least square coefficient average obviously size peanlty denote rewrite tune parameter may determine via cross validation report coefficient lasso prediction model log offender age regression tree tree fit simple model example constant simplify generation tree usually recursive binary parti tions apply feature space consequence partition feature space may drawn binary tree facilitates tree one rectangle may inspect follow path tree furthermore draw divide feature space statistical learn normnein tv sozsit knein toi krim spur kondnein xu zerlaubnisnein xu zlistnein xu zoffentlichnein toit sex vaginalnein toit sexnein toit sex mannein spurendnanein loksonstige tatorte drinnen kungleichunein xl vgeschlecht norm nein xl spositionnein xl vextremitaeten norm nein regression coefficient result lasso variable shrunken zero omit variable name explain feasible low dimensional feature space whereas tree imply limit generate regression tree follow cart approach breiman first feature space split two region mean response variable every region report model response variable split split point chosen archive best model fit afterwards two separate region split process continue statistical learn stop criterion fulfil general model may denote mi number separate region feature space observation fall region algorithm generate partition feature space must decide variable split point split set sum square willequaltheaverage every region ave via greedy algorithm describe pair half plane splitting variable split point chose splitting variable split point minimise min min min xi xi value solve via ave value respectively apply greedy algorithm scan combination find best pair step found pair repeat splitting process sepa rat region obviously repeat process often generate overfitted tree small tree may ignore important structure correspond tree size serf tune parameter deter mining model complexity determine optimal tree size via cost complexity prune minimise cost complex criterion statistical learn describes number terminal node denotes number observation fall partition featurespaceandq describetheaverage nm xi rm asubtreet minimisesc every tune parameter determines trade goodness fit tree size every unique subtree may obtain via weak link prune start exces sively grown tree weak link prune determines internal node result small per node increase sum square statistic collapse node repeates proce dure root tree emerges sequence subtrees contains sought tree ripley optimal may chosen via cross validation method generates purpose tree near neighbour near neighbour technique cover hart describe powerful yet simple technique classification regression though may result low error rate give classi fication problem usually routinely report bayes error rate asymptotically amount half error rate near neighbour classifier therefore roughly indicates optimal low bound niques technique also differs memory base major model decision involve definition distance tween observation feature space however due characteristic necessary include whole data set analysis new observation may become challenge high dimensional setting give new observation near neighbour compiles distance new observation statistical learn normnein tatalter toit sex mannein toie dauer kue xl spositionnein tatalter regression tree prediction offender age variable name explain training data set selects near neighbour aver age deduce among value response give model response denotes near neighbour accord employ distance metric parameter describes tune parameter gov smallvalues result low bias high variance actual value certain data set may deduce via cross validation statistical learn numeric predictor rp euclidean distance new observation training observation would natural choice distance metric random forest randomforrest breiman correlate tree bootstrap sample data model response constitutes simple average across tree sation parametrisation include split variable split ting point value terminal node single tree generate bootstrap sample data technique constitutes modification bagging breiman tree correlation tree reduce min imise variance predictor sufficiently deep grown tree incorporates low bias high variance however tree random forest optimise bootstrap sample data identically distribute expectation average tree expectation single tree consequently bias affected grow large number tree hand forest result well prediction detail observe identically distribute variable variance pairwise correlation theaverageoftheseb var ave statistical learn increase lead decrease second term whereas first term may tackle reduce pairwise correlation random forest lower correlation tree choose set predictor random admits subset pre dictors candidate splitting variable candidate tree therefore serf tune parameter may resolve via cross validation algorithm firstly generates large number bootstrap sample forexampleb prune stop minimum node size reach difference section regression tree node variable select random candidate splitting vari ables term reduce sum square best variable accord splitting point chosen among procedure withparameters whichvary across tree bootstrap sample data random selection variable splitting node every new observation pass single tree average single tree grown bootstrap sample data ev ery observation use generation single tree prediction power tree may test observation use grow process error also know bag oob error cross validation predicts test er ror random forest oob error may exploit gain knowledge variable importance information variable effect prediction accuracy detail grown tree random forest oob sample pass tree prediction error record afterwards value variable permute oob sample therefore statistical learn normnein toit sex mannein xu zlistnein xl spositionnein toie dauer kue xu zerlaubnisnein tatalter xu zoffentlichnein tv sozsit knein spurendnanein loksonstige tatorte drinnen ort fallgemischt kungleichunein loksonstige tatorte draussen loksonstige tatorte draussen xl vgeschlecht norm nein toi krim spur kondnein spurenpersdingenein toit sexnein toit sex vaginalnein xl vextremitaeten norm nein lokwohnung taeter loksonstige tatorte drinnen toi enteigennein lokwohnung taeter variable importance random forest concern mse increase permutation value divide standard error variable name explain thismodifiedoob sample pass tree difference predic tion accuracy indicates importance variable value importance sample data set analyse thesis give statistical learn support vector regression vapnik vector machine classification prediction real response vari able also incorporates margin predictor may also mapped feature space however support vector regression observation outside margin add cost whereas support vector machine classification observation outside margin matter prediction slack variable wrong side linear decision boundary add cost role margin support vector regression originates apply insensitive loss function otherwise describes threshold denotes difference true value fit value support vector regression search prediction function deviation true observation training data time minimises complexity simple linear model denotes dot product translates minimise euclidean norm result optimization problem min allow error include slack variable whichequi librates complexity allow amount deviance statistical learn optimisation may solve easily dual formulation purpose specify lagrange function lagrange multiplier settingr partial derivative primal variable zero rear range term via substitute yield dual optimisation problem max solve dual optimisation problem facilitates support vector expansion predictor function detail set partial derivation primal optimisation equal zero result expression apply expression linear model obtain constant may deduce exploit karush kuh tacker condition value may derive statistical learn equation denotes call support vector expansion describes linear combination training data however due constrains value nonzero corre sponding observation denote support vector complexity function representation support vector independent dimension depends limited number support vector furthermore support vector expansion relies dot product data point kernel trick may therefore ap ply transfer data high dimensional feature space prediction accuracy may enhance may mapping obser vations feature space via function conduct support vector regression feature space ever ofsomeveryhigh dimensional vector may unfeasible obtain acceptable time frame kernel trick need actually compute mapping feature space explicitly solution stem fact certain kernel func tions express inner product vector high dimensional space thesis hand radial basis kernel func tion exp apply solve support vector regression implementation apply several prediction method data order predict offender age information obtain crime scene furthermore limit set predictor information could statistical learn obtain criminal investigation obviously may variable ap ply generation bn hidden police criminal investigation rely thereby several package regression tree cal culated via package rpart therneau atkinson random forest via randomforest liaw wiener rely near neighbor implementation caret pack age kuhn support vector regression calculate gaussian radial basis kernel implement kernlab karat zoglou simple linear model generate via package mass venables ripley penalize version via penalize goeman foldcross parameter observe prediction error response variable real search low root mean square error rmse decide tune parameter every model furthermore peat cross validation time observe distribution rmse vary allotment observation folder cross validation approach allows report box plot final result instead single rmse process make sure every model obtains folder ensure differ ences rmse arise difference model arise allotment observation folder procedure facilitate package caret kuhn package mouse van burren groothuis oudshoorn statistical learn result compare evaluate root mean square error rmse derive cross validation every model furthermore gener ate base line model adopts simplest approach pre diction model response constitutes sample mean without rely information provide predic tor mean age offender data year simple prediction method result rmse predict log offender age prediction method incorpo rating information predictor outperform prediction result present draw box plot result repeat cross validation order model accord prediction performance small rmse predict log offender age furthermore present actual difference model highlight cell report significant difference report test significance level expect base model performs bad term mean however regression tree exhibit large variance across cross validation perform much bad base model par best model high variance typical behaviour tree one reason create random forest next model near neighbour performs marginally bet ter base model regression tree significant difference three model poor performance near neighbour surprising however behaviour probably tween observation predictor nominal type statistical learn tree knn rf lmstepaic svr ridge lasso base tree knn rf lmstepaic svr ridge sig nificant difference level highlight grey background colour wedon near neighboursto large extent model perform equally well exemption ran dom forest exhibit significant bad performance best performer ridge regression lasso see fig ure variance random forest decrease large extent compare single regression tree also average performance random forest outperforms single regression tree sig nificantly although random forest consists single tree restrict choice optimal variable every node aggregation weak learner exhibit well result single opti mized one implementation support vector regression significantly deviate performance best mod el performance however depends chosen kernel function optimise kernel function example polynomial kernel perform well implement gaus sian radial basis function statistical learn linear model however perform best predict offender age even simple linear model optimise via aic criterion deviate significantly complicate penalize model lasso outperforms model although perfor mance ridge regression hardly distinguish lasso linear model quite restrictive assumption elaborate linear relationship predictor response variable case model mark oversim plification model able incorporate nonlinear relation like random forest support vector regression outperform data set however linear model perform reasonable well data set training small sparsity arises data exhibit low signal noise ratio observation predictor analysis may characterise excessive amount data include reasonable amount observation good performance linear model arise due sparsity low signal noise ratio observe difference rmse result compare base line model lasso note increase rather mi base model exhibit rmse whereas lasso lower value perform analysis untrans form response variable offender age result increase one year base line model include rmse year whereas lasso increase performance year although significant increase term test hardly matter practise prediction model help police catch offender average prediction model prediction year may two reason lack performance firstly information drawn crime scene may include lot information offender age therefore model fail secondly poor performance may result lack data statistical learn sex related homicide rather broad term include many different assault data would necessary account hetero geneity however explain begin data sex related homicide hard obtain may infeasible obtain data set large enough predict offender age reasonable well discussion discussion sex related homicide arise wide medium coverage therefore extent pressure police catch responsible offender although case resolve rather quick police employ several spe cialists offender profile expert analyse crime scene carefully try recover happen crime scene great detail possible draw conclusion offender char acteristics knowledge gain crime scene however sex related homicide occur infrequently heterogeneous character therefore knowledge drawn empirical analysis lack thesis hand therefore try contribute back ground knowledge concentrate offender age know approximate age unknown offender constitutes valuable information criminal investigation number potential suspect strongly reduce information apply two different approach firstly general structural learn ing approach without special emphasis offender age sec ondly deliberately try obtain precise estimation fender age evidence found crime scene structural learn approach base graphical model make use bn learn final graphical model apply several structure learn algorithm data algorithm present slightly different bn combine bn single graphical model edge thickness describes often edge found across algorithm number indicates level confidence ac tual existence dependence correspond variable second part thesis apply supervise learningin order predict offender age apply several model namely linear regression step procedure ridge regression lasso regression tree random forest near neighbour support vector regres sion optimise every model obtain optimal value discussion correspond tune parameter indicate fold cross validation cross validation also indicates performance every model new data use result expect test error rank model bn indicates two type crime offender driven crime situation driven crime situation driven crime offender gain control victim offender act familiar surround ings probably know victim offender driven crime ings victim know however may case fit two class apply prediction technique differ performance regressiontreesandk nearestneigh bour significantly deviate simple base line model whereas application model improve predic tion criterion significantly whereas poor performance regres sion tree may explain high variance performance near neighbour somewhat surprising however probably result apply distance metric fit data well model perform similarly although random forest bad application lasso result best prediction performance however actual increase perfor mance comparison simple base line model small translates average error year instead year base model result decrease one year suffice adopt data driven prediction approach criminal investigation may worth note attempt predict geographi cal distance crime scene offender personal hub variable also succeed gain acceptable performance although present detail like report discussion simple base model result rmse km whereas application near neighbour result rmse km may two answer poor performance predic tion method firstly data might necessary sex related conclude evidence crime scene suffice assure data driven prediction offender age geographical distance aitken gammerman zhang connolly bai ley gordon oldfield bayesian belief net work application specific case analysis computa tional learn probabilistic reason ed gammerman chichester wiley akaike new look statistical model identification ieee transaction automatic control aliferis tsamardinos statnikov hiton novel markov blanket algorithm optimal variable selection proceeding american medical informatics association annual symposium aliferis tsamardinos statnikov brown causalexplorer toolkit biomedical discovery proceeding interna tional conference mathematics engineering technique medicine biological science alison bennell mokros ormerod personality paradox offender profile psychology public policy law beauregad role profile investigation sexual homicide sexual murderer comparative analysis new perspective ed proulx beauregard cusson nicole chichester wiley berkson limitation application fourfold analysis hospital data biometrics bulletin breiman bagging predictor machine learn breiman random forest machine learn breiman friedman olshen stone classifi cation regression tree new york wadsworth van buuren groothuis oudshoorn mouse multi variate imputation chain equation journal statistical software forthcoming cheng greiner kelly bell liu learn bayesian network data artificial intelligence journal chickering learn bayesian network np complete learn data artificial intelligence statis tic ed fisher lenz new york springer clages erster angriff handbuch der kriminalisitk ed ackermann clarges roll stuttgart richard boorberg verlag cover hart near neighbour pattern classifica tion ieee transaction information theory davy specific profile analysis data base approach offender profile offender profile theory research practise ed jackson bekerian chichester wi ley dern fr ond straub vick witt geogratisches verhalten fremder ta ter bei sexuellen gewaltdelikten wiesbaden bka fleiss measure nominal scale agreement among many raters psychological bulletin friedman linial nachman peer use bayesian network analyze expression data journal com putational biology friedman nachman peer learn bayesian network structure massive datasets proceeding fif teenth conference uncertainty artificial inteligence goeman hazard model biometrica journal hastie tibshirani friedman element statistical learn new york springer heckerman learn graphical model ed jordan dordrecht kluwer heckerman probabilistic similarity network network hoerl kennard ridge regression bias estimation nonorthogonal problem technometrics jensen introduction bayesian network new york springer kalisch bu hlmann estimate high dimensional algorithm journalofmachine learn research karatzoglou smola hornik andzeileis kernlab an kuhn buuilding predictive model use caret package journal statistical software lauritzen dawid larsen andleimer independence property direct markov field network lauritzen graphical model oxford clarendon press li wang control false discovery rate association causality structure learn pc algorithm journal machine learn research liaw wiener classification regression randomforest news margaritis thrun bayesian network induction via local neighborhood advance neural information process ing system ed solla leen mu ller cambridge mit press meek causal inference causal explanation back ground knowledge uncertainty artificial intelligence ed besnard hank san francisco morgan kaufmann meinshausen bu hlmann high dimensional graph variable selection lasso annals statistic meinshausen bu hlmann stability selection jour nal royal statistical society series miethe andregoeczi rethink homicide new york cambridge press mokros alison offender profile possible legal criminological psychology pearl causality new york cambridge press ressler burgess douglas sexual homicide new york lexington book ripley pattern recognition neural network cam bridge cambridge press robinson counting unlabelled acyclic digraph lecture note mathematics combinatorial mathematics hei delberg springer salfati andcanter profile offender characteristic behavioral style behavioral scinces law schwarz estimate dimension model annals statistic learn bayesian network bnlearn package journal statistical software sprite glymour scheines causation predic tion search cambridge mit press stahlschmidt tausendteufel ardle bayesian network sex related homicide sfb discus sion paper universit zu strauss corbin basic qualitative research thousand oak sage publication tausendteufel stahlschmidt ku hnel bestim mung de ateralters bei sexuell assoziierten otungsdelikten auf der basis von wiesbaden bundeskrim inalamt therneau atkinson introduction recursive partition use rpart routine technical report mayo clinic section statistic regression shrinkage selection via lasso journal royal statistical society series tsamardinos aliferis statnikov algorithm large scale markov blanket discovery th international flair conference tsamardinos brwon aliferis max min hill climb bayesian network structure learn algorithm machine learn vapnik nature statistical learn theory new york springer venables ripley modern apply statistic new york springer verma pearl equivalence synthesis causal model proceeding sixth conference uncertainty artificial intelligence verma pearl algorithm decide set observe independency causal explanation proceeding eighth conference uncertainty artificial intelligence wright correlation causation journal agricultural research zuk margel anddomany inuai sadistic offender sadistic offence yes yes seyon redneffo redneffo yb noitaraperpredneffo citsidas sraey serial crime serial crime yes yes ega dna citsidas htnom rendefforedneffo enondetimilelpma serial crime alcohol consumption offender yes yes doirep yb noitaraperp yriuqne mosaic plot correspond discuss edge alcohol consumption offender alcohol consumption offender yes yes mitciv noitpmusnoc ecrof eturbredneffo lohoclasemirc brute force tie victim yes yes yb lairesredneffo suffocation implement suffocation implement yes yes yb noitaraperp evitca mosaic plot correspond discuss edge forensic awareness forensic awareness ample limited none ample limited none seyonnwonknwonknu redneffo esproc yb fo tnemevomnoitlaer contact location contact location familiar unfamiliar indoors outdoors mitciv cisnerof mk redneffo htnom contact location distance hub contact location km familiar unfamiliar noitacol tcatnoc doirep buh dna yriuqne ecnatsid mosaic plot correspond discuss edge contact location indoors outdoors noitacol seyon tluassa tnereffid mosaic plot correspond discuss edge stca oitallefmitciv dnamedtnemelpmi esruocretni tnemnorivne regnif tnemelpmi esruocretni lanigavdesilanigram detresni ytilibisnopser lanamitciv ytreporp sedicimohdetaler erugif noitpeced redneffo ecneloiv yllaicos tsniaga pu drocer deitpihsnoitaler redneffonoitalosi lanimirc drocer dehsinimid htiw lanimircyrebbor noitacoffusmitciv lanimirc sredneffo fo lasiarppa tnenamrep laicos redneffoesproc redneffo ssenerawa fo lanosrep yb rebmun ecrof laicurcytitnedi tuohtiw fo fo noitnetnimitciv tnemevomnoitacol noitacoffusesproc cisnerofredneffo desiugsidredneffo evitcamsidas redneffo fo noitalupinam citsidaspu kaerb yb eturbdoirep yb noitpmusnoc noitpmusnoc fo xessemirc redneg fo ega fo ega noitacol lohoclamitciv yriuqnetlusni lohocla lairespihsnoitaler noitacovorp esproc tcatnoc buh fo mitciv ytilanoitan etupsid tcatnoc noitacol ecnatsidtaerht htiw esruocretnisecneffo laicnanif noitacovorp noitacovorp tluassa drocer evissap tnereffid lanimirc eertnoisserger ledomesabehtyb egas redneffo erugif snoitubirtsideht ledomraenil tserofmodnar ruobhgien tseraen noitadilav esmr noitacovorp noitacovorp snagrolauxess noitacovorp xesdnamed drocerlanimirc drocerlanimirc elbat buh ecnatsid kaerb noitacovorp drocerlanimirc redneffo elbat kcattas redneffo redneffo elbat redneffo kcattas tiot tiot tafls mronthcelhcsegvlx elbat egas
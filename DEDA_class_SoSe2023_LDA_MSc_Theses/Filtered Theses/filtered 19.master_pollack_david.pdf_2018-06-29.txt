musical genre classification audio musikgattungszugeh rigkeitserkennung master thesis submit prof dr wolfgang rdle prof dr cathy yi hsuan chen school business economics ladislaus von bortkiewicz chair statistic universit zu david pollack partial fulfillment requirement degree master economics management science june th  struggle problem connect second music musical genre since creation music audio data present lot unique problem past solve handcraft feature selection base plethora domain knowledge audio signal processing ever increase compute power audio machine learn move away handcraft feature learn feature representation raw audio signal discus make audio data unique one dealt audio data past future machine learn audio head specifically tackle problem audio classification attempt de termine label label entire clip audio audio realm class problem include audio transcription audio denoising signal separation audio generation technique apply analysis adapt class problem solve classification various network architecture show promising result training data unable achieve desire result validation test set discus many method use attempt combat overfitting conjecture none attempt successful however result achieve accuracy far well random guess many lesson learn apply audio machine learn task code use obtain result paper available via www quantlet de keywords machine learn audio classification musical genre deep learn dilate convolution content introduction background motivation related work dataset methodology procedure resnet resnet attention base rnn bytenet discussion conclusion list spectrogram sample audioset attention base phoneme detection luong shazam spectrogram peak wang th floor block distribution audioset label resnet resnet training validation graph balance set resnet training validation graph unbalanced set resnet training validation graph unbalanced set resnet training validation graph unbalanced set list information google research audioset dataset result introduction problem correctly identify clip audio especially musical audio tale old time one first successful smartphone apps shazam us machine learn identify song title short record song play room december shazam acquire apple report million dollar bloomberg clearly market exists audio recognition technology chosen tackle problem genre classification rather song identification one current copyright law would make impossible acquire enough data build reasonable classifier secondly musical genre classification part whole family cluster problem similar problem field include language identification keyword detection although tend nlp problem seek find generic class rather exactly match one record another record musical genre classification require model generalize feature within sample also across entire genre classification musical genre audio clip many us obviously one tag audio clip musical genre group similar song together recommendation engine another application one could explore find distance measure musical genre similar mikolov do nlp word vec distance similarity measure genre one could easily make recommendation across genre use advanced search do word vec audio generation another activate area research itpresentsit doestheaudio sound natural good unknown output length past month voice generation gotten near human quality skerry ryan several obvious application deep learn audio bring large component nlp want focus specifically audio challenge present rather challenge amplify masked nlp still many preprocessing toolchains algorithm adapt area research machine learn audio data background motivation genesis project stem simple question audio explosion machine learn center primarily around image digital dimensionaltensorof bitunsignedintegers one dimension represent color channel red green blue two dimension represent height width data point represent intensity color position image conversely audio data two dimension variable sample rate com monly hz hz often high fidelity sign bit integer one dimension represent audio channel mono stereo etc dimension represent time sound continuous signal rather discrete signal digitalization convert continuous signal discrete signal take sample continuous signal set interval record discrete sample time series example digitalize audio come time long long ago one could purchase audio something call compact disc cd cd audio represent bit sign integer sample per second hz khz bitinteger khz thus one second stereo cd audio would channel tensor length channeltensor length assume original audio encode cd landline phone people would still able identify two encoding sample many aspect two sample would cd audio would objectively sound clearer problem bit length sample rate one must choose fidelity space dimensionality well machine learn importantly human hear sound go back original question audio know digital representation audio general structure image example pixel tend high correlation nearby pixel one pixel part red apple photo pixel next probably red well audio equivalent audio take waveform length wave audio determines hear single wave sine wave likely audio many different wave overlap create perceive sound white noise zero correlation sound like static perceive sound must correlation structure fact hear actually depends several sample temporally distant early signal processing algorithm exploit structure create feature raw audio signal earlier learn audio represent digitally time series time series make bunch different wave one use fourier transform go time domain frequency domain however hear pitch linear fashion rather logarithmic scale bin frequency domain representation audio mel scale stevens volkmann newman create scale pitch call mel scale use scale intensity various pitch represent way similar hear sound actually many mel scale famous shaughnessy log however want purely time domain purely frequency domain one use hybrid approach many fourier transforms across small overlap window signal arrange across time call short time fourier transform stft mathematically represent early machine learn audio do use mel frequency cepstrum coeffi cients mfccs prior mfccs lpcs lyon lpccs lorenz meredith advantage take high dimen sional audio transform relatively low dimensional uncorrelated fea ture representation exact series step take power stft signal square complex number result stft take log discrete cosine transform type fourier transform makhoul co typically window hop mfccs employ rudi mentary speech recognition mfccs relatively inexpensive calculate could utilized compute source time however feature audio would mean khz sample represent feature clearly different pitch distinguish perhaps high dimensional representation audio could retain audio information still reduce dimensionality make machine learn feasible plus two different fourier transforms calculate mfccs one could simplify process remove one fourier transforms turn stft create spectrogram spectrogram also call periodograms simply visual representation stft audio signal often mel scale create spectrogram one stft convert signal time frequency domain standard stft mel scale thus one must use filterbank bin result stft standard frequency bin mel frequency bin handcraft feature lay foundation modern audio analysis related work one seminal work speech classification davis mermelstein discuss need representation audio capture large percent age variation human speech maintain compact form compare mfccs linear frequency coefficient lfccs linear prediction coef ficients lpcs reflection coefficient rcs linear prediction ceptrum coeffi cients lpccs found mfccs similar number feature coefficient outperform form recognition test tably davis mermelstein utilize either mfccs later work zheng pearce esclercs use coefficient significantly commonly chosen number audio classification mfccs often pair hidden markov machine hmms clas sifiers gaussian mixture model gmms rise deep learn less craft set feature could use input modern neural network decorrelate simpler feature set state earlier mfccs dct filter bank spectrogram dct remove correlation spectrogram bin also inherently destroys information comparison time frequency representation audio huzaifah show task classification convolutional neural network spectrogram representation audio able outperform mfcc representation sample intuitively make sense network learn relationship dct exemplify also could find new useful relationship destroyed dct additional power spectrogram come increase number spectral bin spectrogram often bin utilize similar window hop length mfccs importantly spectrogram often view image rather linear input feature logically lead use image classification network audio feature representation spectrogram sample audioset image classification network ushered new era deep learn exhibit unparalleled performance classification task furthermore image classification network often train one task imagenet classification fine tune look another class image one use pre train network image classification almost sort image include spectrogram audio clip transfer domain knowledge could possibly allow one world class audio classification use relatively simple preprocessing step raw audio spectrogram powerful pretrained image recognition network resnet however audio sequence data often time desire output algorithm also sequence task well suit recurrent neural network rnns accord rdle audio transcription speech text audio generation text speech two common task space length raw audio present problem traditional neural network spectro gram dual representation frequency time especially windowed representation time allow rnns get bogged time aspectofaudio learn away time base number sample less likely connection make rnns often deployed call encoder decoder framework another solu tion alignment problem one rnn encode input output network use input another network decode desire output special type encoder decoder framework attention base network framework decoder take hidden context encoder network call memory additional input information hidden context often encodes exact portion unencoded input encoder found important decoder use information focus specific portion input make classification attention base phoneme detection luong audio generation realm one advanced network tacotron skerry ryanetal encode speaker identifier input output raw audio original tacotron network could create natural sound voice previously possible newer iteration tacotron even mimic different intonation however audio network take spectrogram input another advanced audio generation network wavenet van den oord wavenet us raw audio input encodes raw audio use gate dilate convolution dilate convolution similar normal convolution except gap convolutional length example normal convolution size would convolution first second third sample whereas dilate convolution size dilation would convolution first third fifth sample wavenet utilizes exponentially increase dilation length increase coverage feature map without increase convolutional window size allows network learn sample temporally far important audio since sound relies oscillation distant sample produce hear kalchbrenner create predecessor wavenet call bytenet also us dilate convolution use gate convolution wavenet bytenet first developed neural translation task translate text one language another finally shazam accord wang th floor block one founder shazam shazam create fingerprint song use power peak spectrogram song database user record audio sent shazam transform spectrogram peak spectro gram use fingerprint match database fingerprint recording song shazam spectrogram peak wang th floor block peak spectrogram resistant noise since theoretically peak remain peak presence noise match process combinatorial hash peak match peak relative process sensitive millisecond temporal difference even among different version song thus technique would translate process musical genre classification match generalize different version song let alone swath combination peak across different genre dataset chosen use google research gemmeke audioset dataset heretofore audioset audioset make second clip audio take youtube video total different class audio clip label audioset contains three different subset balance train set segment eval set segment unbalanced train set segment chose label isolate musical label use musical label left segment hour balance set segment hour eval set segment hour unbalanced set attempt train network balance set found algorithm generalize due massive size unbalance set take random sample segment use segment hour dataset name sample total length balance hour eval hour unbalanced hour unbalanced subset hour information google research audioset dataset segment label person label correspond idea category come mind hearing clip include label strictly musical genre still pre train musical theme theme music specifically within music category kept music genre music concept music role music mood distribution subset label distribution audioset label segment come different encoding format convert every clip khz mono wav file chose sample rate capture frequency range human ear capable hearing high sample significantly resource process additionally human distinguish small difference audio even much low sample frequency fact one look first modern digital audio encode gsm cell phone lorenz meredith produce khz audio consider poor quality modern standard ushered modern cellular communication era since sample potentially contain one label create vector binary value length represent presence label absence label use binary cross entropy loss function train network sigmoid layer network output coerce output author audioset use second cut segment feature represen tation audio input fully connect neural network classifier take average prediction make final prediction clip methodology procedure goal paper compare relative performance different encode decode method audio data task classification encode audio take place either one two stage one stage encode process raw audio either mfccs spectrogram learn feature map dilate convolution two stage encode process attention base rnn encoder spectrogram raw audio decoder use primarily resnets pre train imagenet fine tune audio classification test also utilized gru base rnn network bytenet style decoder network overall test different encode decode combination resnet mfccs resnet spectrogram resnet mfccs resnet spectrogram attention base rnn spectro gram bytenet encoder decoder resnet baseline encoder decoder setup use mfcc feature input resnet network thisresnet networkwaspre image thus mfccs spectrogram resize feature representation use bilinear interpolation use convolution produce channel single channel output mfccs spectrogram resnet channelsto feature map next four set denote different color upon enter successive set finally network average pool layer follow dense layer desire number output use rectify linear unit non linear activation function throughout network visualization network show resnet utilized either binary cross entropy loss precede sigmoid layer allows use log sum exp trick numerical stability cross entropy loss precede softmax layer binary cross entropy allows possibility multi label per sample loss calculate take sum derivative binomial prediction target rc mathematically express pc log log hand cross entropy optimizes output one label importantly softmax function normalizes score output relative sum output cross entropy simpler metric see formulation loss ylogy optimize network use adam amsgrad stochastic optimization method reddi begin learn rate multiply epoch first epoch fine tune fully connect layer freeze weight rest network unfroze weight network remainder training procedure epoch use minibatch size record training loss minibatch additionally ran network validation set audio clip record validation loss accuracy correct positive prediction training procedure complete save weight network use weight evaluation set audio clip test eval set validation sample set record accuracy validation test ran output sigmoid layer coerce output value resnet network spectrogram create spectrogram win dow size hop size filter bank bilinear interpolation coerce output matrix input height width expect resnet family network additionally scale spectrogram power decibel rescale everything resnet network train input configuration option resnet mfccs network resnet resnet network use layer resnet base network primary difference resnet resnet network type block use within set network resnet utilizes block described resnet utilizes bottleneck block bottleneck block use convolution reduce number feature map go convolution follow another convolution restore original number feature map do reduce compute complexity convolution allows network depth increase without number parameter explode experiment found network also seem converge faster resnet network thus lower total number epoch change learn rate schedule decrease th th rd epoch respectively bottleneck block speed schedule configuration network respective resnet network attention base rnn next configuration try attention base rnn encoder decoder network use spectrogram described input encoder net work encoder network simple gru base rnn use unidirectional layer grus hidden size grus chosen instead lstms reduce computational complexity use final hidden input decoder initial hidden decoder input spectrogram normal input decoder network attention network calculate attention score use general method fully connect multiplication encoder output get attention energy since calculate sequence also modify final layer network transpose time feature dimension convolution feature reduce number feature number hop number hop flatten tensor use fully connect layer output correct number class network use stochastic gradient descent optimization scheme momentum training schedule last epoch single learn rate adjustment th epoch network pre train do end end training network bytenet dilate convolutional network use bytenet encoder network set block exponential dilation hidden feature kernel size three bytenet encoder also use stride convolution length st nd th th set respectively reduce dimensionality encode decoder network similar bytenet style network fully connect layer classification layer use adam optimizer amsgrad similar resnet network training rather sgd anneal schedule attention network discussion unfortunately many network converge training set tend overfit generalize well test set first experiment annealingschedule type optimizer learn rate network depth number filter bank etc etc described set finally settle network perfor mant training data method tend converge training data validate well training procedure best result accuracy rate resnet network spectrogram train cross entropy loss result begin experiment use binary cross entropy loss allow network learn multi label dataset use balance training set loss network fell throughout training validation set loss accuracy plateaued network type accuracy resnet mfcc bce balance noise cache resnet spectrogram bce balance noise cache resnet mfcc bce unbalanced noise cache resnet spectrogram bce unbalanced noise cache resnet spectrogram cross entropy unbalanced noise cache resnet spectrogram bce balance noise add cache resnet spectrogram cross entropy balance noise add cache resnet mfcc bce balance noise cache resnet spectrogram bce balance noise cache resnet mfcc bce unbalanced noise cache resnet spectrogram bce unbalanced noise cache resnet spectrogram cross entropy unbalanced noise cache resnet spectrogram bce balance noise add cache resnet spectrogram cross entropy balance noise add cache attn bce balance noise cache attn bce unbalanced noise cache attn cross entropy balance noise cache attn bce balance noise add cache bytenet cross entropy balance noise cache result resnet training validation graph balance set mgc classical sign overfitting naive answer overfitting problem find data often time option case access totheunbalancedset withmoredata network could see example particular genre music hope example intra genre pattern across sample would develop retrain network large unbalanced dataset however network still generalize well test set resnet training validation graph unbalanced set find data work one make data found small noise dataset hu different non speech noise since genre music remains genre regardless environment played kept label sample without noise shazam paper also show evidence noise affect peak spectrogram add noise may mask important feature sample simultaneously prevent model memorize sample probabilistically mixed one sample could increase dataset fold combinatorially high decide mix single noise single sample however result promising also result good noise add input example resnet network use bce loss balance dataset achieve accuracy model noise add achieve accuracy could deterministically add sound sample would increase run time memory usage linearly unbalanced dataset already run memory limit system create augment dataset time large original dataset realistic note decrease training time precomputed cached spectrogram especially resnet network attention base network notice gpus fully utilized thus add noise recomputed cached sample epoch always use unaltered sample first ten epoch result vary much use cache cache however training graph utilize cache spike epoch cache refresh resnet training validation graph unbalanced set find data work make data work create data data already instead use full second sample randomly take second section iteration cache operation although sample could overlap across epoch feature temporally displace training network generalize across sample also within sample perhaps repeat pattern define genre would found within sample generalize genre however case found training loss would still settle range similar second sample interestingly training curve decline slowly sub sample suspect due network effectively see large dataset yet still large diverse enough overcome overfitting data use data make data split get sample data still problem classify multi label dataset remains simplify problem instead try classify multi label sample choose one label sample use cross entropy loss precede softmax activation theoretically sample one label network learn multiple label sample one thus network need learn learn correct class many class might correct class number class downside switch single label problem perhaps network would make connection similar genre music attack new problem repeat process unfortunately result network properly generalize validation set resnet training validation graph unbalanced set finally note attention base rnn bytenet network perform rather poorly fact bytenet encoder decoder network never con verged suspect end end training process relatively small dataset size contribute issue network pre train resnet network train million image fine tune dataset perhaps large cleaner dataset network would able generalize dataset bytenet network also suspect dilate convolution may large enough wavenet us dilation kernel size two would equivalent dilation kernel size however try increase dilation level ran memory gpus conclusion although get result want network classify misclassification obvious problem musical genre difficult human classify inherent ambiguity dance music pop music drum bass subclass techno category altogether question correct answer thus although data label human could label mislead especially less specific category perhaps dataset contain breadth feature variation network properly generalize class speak enough sample even large unbalanced dataset able train model sample class neural network relatively paltry amount data resource constraint restrict use entire unbalanced dataset even would introduce additional problem specifically unbalanced nature dataset could skew network choose genre appear dataset often technique combat unbalanced datasets many require remove sample class sample duplicate sample class low number sample solution ideal additionally sample come youtube video quality audio varies greatly record environment quality record background noise factor contribute relatively low quality dataset could network memorize feature rather focus music listen random selection sample often time trouble connect genre music however additional step attempt may give well result one could reduce number genre specifically could eliminate overlap genre techno drum bass arch musical theme video game music decide want avoid cherry pick also state earlier problem musical genre classification inherently difficult nature people classify mu sical genre want remove element difficulty problem hand pick genre accuracy may increase desire level would still plague generalization problem state expand full set genre problem would masked preselected class another solution would visualize spectrogram actual image take image representation spectrogram input method feel convolute require rela tively computationally intensive step save intermediary step disk plus would pure image classification rather audio classification end science attain predetermine result rather devel oping process solve problem lesson learn call failure one knowledge subject matter much successful ex periments network able achieve desire accuracy achieve many good result training loss generally fell near zero mean network design learn training data also although level desire network identify genre level far well random fundamental understand audio data unique problem present project born sister project identify language speech sample bring lesson learn back task improve result bibliography bloomberg apple buy shazam boost apple mu sic http www bloomberg com news article apple buy early iphone app hit shazam boost apple music line access mar davis mermelstein aug comparison parametric representa tions monosyllabic word recognition continuously spoken sentence ieee transaction acoustic speech signal processing gemmeke elli freedman jansen lawrence moore plakal ritter audio set ontology human label dataset audio event proc ieee icassp new orleans la rdle borak pez cabrera statistic financial market exercise solution universitext springer heidelberg zhang ren sun deep residual learn image recognition corr ab hu corpus non speech sound http web cse ohio state edu pnl corpus hunonspeech hucorpus html online access jun huzaifah comparison time frequency representation environmental sound classification use convolutional neural network corr ab kalchbrenner espeholt simonyan van den oord graf kavukcuoglu neural machine translation linear time corr ab lorenz meredith digital cellular telecommunication sys tem phase gsm full rate speech transcoding gsm version release http portal etsi org webapp workprogram report workitem asp wki id online access jun luong pham man effective approach attention base neural machine translation corr ab lyon mel frequency cepstral coefficient mfcc tutorial http com miscellaneous machine learn guide mel frequency cepstral coefficient mfccs online access jan makhoul february fast cosine transform one two dimension ieee transaction acoustic speech signal processing mikolov chen corrado dean efficient estimation word representation vector space corr ab shaughnessy speech communication human machine addison wesley series electrical engineering addison wesley pub co pearce esclercs speech processing transmission qual ity aspect stq distribute speech recognition front end feature extrac tion algorithm compression algorithm http portal etsi org webapp workprogram report workitem asp wki id reddi kale ands kumar international conference learn representation stevens volkmann newman scale measurement psychological magnitude pitch journal acoustical society america skerry ryan battenberg xiao wang stanton shor wei clark saurous towards end end prosody transfer expressive speech synthesis tacotron corr ab van den oord dieleman zen simonyan vinyals graf kalchbrenner senior kavukcuoglu wavenet gener ative model raw audio corr ab wang th floor block industrial strength audio search algo rithm proceeding th international conference music information retrieval zheng zhang song nov comparison different implemen tations mfcc journal computer science technology declaration authorship hereby confirm author master thesis independently without use others indicate source consult publish work others form idea equation text always ex plicitly attribute june david pollack
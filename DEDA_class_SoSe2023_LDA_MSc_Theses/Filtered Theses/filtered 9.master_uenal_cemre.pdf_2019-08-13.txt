search unicorn machine learn approach towards startup success prediction master thesis submit prof dr wolfgang karl ardle prof dr weining wang universit zu school business economics institute statistic econometrics ladislaus von bortkiewicz chair statistic cemre nal partial ful llment requirement degree master science economics management science july dr wolfgangkarlh eldofstatistics irtg invaluable feedback throughout creation thesis also would like thank dear friend good bad time importantly grateful unconditional unfailing support family make journey germany possible importance startup economic dynamism innovation competition acknowledge literature highly uncertain volatile nature startup ecosys tem make di cult analyze interpret information evaluate startup successful time computationally intensive nature prediction problem induces need quanti ed model enables objective approach startup success pre diction paper objective obtain reproducible model startup success prediction use machine learn method earlier literature predict startup success almost exclusively relies survey data collect rms analyze study estimation hence almost impossible apply repeatable automate way future startup success prediction paper publicly available large scale data crunchbase comisused thedataispre imbalance use oversampling approach adasyn total six di erent model implement predict startup success logistic regression full reduce recursive partition tree conditional inference tree random forest extreme gradient boost use goodness measure applicable model case best model select ensemble method random forest extreme gradient boost test andaucof respectively top variable model last funding date rst funding lag company age model estimate study use predict success rate future new rms venture repeatable way use publicly available large scale data ii content list abbreviation list vi list vii introduction motivation literature review startup performance business success corporate bankruptcy startup failure brief review business success prediction model methodology measure variable data pre processing overcome class imbalance adaptive synthetic sample approach adasyn logistic regression recursive partition tree rpart conditional reference tree bootstrapping bagging boost random forest bootstrapping bagging boost random forest extreme gradient boost result discussion logistic regression implementation recursive partition conditional inference tree implementation random forest implementation extreme gradient boost implementation comparison model iii discussion variable importance conclusion research iv list abbreviation adasyn adaptive synthetic oversampling technique api application program interface auc area curve cv cross validation ebit earnings interest tax ebitda earnings interest tax depreciation amortization fn false negative fp false positive fpr false positive rate ipo initial public ering information technology knn kth near neighbour kpi key performance indicator rpart recursive partition tree sme small medium size enterprise smote synthetic minority oversampling technique tn true negative tp true positive tpr true positive rate usd dollar xgb extreme gradient boost list description raw variable summary data cleaning step summary data transformation descriptive statistic categorical variable summary reduce logistic regression confusion matrix full logistic regression confusion matrix reduce logistic regression confusion matrix recursive partition tree confusion matrix conditional inference tree confusion matrix random forest confusion matrix extreme gradient boost comparison performance metric across model ranked variable importance normalize recursive partition tree ranked variable importance random forest ranked variable importance extreme gradient boost vi list descriptive statistic continuous variable smote adasyn diagram base hu li scatter plot success probability regressors base comparison auc among model vii introduction small medium size business smes consider drive force technological innovation economic exibility growth create new job opportuni tie luger koo hence success company interest favor society shane however startup fail within rst year found less remain pas year milestone regmi de spite intimidate statistic entrepreneur continue start business believe idea one break hope monetize optimize success factor paper aim construct appropriate quantitative model predict whether startup succeed fail past decade extensive research sur historical nancial data kpis however historical nancial sale production data always exist startup important component success prediction corporate company startup success base di erent dynamic show similar ities dotcom company dotcom company startup need evaluate innovative strategy example pro power internet digi talization overthelast year andfacehigherrisks rms operate disruptive area like blockchain application cryptocurren cies face unique business risk uncertainty compare traditional establish company therefore paper approach startup success prediction di erently common research conventional company success prediction data use paper provide crunchbase com crowd source database startup paper section section explores main motivation behind research sec tion er review related work scienti literature section present discus data methodology model method result present section section articulate conclusion future research possibility respectively motivation startup become important topic economic policy developed emerge economy around world driver economic prosperity wealth also major impact innovation technological development luger koo fast growth rate agility deploy innovative business model disruptive actor global economy especially since business playground frequently global one dynamic sometimes irreverent approach business challenge status quo traditional corporate business even classical smes success startup interest entrepreneur also stakeholder investor shareholder supplier customer client ability accurately predict success failure new venture brings value whole startup ecosystem boritz kennedy classical literature major motivator stakeholder refer mostly smes important stakeholder man agers bene success prediction model take early precaution future distress business therefore avoid bankruptcy ii sponsor lender investor enable prediction model maximize return minimize risk business portfolio identi cation healthy company invest iii employee well ass career choice avoid cost unemployment event bankruptcy wu however case startup stakeholder rst entrepreneur ben prediction model regard success failure business idea make educate decision address potential critical point within business mod el ability pivot timely manner save resource nancial human etc canbeangelinvestors seedmoneyfunds venture capitalinvestors etc whoideallybene traditional success rate startup shane last least rest player stake well prepared regard whether startup succeed fail supplier need create new supply chain system client customer might rely new product service also bear risk related startup success say involve party high risk tolerance since dependable quanti ed success prediction model predictability startup success would generate cient ective resource allocation dynamic market player stakeholder environment startup grow develop complex nu model issue becomes even di cult young startup provide historical nancial operational data available data best sparse qualitative multiple source context di cult entrepreneur investor make educate objective decision since human tend selective information use su er bias make decision claim intuition gut feel base decision maker previous experience expertise best struments decision make come startup einhorn example state human capable use intuition make decision base subjective judgement information proven recognize use rare informa tion piece various decision make environment would di cult predict outcome algorithm however research within social science literature challenge argument dual process theory propose fischho suggests two system think system quickly supply intuitive answer judgment problem surface described automatic ortless associative ii system concern ana lytical approach weighs carefully situation require energy focus ability critical think important allows decision maker make di cult complex decision prior experience draw even though ectingone issometimespushed forward cient way decision make objective quantitative approach processing evaluate information require account business risk evans behavioural economics focus bound rationality decision maker therefore proneness make error bound rationality link limitation human process vast amount information rational way venkatraman simon argument valid especially today business environment manager entrepreneur ooded information data useful consider dynamic unstable business situation startup practice attention time require collect process information scarce resource thus decision maker always pay enough attention information available hence process underlie connection various piece information source consequence decision maker tendency consider information value information de ne unimportant however experience reference intuitive think lead ine cient poor choice similarly read van leeuwen claim overestimation one skill lead use heuristic order solve complex problem erentpieces information also uence decision make decision time variant luce therefore bound rationality decision maker induces motivation towards quan titative approach give limitation decision maker respect information evaluation quanti ed model introduce literature review thestartupde lugerandkoo emphasizes three characteristic describe startup new active independent new implies establishment company exist active excludes company establish recently exist paper administrative purpose tax avoidance lastly independent implies startup part establish parent company hold de nitional problem startup research link data measurement collection hence many researcher de ne startup base available information data set luger koo paper de nition startup base available data hence company consider startup active industry de ned year business year due lack information possible identify exclude spin startup found large corporation startup performance business success lot research topic business success focus corporate sme success context health rm competitive business environment highly associ ated pro tability level nancial solvency butler fitzgerald associate business success competitive performance rm competitor lussier pfeifer considers rms successful make least industry average pro last year gatev hand de ne success continu ance operation without owe creditor shareholder context startup however de nition business success corporate compa ny smes apply due various reason first foremost majority early stage startup generate pro stable historical nancial data hence de nitions lussier pfeifer gatev apply competitive performance hand always objective metric ass business success construct without comparative nancial performance player market nancial kpis analyse indus try peer comparison framework study focus impact startup performance frequently take approach tavoletti evaluates startup success potential early international growth ability entrepreneur generate valuable opportunity business model another approach startup success look number size investment startup receives dempwolf ability startup gain traction connect cient valu able manner local global ecosystem prove scale ect short period time also consider measure performance ceausu holistic approach ozdemir look startup success qualitative lens consider global impact contribution development entrepreneurial ecosystem well quantitative aspect revenue user client number job create corporate bankruptcy startup failure wide body scienti literature dedicate corporate sme disruption smebankruptcy oogheanddepri jcker argue business failure unique moment time rather process di erent trigger turn point along life cycle business disruption success happen di erent way ooghe de prijcker suggest three main trajectory firstly lack success due mismanagement secondly failure startup rapid launch right begin establish business butthecompany still face failure due neglect nancial operational duty growth phase third trajectory lack nancial sustainability due general immediate environment corporate policy come startup failure dynamic pace venture need grow develop failure process window much shorter case corporate company smes even though failure concept use frequently startup world sometimes even pride consider source valuable knowledge experience expertise mostly north america little scienti study focus startup speci dynamic factor ooghe waeyaert summarizes factor uencing business success category generalenvironment economics aspect foreigncoun try currency politics etc ii immediate environment supplier customer creditor competitor iii management team characteristic motivation experience skill personal ity trait iv corporate policy strategy investment corporate governance com pany characteristic size maturity industry source classify factor two category industry speci characteristic rm speci characteris tic kau man wang business failure also analyse two theoretical framework deterministic voluntaristic one karabag amankwah amoah mellahi wilkinson deterministic approach premise manager leader company little control external factor fact determine business failure factor baumandsingh porter innovation new technology tushman anderson economic regime dornbusch technology development policy hung whittington lee political stability instability erb voluntaristic framework argues internal factor actually far great impact potential failure business meaning decision strategic action manager leader direct impact several research study highlight fact framework interrelate consider separately integrate approach key discover underlie factor failure success hager gonczi nancial ratio cash ow total sale ebit ebitda margin net income etc base rm balance sheet income cash ow statement proven useful performance prediction establish company also overall nancial situation success prediction model literature design use nancial ratio extensively due standardize nature availability establish rms however success prediction aspreviouslystated stage startup generate pro stable nancial data implies business success prediction startup primarily base quantitative nancialdata irrelevant startup success prediction data exist even rare case nancial ratio exist startup may strong enough build good model data source need study scienti literature discus qualitative data provide prediction good nancial ratio liu wu also solely use nancial ratio heavily criticize doumpos zopounidis dimitras laitinen state nancial ratio operatingand nancialproblems brief review business success prediction model model wrong useful george box business success prediction model aim predict status company disruption success happens ooghe de prijcker du jardin state rms fail unique way directly attack classi cation problem cluster algorithm therefore little use important study analyse many fail rms possible learn identify key factor lead failure rst place bankruptcy prediction subject research decade kumar ravi categorises prediction technique eld type statistical technique fer linear discriminant analysis multivariate discriminant analysis quadratic discriminant analysis logistic regression factor analysis ii intelligent technique neural network self organize map etc early study literature mostly rely statistical model formalizes relation ship variable statistical model make prediction accurate consistent possible context nancial decision extreme uncertainty jones olson research focus corporate bankruptcy survival model estab lished company smes application prediction model eld go back model use information nancial statement nancial ratio boritz kennedy early study pay much attention abil data create successful unsuccessful company di erent industry validity model assess base confusion matrix type type ii error research success prediction early stage company become predominant lussier implement one rst non nancial model mainly use qualitative variable regression model predict new venture failure call lussiermodel original full model base variable record keep nancialcontrols capital industryexperience planning professional advisory education sta ng product service timing economic timing age partner parent minority business owner marketing also many study show relation success new venture skill motivation management ooghe de prijcker ooghe de prijcker recognizes time dimension success underlie non nancial factor author emphasize fragment structure non nancial factor include management team also relationship dif ferent stakeholder come framework classify various bankruptcy case accord underlie reason previously explain researcher identi ed di dujardin wu lussier pfeifer state follow multivariate dis methodslikelogit probit analysis well linear program developed frequently use independent predictive statistical model use researcher use type type ii error basis evaluation however inthelastdecades althoughboth approach aim learn data main di erence machine learn algorithm rely rule base program cao state continuous concern statistical model adequacy correctness underlie assumption speci cation haavelmo question validity regression coe cients whole assumption example linear regression wrong framework implementation non parametric model permit relaxed assumption model structure methodology measure variable majority paper scienti literature present study author design survey conduct interview startup stakeholder order collect data directly successful fail company however approach limitation since size data set number interviewed company new venture exceed even cite paper lussier pfeifer lussier large amount data predict startup success data set form use data research application program interface api crunchbase com summarizes raw data obtain data pre processing initial data setobtained crunchbase com observation variable step follow complete data set summarizes step startup round miss data exclude company found exclude consider framework paper old startup startup miss establishment date company domain name exclude due concern company might ghost rms firm industry speci cation exclude duplicate remove firm miss region information delete data set clean outlier feature zero near zero variance remove variable name description company name name company domain url company website country code alpha country code state code state code region state region abbreviation city location company headquarters status status company operating close etc short description top level industry classification category list industry category group list sector employee number employee funding round funding round complete total funding usd total funding raise found date firm establish first funding date firm receive first funding last funding date firm receive last funding close date firm close applicable email email address company phone phone number company cb url url crunchbase page company twitter url url twitter page company facebook url url facebook page company uuid unique id description raw variable nextunicorn datacleaning data cleaning list variable use throughout paper summarize variable provide snapshot company give point time remove predictor thoroughly discuss literature however kuhn john son discus remove variable help reduce compute time complexity model consider predictor uniform almost uniform value refer zero near zero variance predictor respectively variable uninfor mative characteristic data also harm prediction accuracy zero near zero variance calculate divide unique value sample size compare predefined threshold value variable consider example tree base classification model since provide vary information class one approach avoid information loss collect data abstain zero near zero variance since collect information company data set within scope paper variable zero near zero variance elimi nated hence sector energy industrial real estate utility well continent africa oceania exclude analysis action initiate drop sample size initial observation extract crunchbase drop total funding raise usd funding round miss consider startup establish drop year found company name miss drop domain information miss drop industry miss drop duplicate exists drop region information miss cleaning outlier first funding lag last funding lag funding round drop near zero zero variance explanatory variable summary data cleaning step nextunicorn datacleaning original data defines startup status four category operating ii acquire iii ipoand iv close chang ipo ambiguity definition depend dynamic deal acquisition also represent failure example entrepreneur make gain deal also many unsuccessful incomplete ipo however detail transaction usually public startup resource intensive obtain therefore sake simplicity keep relevant information startup operating acquire issue ipo label successful startup close label failure hence company status success failure define dependent variable within framework paper main industry category raw dataset industry grouped un der industry sector accord industry communication service consumer discretionary consumer staple energy nance health industrials utility real estate material company data set business material industry industry sector energy industrials utility real estate remove due near zero variance therefore total number industry reduces next step investigate obvious di erence successful fail company di erent characteristic type company similar median value company age total funding usd number funding round rst funding lag last funding lag last funding date also support implementation usage machine learn algorithm distinct di erence two group make classi cation problem di cult deal however characteristic continuous variable di er strongly successful fail company give overview descriptive characteristic categorical variable feature transformation data reveals overall company base america america europe host almost rms successful andit inthelast year company social medium existence multiple platform gen eral characteristic startup data set accordance current startup trend similar continuous variable categorical variable also di er strongly tween two class sake performance model built follow section nostrongcorrelation variable found hence multi collinearity checked variable name transformation use variable variable type country code base country code respective company continent categorical identify avoid granularity status failure close status categorical success operating acquire ipo category group list value multiple industry split sector categorical major industry identify mapped industry classification funding round funding round numeric total funding usd total funding usd numeric found company age calculate subtract company age numeric foundation date year found first funding first funding lag year pass first funding lag numeric foundation company first funding receive first funding found last funding last funding lag year pass last funding lag numeric first funding last funding receive last funding first funding receive last funding date last funding date year pass since last funding date numeric company receive last funding date last funding twitter url function create identify social social categorical facebook url medium appearance firm twitter facebook active twitter twitter facebook facebook none social medium appearance summary data transformation nextunicorn datacleaning complete mention data pre processing step final data set consists firm initial sample size variable point class imbalance dependent variable checked company age total funding usd dsu ega ynapmocsdnuor gnidnuf latotgal failure successful failure successful company status company status funding round first funding lag gnidnuf gnidnufetad tsrifgal failure successful failure successful company status company status last funding date last funding lag ot gnidnuf gnidnuf tsal tsal failure successful failure successful company status company status descriptive statistic continuous variable nextunicorn descriptivestats success failure variable name frequency frequency social facebook twitter none continent america asia europe sector commercial service consumer discretionary consumer staple finance health descriptive statistic categorical variable nextunicorn descriptivestats overcome class imbalance website crunchbase com employ crowdsourcing model information gather large open rapidly grow internet user interview conduct crunchbase team within scope research reveal operating firm provide update information enterprise hence data set obtain crunchbase com subject selection success bias success bias refers sample limitation sample set representative true population clean data set reveals company classify successful remain fail close indicate class imbalance class imbalance mostimportantly performance number instance one class large machine learn algorithm tend label minority class majority class although would smote adasyn diagram base hu li drastic effect accuracy type ii error high determine model performance accuracy via number false positive fp class imbalance negative impact cost misclassification different class often vary well refer section handle imbalanced data however new improve sample approach possible paper adopt approach sample majority class oversample minority class krawczyk paper class imbalance handle oversampling minority class synthetically create artificial data point described section adaptive synthetic sample approach adasyn adasyn samplingtechnique smote bychawlaetal smote find randomly select minority class data point draw line kth near neighbour knn smote generates synthetic data point line increase population minority class however process allows new data point linearly correlate parent data point adasyn advance smote adaptively generates minority data accord dis tribution add random value synthetically generate data point order make scatter hence adasyn help reduce learn bias adaptively shift decision boundary classi cation problem focus sample di cult learn illustrates di erence smote adasyn goal oversampling increase size minority class via synthetic observation base exist minority class observation balance size majority minority class adasyn rst calculates degree class imbalance take proportion minority majority class compare pre de ned accepted threshold level balance class degree class imbalance small th threshold adasyn proceeds calculate number synthetic data sample gen erated minority class feature adasyn nd knn base prede ned distance measure purpose paper threshold de ned euclidean distance use measure distance ratio fea tures belonging majority class within knn determine normalize obtain density distribution use require number synthetic sample generate minority class feature reach one minority data example select knn synthetic data example gener zi ated add random number linear dependency actual data point heetal algorithm complete data pre processing remain data point split training test set respectively adasyn adopt training test sample separately prevent dependence two data set algorithm pseudocode adasyn base input training test dataset preset th threshold maximum tolerate degree class imbalance ratio procedure calculate degree class imbalance th calculate number data point need synthetically generate parameter satisfy th find knn base euclidean distance dimensional space calculate number example near neighbour belong majority class normalize accord xms density function ii calculate number data point need synthetically generate minority example randomly pick minority data example knn zi generate synthetic data example zi di erence vector random number zi output synthetic data example logistic regression logistic regression speci case linear regression response dichotomous variable logistic regression model probability belongs one two category ardle simar log epp jxij jx epp jxij design logistic regression function give output proba bility belonging one dichotomous class coe cients equation use maximum likelihood estimation recursive partition tree rpart rpart scheme construct regression classi cation model top level general structure two stage procedure result model represent binary tree literature first algorithm nd best variable best split data two group step repeat result two subgroup subgroup size reach predetermine minimum size improvement model make hothorn de ne rpart model follow let dependent variable give status covariates dimensional covariate vector de ned assumption conditional distribution yjx function covariates yjx yjx yjf learn sample model regression relationship random sample number observation pi non negative integer value case weight use formulate learn sample node tree represent weight vector weight non zero correspond observation represent node zero otherwise lefti righti goodness split criterion de ned breiman impurity function commonly use impurity function gini index entropy gini index entropy log probability reach respective node another approach consider decrease test error goodness split criterion implement partition tree null hypothesis independence covariates response test step select jth covariate strong relation step subset observation select data split two case weight also adjust correspond indicator function represent new split two step recursively repeat null hypothesis reject conditional reference tree step general recursive partition face independence problem algorithm rst test hypothesis independence response variable covariates hypothesis reject recursive step general model iterate stop criterion met implementation us uni ed framework con ditional inference strasser weber split establish sum weight two neighbour node exceeds predetermine minimum value relation covariate measure linear statistic vec rpjq ji rpjq non random transformation covariate uence function depends response distribution null hypothesis depends joint distribution identi ed majority real circumstance permutation test procedure use clarify dependency xing covariates conditioning possible combination permutation dependent variable hothorn explores thesetest extensively testswill notbefurther discuss scope paper bootstrapping bagging boost random forest essential understand bagging boost order fully comprehend method ology ensemble method bootstrapping foundation two method bootstrapping bootstrapping consider non parametric approach statistical inference data meet assumption adopt model bootstrapping refer literature resampling method basic idea behind randomly select observation replacement one data point occur bootstrapping data set data set bootstrap data set bootstrapping data set use generate new estimate procedure repeat time large value james bagging boost bagging boost call ensemble method aim bring pre dictive power single learner together powerful learner main di erence bagging boost relationship model use bagging combine independent model usually decision tree boost conduct iterative method de crease error precede model succeed model sutton lemmens croux bagging take average set observation reduce variance therefore improve predictive accuracy statistical model build separate decision tree individually predict response use training data set nal output mode output individual tree individual decision tree however usually face obstacle high variance word high variance mean training data set split two equal part two di erent decision tree half end result bagging bootstrap aggregation therefore summarize variance reduce procedure hence bagging generates di erent bootstrap data set average prediction obtain nal prediction average tree reduces variance result improve accuracy james idea behind boost strengthen performance weak learner assume training set data point data point assume weight iterative process round new weight assign point accord classi cation result previous iteration step correct classi cation result reduce weight vice versa complete iteration model call tted model iterationsclassi cation random forest bagging pillar random forest however presence one highly dom inant predictor single tree would use strong predictor top level hence tree would end look quite similar random forest model force consider whole set available predictor restriction available predictor tree therefore prevents model dominate one strong predictor breiman building decision tree bootstrapping data set split tree base random sample predictor subset feature space sample predictor generate tree scratch dichotomous dependent variable size de ned approximately select variable random tree grows without prune output prediction derive take average weight average majority vote individual tree james algorithm summarizes random forest formation one distinctive advantage implant random forest base multiple decision tree decision tree non parametric meaning depend prior distri bution assumption require transformation variable condition one cation label overlap distinct identi cation framework paper success failure distinct classi cation label algorithm pseudocode random forest base gepp input bootstrap sample feature total number tree forest function random forest bootstrap sample randomtlearn return end function function randomtlearn node verysmallsubsetof split best feature end function output learn tree extreme gradient boost gradient boost combine weak learner bagging boost explain additive manner form new learner maximal correlation negative gradient loss function friedman gradient boost newly generate model predict residual error previous model use prediction form output first subset full training data drawn random without replacement iteration deviation residual iteration partition derive best data partition determine stage afterwards succeed model aim correct mistake rst model give training sample fy know fy xg goal gradient boost nd function map expect value loss function minimize hence boost approximates additive expansion base learner follow form base learner base learner parameter loss function write argmin fa parameter argmin im hence give optimal coe cient value argmin friedman solves equation two step rst step base line function least square current pseudo residual give tted base line function optimal value coe cient derive extreme gradient boost xgb implement improvement gradient boost cation ciency extra randomization parameter ensure low variance xgb reduces space possible feature split base distribution feature across data point leaf branch couple point one need consider assess model performance conclude best model implement first performance learner mainly depends training data formulation initial hypothesis training data provide su cient information di cult conclude one single best learner hence another motivation use ensemble model bene multiple weak learner rather one strong learner wang wang du jardin state well approach ensemble model reasonable however practice necessary condition accuracy diversity need tobesatis ed dom guess generally base learner information problem inclusion variable regressors prior estimate model compare possible say model method perform well framework paper general single model method performs well research problem next section model estimation result discuss result discussion logistic regression implementation full simple logistic regression considers remain variable eliminate one near zero variance explain earlier chapter con rms existence dummy trap reveals insigni cant variable second step one level dummy variable statistically insigni cant variable exclude reduce logistic regression model hence coe cient estimate signi cant summarize strike result near zero estimate total funding usd combine ect many factor positively negatively correlate success rate positive sign expect since successful company future potential careful review research lender get funding favorable competitive term hence high funding amount high expectation startup future potential negligible ect total funding usd success explain cash burning startup discuss ooghe de prijcker startup receive high investment rapid growth phase often end bankruptcy due poor management decision include misallocation receive fund result indicates high burn rate fail company convincing investor begin search external funding early stage funding indicate entrepreneur successful sell idea investor however funding round follow appropriate managerial action refer section increase number funding round may negative impact success coefficient std error intercept funding round company age last funding date total funding usd social social facebook social twitter continent america sector comm serv sector con disc sector con stap sector health summary reduce logistic regression nextunicorn logisticregression regression coefficient change range dummy variable existence digital platform facebook high impact busi ness success negative coefficient geographic location continent america explain intense competition harsh business environment discuss failure culture differs america hence plausible conclude negative coefficient confirms fail fast mentality positive coefficient health sector sup port popularity startup health sector recent year negative coefficient last funding date indicates company less likely fail last funding long unlike linear regression model logistic regression explains variance dependent variable explain independent variable literature one commonly use metric mcfadden pseudo mcfadden define equation ln fit model ln represent null model intercept predictor mcfadden pseudo range value closer zero predictive power model decrease reduce model mcfadden pseudo indicate quite weak predictive power hu ln mcfaddensr ln train model use predict failure probability startup status label success assign predict success probability predetermine threshold failure otherwise confusion matrix test set prediction see prediction accuracy test set despite existence dummy trap insignificant coefficient estimate although insignificant regressors eliminate also perform predictive accuracy data test set erroneously classify select threshold level confusion matrix test set prediction foundintable andm guess original empirical study business success prediction lussier predictive ability accuracy hand recent extension lussier model able reach accuracy level despite low mcfadden pseudo reduce logistic regression model underperform compare pre cede study actual failure actual success predict failure predict success confusion matrix full logistic regression nextunicorn logisticregression relationship predict probability belonging success class continuous covariates use illustrate clearly conclude actual failure actual success predict failure predict success confusion matrix reduce logistic regression nextunicorn logisticregression number firm achieve funding round achieve high number funding round attract continuous investor attention consistency vestor relation financial support link high probability successful also stagefunding success explain predict probability rather random low end number funding round also section elaborate first year thepredicted probability success decrease start rd year company age increase becomes difficult make distinct differentiation probability success failure lag last funding date reflect negative linear dependence predict probability success mean venture receive recent funding high odds successful hand clear pattern predict probability success categorical variable social slightly exhibit positive relationship predict success probability recursive partition conditional inference tree implementation control parameter affect complexity performance decision tree two important parameter minimum split minimum bucket size minimum split number observation need exist node split attempt minimum bucket size minimum number observation terminal node explain startup profile quite unique difficult find general fitting pattern fail company hence size minimum split minimum bucket set two order embrace granular nature startup failure funding round company age last funding date total funding usd first funding lag last funding lag scatter plot success probability regressors base nextunicorn scatter pattern furthermore recursive partition tree function us parameter call complexity track control complexity tree measure combination ability tree successfully separate label dependent variable status size tree order determine complexity measure record minimum cross validation error identify complexity measure record use hence complexity measure set prune attempt result complexity measure therefore prune change improve initial construction recursive partition tree recursive partition tree perform surprisingly well error rate give alonedecisiontrees partition tree indicate overfitting also fitting single model prone instability small change training set hothorn actual failure actual success predict failure predict success confusion matrix recursive partition tree nextunicorn conditional inference tree explain previously check independence sponse variable covariates oppose recursive partition tree confusion matrix prediction conditional inference tree represent condi tional inference tree perform error rate test accuracy rate conditional inference tree performs well literature benchmark mention earlier actual failure actual success predict failure predict success confusion matrix conditional inference tree nextunicorn conditionaltree random forest implementation criticism towards stand alone decision tree address high dependence result training data alteration decision tree structure related small change training data order overcome hurdle forest decision tree generate number independent variable consider split restrict mention model description optimal number variable splitting node square root number available independent variable hence parameter set number tree grow limited data set quite large cutler strobl actual failure actual success predict failure predict success confusion matrix random forest nextunicorn randomforest summarizes confusion matrix prediction random forest model expect random forest model perform well error rate undersection ithas error rate almost percentage point compare partition percentage point compare conditional inference tree extreme gradient boost implementation similar model parameter affect model performance adjust xgb well booster parameter set equal gbtree model train classification problem regularization method logistic regression model misclassification penalty decision tree base method implement gamma loss reduction parameter control overfitting problem set foldcross validation cv optimal number iteration round maximum number iteration cross validation set optimal number iteration determine minimum test error reach via cross validation round sub sample fold retain test set validation remain sub sample use training test error round improve decrease consecutive round process terminate optimal number iteration round identify model return low test error th iteration minimum test error indicate cv accuracy xgb perform predictive accuracy rate actual failure actual success predict failure predict success confusion matrix extreme gradient boost nextunicorn xgboost comparison model plenty option come evaluate model performance conclude metric compare six model implement description metric accuracy tp tn tp tn fp fn error rate accuracy sensitivity tpr tp tp fn specificity tn tn fp fpr fp fp tn receiver operating curve roc illustrates performance classification model plot true positive rate tpr false positive rate fpr classification thresh old area roc curve auc take integral roc curve provide aggregate measure performance different threshold level ling provide overview various comparison metric since measure benefit drawback combine evaluation approach adopt accuracy error rate model mention respective section metric rank ensemble method xgb best perform method mean xgb able label class success failure well comparison method random forest close second xgb accuracy rate indicates general classification performance ensemble method dominate model traditional approach accuracy metric sensitivity specificity need discuss relation type type ii error sen sitivity represent percentage accuracy model correctly predict positive class model name accuracy sensitivity specificity type error type ii error full logistic regression reduce logistic regression rpart tree conditional inference tree random forest extreme gradient boost comparison performance metric across model nextunicorn result success true positive tp specificity hand represent percentage accuracy model correctly predict negative class failure true negative tn one argue cost misclassifying fail company successful false positive type ii error costlier misclassifying successful company fail false nega tive type error wang gepp state type ii error within startup success prediction framework critical type ii error bear financial loss due invest startup doom fail whereas type error creates lose opportunity cost invest deal successful new business also refer miss potential investment gain hence misclassification cost equal real world set background one argue type ii error specificity use proxy real life cost classification error model low type ii error high specificity argue best perform model xgb label fail company correctly type ii error rate similar elaboration accuracy error rate second ensemble model random forest reach specificity low type ii error rate lastly auc scale invariant metric mean auc measure rank pre diction rather absolute value auc require threshold measure performance model although threshold invariance auc metric advan tageous case disparity cost misclassification different class raise need threshold suppress problem provide comparison auc metric among model auc criterion xgb dominates rest model randomforest second best perform model auc well different performance metric point different best perform model however plausible conclude ensemble method random forest xgb dominate model performance metric consider model name auc full logistic regression reduce logistic regression rpart tree conditional inference tree random forest extreme gradient boost comparison auc among model nextunicorn auc discussion variable importance statistical model sometimes difficult interpret refer general black box model case variable importance construct model useful articulate model achieve well understand rank variable accord importance model construction implement top best performingmodels importance variable recursive partition tree calculate add improvement measure variable contributes primary surrogate splitter splitmeasure refertosection summarizes normalize relative importance variable main contribution split do last funding date follow company age social variable importance level last funding date company age first funding lag funding round social twitter social continent america social facebook continent asia sector health sector consumer discretionary sector consumer staple ranked variable importance normalize recursive partition tree nextunicorn tree generate random forest bag oob sample construct ing random forest hence tree prediction accuracy measure oob value oob variable shuffle keep else mean decrease accuracy represent much accuracy model decrease shuffle oob variable respective variable omit hand mean decrease gini index equation represent impurity variable chosen split node calculate node impurity weight probability reach node high gini index important feature accord gini index last funding date company age first funding lag top perform variable variable importance outlook random forest provide insight compare recursive partition tree importance measure broken outcome class success failure example total funding usd much important predict failure class predict success hand last funding date important predict success predict failure mean decrease mean decrease accuracy gini last funding date first funding lag company age funding round last funding lag total funding usd social continent america social twitter sector commercial service social none sector consumer discretionary sector sector health sector consumer staple continent europe continent asia sector finance social facebook ranked variable importance random forest nextunicorn randomforest variable importance xgb measure gain cover frequency met rics gain represent relative contribution respective variable calculate contribution feature tree model high value indicates high importance cover represent relative number observation related variable frequency percentage represent relative number time particular indepen dent variable occurs tree model literature suggests relevant variable importance metric gain chen guestrin gain cover frequency last funding date first funding lag company age total funding usd funding round last funding lag social continent america social none sector health sector consumer staple social facebook sector sector commercial service sector consumer discretionary continent europe social twitter sector finance continent asia ranked variable importance extreme gradient boost nextunicorn xgboost importance gain calculate decrease entropy equation splitting node use respective variable target dependent variable gain entropy entropy use gain measure top perform variable last funding date first funding lag company age top perform model consensus important variable last funding date first funding lag company age general rank vari able importance reveal top perform model prioritize continuous variable categorical one variable importance di er signi cantly di erent model implement universal function approximators choose variable conclusion paper thoroughly address predict success startup rms amount literature work startup success reveal need research area exist lit erature focus establish rm success rate prediction however di erences corporate startup success prediction make model exist literature di cult use predict success startup rms cost high make wrong decision startup successful due energy ecosystem highly bene quanti ed method come make decision high risk environment hence paper empirically illustrates implementation various machine learn algorithm predict startup success data use estimation base information crowd source database crunchbase com without allocate budget time interview collect survey answer startup one advantage use data set paper sample size large compare research paper literature since majority rms provide update crunchbase pro le mostly successful rms use data entail aselection success bias fail company imbalance would mean example accuracy rate even though fail company label successful problem tackle oversampling minority class data fail company implement adasyn oversampling approach enables retainment information oppose undersampling improves predictive ability machine learn method total six separate model implement full logistic regression ii reduce logistic regression iii recursive partition tree iv conditional inference tree random forest vi extreme gradient boost common method literature logistic regression implement comparability reason construct benchmark succeed model logistic regression full reduce model perform well random guess mcfadden pseudo error rate around logistic regression perform within predictive accuracy interval set precede logistic regression model literature however compare four implement model neither logistic regression mod el exhibit satisfactory predictive ability order fully use information contain feature two di erent type decision tree built traditional decision tree recursive partition tree con tting recursive partition tree reach auc overperformed conditional inference tree auc order tackle tting problem two decision tree model ex tend random forest random forest show average performance range di erent metric provide low type ii error rate indicate prediction random forest model result low cost misclassi cation fail company although random forest ensemble method research extend ex treme gradient boost ciency proven performance recent competition research compliant application literature xgb perform best among model implement majority metric accuracy speci city auc xgb slightly dominates random forest ap proach top perform model xgb random forest recursive partition tree ranked three variable main feature last funding date rst funding lag company age cost high study provide repeatable quanti ed model process predict startup rm success use machine learn method large scale publicly available data research first foremost problem address availability collection data star tup reproducible also lead response bias paper show reproducible model train shelf data none minimum information personality entrepreneur characteristic management team still reach near accu racy level however data use study lack information personality trait entrepreneur management team include widely acknowledge variable improve model performance future research common frame work conceptualize collection information rich data would essential build solid prediction model also data use paper provide snapshot single point time time aspect failure neglect need panel data well understand trigger failure indisputable percentage growth metric change number employee growth rate funding amount receive many similar metric generate longitudinal manner would help improve prediction result startup lead ipo within rst year establishment uncommon business necessarily proxy success similarly every acquisition characteristic acquisition represent success entrepreneur bene transaction also point failure startup reach nancial stability failure hand also speci cally de ned one argue startup consider fail exist long enough cially le bankruptcy authority improvement label determination potential reduce class imbalance asymmetry term cost correctly predict startup success failure correctly mention section model selection startup success prediction also provide researcharea theminusculedi random cost function matrix approach hand would require intensive research nancial opportunity cost misclassi cation trivial another improvement point set focus research speci industry sub category industry benchmark success rms operating disruptive eld digital tech rms specialize cryptocurrencies indeed di erent venture operate utility heavy machinery although implement dustry speci cation would impact variable de ned data set might result small sample size tailor quanti ed model need di erent sector help determine driver success predict business success high accuracy startup success prediction indeed interest party involve startup ecosystem light mention improvement might possible quantitativemodels spot next unicorn amankwah amoah integrative process model organisational failure journal business research baum singh organizational niche dynamic organi zational mortality american journal sociology boritz kennedy ectiveness neural network type prediction business failure expert system application breiman property splitting criterion machine learn random forest machine learn butler fitzgerald unpack system development process empirical application csf concept research context journal strategic information system cao delgado gonza lez manteiga nonparametric curve estimation overview investigaciones economicas ceausu marquardt irmer ande gotesman factorsin uencing performance within startup assistance organization proceeding international conference business excellence de gruyter open vol chang venture capital nancing strategic alliance initial public erings internet startup journal business venture chawla bowyer hall kegelmeyer smote synthetic minority sample technique journal arti cial intelligence research chen guestrin xgboost scalable tree boost system pro ceedings nd acm sigkdd international conference knowledge discovery data mining acm cutler edward jr beard cutler hess gibson lawler random forest classi cation ecology ecology dempwolf auer andm dippolito de ning small business administration dimitras zanakis zopounidis emphasis prediction method industrial application european journal operational research dornbusch case trade liberalization develop country journal economic perspective doumpos zopounidis business failure prediction comparison classi cation method operational research du jardin two stage classi cation technique bankruptcy prediction european journal operational research einhorn expert judgment necessary condition example journal apply psychology evans two mind dual process account reason trend cognitive science fischhoff kahneman slovic tversky con demned study past heuristic bias hindsight foundation cognitive psychology core reading friedman stochastic gradient boost computational statistic data analysis gatev thomas lou lim hallett ect dimin ished con icting sensory information balance patient cerebellar de cits movement disorder cial journal movement disorder society gepp kumar bhattacharya business failure prediction use decision tree journal forecasting haavelmo probability approach econometrics econometrica journal econometric society iii hager gonczi competence medical teacher ha rdle simar apply multivariate statistical analysis vol springer bai garcia li adasyn ieee international joint conference neural network ieee world congress computational intelligence ieee hothorn hornik zeileis unbiased recursive partition conditional inference framework journal computational graphical statistic hu shao palta pseudo logistic regression model statistica sinica hu li novel boundary oversampling algorithm base neighbor hood rough set model nrsboundary smote mathematical problem engineering hung whittington playingbytherules success failure taiwanese industry journal business research james witten hastie tibshirani introduction sta tistical learn vol springer jones olson time vary correlation uncertainty output ation evidence dcc garch model economics letter karabag factor impact rm failure technological development study three emerge economy rms journal business research kauffman wang success failure dotcoms multi method survival analysis proceeding th informs conference information system technology cist miami fl usa citeseer krawczyk learn imbalanced data open challenge future direc tions progress arti cial intelligence kuhn johnson apply predictive model vol springer kumar ravi bankruptcy prediction bank rms via sta tistical intelligent technique review european journal operational research laitinen rm journal business venture lee capability failure industrial policy move beyond middle income trap trade base technology base specialization industrial policy revo lution springer lemmens croux bagging boost classi cation tree predict churn journal marketing research ling huang zhang auc statistically consistent discriminate measure accuracy ijcai vol liu wu hybridize kernel base fuzzy mean hierarchical selec journal forecasting luce possible psychophysical law psychological review luger koo de ning track business start ups small busi ness economics lussier non nancial business success versus failure prediction mo journal small business management lussier pfeifer crossnational prediction model business success journal small business management mellahi wilkinson organizational failure critique recent research propose integrative framework international journal management review ooghe de prijcker failure process cause company bankruptcy typology management decision ooghe waeyaert cause company failure failure path rise fall fardis european case study ozdemir moran zhong andm bliemel reachingandacquir ing valuable resource entrepreneur use brokerage cohesion embeddedness entrepreneurship theory practice porter competitive advantage nation new introduction ny free press read van leeuwen predict hunger ect appetite delay choice organizational behavior human decision process regmi ahmed quinn data driven analysis startup accel erators universal journal industrial business management shane importance angel invest nancing growth en trepreneurial venture quarterly journal finance simon behavioral model rational choice quarterly journal economics strasser weber strobl boulesteix kneib augustin zeileis con ditional variable importance random forest bmc bioinformatics strobl boulesteix zeileis hothorn bias random forest variable importance measure illustration source solution bmc bioin formatics sutton classi cation regression tree bagging boost hand book statistic tavoletti business incubator ective infrastructure waste public money look theoretical framework guideline criterion journal knowledge economy tushman anderson technological discontinuity organiza tional environment administrative science quarterly venkatraman payne bettman luce huettel separate neural mechanism underlie choice strategic preference risky decision make neuron wang yang improve boost base feature selection corporate bankruptcy prediction expert system application wu expert system application declaration authorship hereby con rm author master thesis independently without use others indicate source passage literally general matter take publication source marked july cemre nal
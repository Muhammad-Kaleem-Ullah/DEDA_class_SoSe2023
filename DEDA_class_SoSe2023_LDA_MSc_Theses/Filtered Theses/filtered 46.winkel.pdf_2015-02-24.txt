multiple nonlinear prediction return use anfis master thesis submit prof dr ostap okhrin universit zu ladislaus von bortkiewicz chair statistic david winkel february nonlinearly follow welch goyal benchmark performance return prediction return historical average anfis apply data capture year year period anfis fails outperform historical average use year data anfis use year data however able outperform historical average keywords fuzzy logic fuzzy inference system neural network anfis machine learn return prediction zusammenfassung diese arbeit pr asentiert mit dem anfis ein konzept au dem machine learn mit dessen hilfe die rendite de nichtlinear vorhergesagt wird anlehnung welch goyal wird al vergleichsgro zur renditevorhersage der historische durchschnitt der rendite verwendet da anfis wird auf daten angewendet welche ber ahrige zeitra ume und ja hrige zeitr aume erhoben wurden bei der verwendung der daten der ahrigen zeitra ume gelingt mit dem anfis nicht den historischen durchschnitt der rendite al vergleichsgro zu schlagen angewendet auf die daten der ahrigen zeitra ume ist jedoch oglich die vergleichsgr zu schlagen schlu sselw orter fuzzylogik fuzzyinferenzsystem neuralesnetzwerk anfis machinelearning ren ditevorhersage acknowledgement first would like thank prof dr ostap okhrin give opportunity write thesis thanks go prof dr wolfgang ardle guidance whole course master program special thanks go mother support experience write thesis mother also thank sister father provide assistance anyone hope provide content introduction motivation methodology logic fuzzy logic fuzzy set compositional rule inference fuzzy rule fuzzy reason fuzzy inference system artificial neural network adaptive neuro fuzzy inference system learn cost function backpropagation method hybrid learn rule application data evaluation criterion autoregressive model anfis model general problem anfis configuration anfis forecasting anfis result summary list comparison mf mf different operation fuzzy set comparison mf two fuzzy set cylindrical extension fuzzy set comparison two relation compositional rule inference construction fuzzy rule fuzzy reason single rule single antecedent fuzzy reason single rule two antecedent fuzzy reason two rule two antecedent defuzzification method obtain crisp value two rule mamdani fuzzy inference system two rule sugeno fuzzy inference system conceptual structure mcp neuron conceptual structure perceptron comparison anns feedforward neural network topological order representation notation ann layer representation sugeno inference system ann representation sugeno inference system anfis effect change parameter gradient visualisation feedforward neural network partial derivative visualisation ar result model overfitting curse dimensionality visualisation forecasting process anfis overtraining mse red mse blue oos surface best perform anfis additional information train anfis actual return blue year anfis forecast red historical average green surface best perform anfis additional information train anfis vi actual return blue year best anfis forecast red historical average green surface second best perform anfis additional information train anfis actual return blue year second best anfis forecast red historical average green vii list parametric mf input output two input mcp neuron represent logical function two pass hybrid learn rule estimation result year period estimation result year period result forecasting ar five best perform model input pair year period five best perform model input pair year period viii nomenclature acf autocorrelation function anfis adaptive neuro fuzzy inference system ann artifical neural network ar autoregressive cpi consumer price index fis fuzzy inference system hlr hybrid learn rule lse least square estimation mcp mcculloch pitt mf membership function mlp multilayer perceptron mse mean square error price earn ssr sum square residual ix introduction motivation move stock market question old stock market long time academic view question coin random walk hypothesis originally examine kendall hill developed fama theory state stock price move randomly thus possible predict movement way another influential theory also consistent random walk hypothesis efficient market theory fama base efficient market theory many author deny return predictability since would imply market inefficiency contrast many successful practitioner like value orient investor graham dodd state certain variable like fundamental ratio predict stock return long time horizon late however academic paradigm unpredictable return chal lenged several paper show statistical evidence predictability return fama french well campbell shiller found dividend yield positively correlate subsequent return study conclude pre dictability especially long time horizon also correlation subsequent stock return variable found short term long term treasury yield campbell research continued study find significant explanatory variable book market ratio pontiff schall kothari shanken also price earn ratio lamont due large number study state return predictability prevail tone academic literature end best summarize cochrane call predictability new fact finance recent study however begin cast doubt study find return predictability goyal welch example examine dividend yield explanatory variable found poor sample performance model argue predictability found pre data study welch goyal examine empirical evidence various study use variable ratio book market ratio long term treasury yield predict stock return found predictability certain time period poor sample performance author like butler grullon weston campbell thompson also confirm often poor sample performance linear regression model linear regression framework mostly use also point criticism chen hong campbell shiller horizon return might nonlinear thesis examines model address point criticism found recent study examine model use predict return thesis challenge welch goyal state superiority historical average prediction regression model objective find regression model able outperform historical average predictor return additionally good sample performance found model shall limited certain time period valid time period thesis examines different model call adaptive neuro fuzzy inference system anfis anfis propose jang concept machine learn base artificial neural network ann capable model nonlinear relationship utilizes principle fuzzy inference system fis strength anfis suitability hybrid learn rule hlr computational advantage method parameter identification end thesis question raise whether anfis anns general suit financial application present thesis structure four chapter current chapter describes motivation give overview thesis chapter introduces concept necessary understand anfis concept fuzzy logic fuzzy inference system ann learn method ann chapter present result prediction return use anfis chapter summarizes finding thesis discus result methodology logic section short introduction traditional logic build foundation fuzzy logic logic science reason reason context logic describes act infer make inference call argument examine argument collection statement statement declarative sentence traditional two value logic declarative sentence take two truth value true false example declarative sentence god exists sentence capable either true false argument include statement call premise use give reason accept another statement call conclusion premise see input inference process conclusion process output example argument would premise men mortal input premise socrates man conclusion socrates mortal output different structure argument structure call inference rule follow two important inference rule introduce one commonly use inference rule logic modus ponens consists two premise one form another form return conclusion example argument fit form modus ponens premise rain street wet premise rain conclusion street wet another commonly use inference rule modus tollens also consists two premise one form another form return conclusion example argument fitting form modus tollens premise rain street wet premise street wet conclusion rain middle th century traditional logic evolve work boole formalistic discipline boole brought two value logic algebraic structure boolean algebra algebra value variable truth value true false usually denote main operator boolean algebra conjunction denote disjunction denote negation denote boolean algebra become fundamental development digital electronics backbone electronics program language nowadays nevertheless overwhelm application modern technology limitation use boolean algebra inherent traditional logic problem traditional logic show future contingent future contingent statement future event aristotle formulate problem follow two statement future event tomorrow sea battle tomorrow sea battle since two possibility exist one statement already true today would mean nothing do alter happen event generalization problem lead idea free idea human power determine course event future state law logic apply future event deal aristotle paradox sea battle early th century polish formal logician ukasiewicz propose logic three truth value true false yet undetermined later ukasiewicz tarski generalize idea even formulate logic truth value foundation infinite value logic fuzzy logic probabilistic logic arose fuzzy logic fuzzy logic infinite value extension traditional logic base mathematical theory fuzzy set generalization classical set theory introduce paper zadeh zadeh observe binary logic com puters able deal subjective human concept hot cold fuzzy set enable computer distinguish certain degree hotness idea come close way human perception work fuzzy logic statement get degree truth state true false fuzzy set also use inference process build foundation fuzzy logic fuzzy set set base two value logic crisp boundary value either belongs set example set include value great boundary point otherwise value belong crisp set set crisp boundary call crisp set thesis fuzzy set set without crisp boundary define set order pair function call memb ership fu nction mf define assigns continuous value degree membership element value mean member fuzzy set value mean full member value characterize fuzzy member mean belongs partially crisp set special case fuzzy set equal indicator function restrict value either example illustrates difference crisp set fuzzy set example property height two person investigate first property investigate use crisp set two value logic mf crisp set mf fuzzy set comparison mf set define include person consider tall crisp boundary height cm great chosen peter height cm statement peter tall true member set clark height cm statement clark tall false member set assignment seem counterintuitive human perception investigation also make use fuzzy set statement peter tall true degree statement clark tall partially true degree come closer human perception peter tall clark still tall example illustrates advantage fuzzy logic two value logic able come closer way human think work additionally fuzzy logic make possible put natural language mathematical framework natural language human use every day life consists linguistic variable example linguistic variable age different possible realisation realisation call linguistic value age linguistic value young old old fuzzy set mathematical way express linguistic value use fuzzy set allows incorporate human knowledge store natural language mathematical model use linguistic value also disadvantage though individual definition linguistic value might differ person person one person considers old another person might consider young different people might different subjective perception linguistic variable age different definition linguistic value lead different specification fuzzy set describe linguistic value therefore fuzzy set mf highly subjective mf fuzzy set function mapping real inter val nevertheless function often use membership function present parametric function zadeh defines paper basic operator relation fuzzy set similar crisp set fuzzy set alternatively call subset symbol union two fuzzy set fuzzy set write mf related max intersection two fuzzy set fuz zy set writt en mf related min complement fuzzy set fuzzy set denote accord mf give function example trapezoid max min gaussian exp generalizedbell ab sigmoid exp ax ac parametric mf mf mf union mf intersection mf complement mf different operation fuzzy set mf union intersection two fuzzy set mf complement single fuzzy set illustrate beside definition basic operator relation introduce thesis also us different concept fuzzy set theory introduce follow singleton use represent crisp value fuzzy set singleton contains single point certain point applies show two fuzzy set comparison whereby show singleton fuzzy set also two dimensional result mf two input two dimensional fuzzy set define definition multidim ensional fuzzy set th two dimension analog application fuzzy logic necessary extend dimension fuzzy set do call cylindrical extension fuzzy set middle age year old age age mf fuzzy set middle age mf singleton year old comparison mf two fuzzy set cy extension fuzzy show wo dimensional fuzzy set show mf related cy meaning value influence cy mf fuzzy set mf cylindrical extension cylindrical extension fuzzy set carthesian product fuzzy set denote fuzzy set dimension mf define minimum cylindrical extension min min cy cx compositional rule inference essential principle behind fuzzy reason compositional rule inference describes process mapping one fuzzy set another fuzzy set accord certain relation compositional rule inference best explain generalize concept already know suppose give relation reflect relation real value input infer real value output use relation denote illustrates relation point concept extend case relation interval value mapping interval interval illustrates case interval mapped interval relation find interval first cylindrical extension denote construct cylindrical extension define contrast define second step intersection interval value curve found final step intersection project onto axis yield interval relation interval value relation comparison two relation fuzzy set fuzzy relation also call fuzzy rule fuzzy rule interpret two dimensional fuzzy set define mf fuzzy rule mf mf projection onto compositional rule inference application fuzzy rule input receive output visualize show mf fuzzy rule space inference process fuzzy set cylindrically extend fuzzy set two dimensional space show mf analog previous example intersection fuzzy rule cylindrical extension make intersection two dimensional fuzzy set write mf see function mf two intersect set common choice min operator lead min mf fuzzy ntersection show projection onto axis yield fuzzy set visualize mathem tically th do function trans form function two dimensional input space back function one dimensional input space common choice max operator lead max min due choice max min operator call max min composition represent whereby denotes composition operator fuzzy rule application fuzzy logic fuzzy rule play crucial role fuzzy rule use linguistic value widespread daily life performance great applause long pressure high volume small service good tip high fuzzy rule include fuzzy set general form antecedent consequent first part rule clu le antecedent second part include call consequent fuzzy rule abbreviate mention previous section fuzzy rule interpret fuzzy set case fuzzy rule include two fuzzy set und define define function call fuzzy implication function transforms mem bership grade membership grade larsen example suggests product operator fuzzy implication func tion mamdani assilian contrast suggest min operator fuzzy implication function thesis mamdani assilan definition use construction fuzzy rule mamdani assilan illustrate first step fuzzy set cylindrically extend see second step see fuzzy implication function apply mf result mf cylindrical extension min operator apply mf construction fuzzy rule fuzzy reason follow section describes inference process fuzzy logic also call fuzzy reason concept compositional rule inference fuzzy rule already introduce use inference rule two value logic different form already introduce modus ponens form suppose decide banana ripe use modus ponens premise colour yellow ripeness good colour yellow lead conclusion ripeness good premise premise conclusion human environment however often hard classify traditional two value logical sense happens banana colour yellow green yellow human reason able use modus ponens approximate manner would leadfromthepremises thecolour green yellow conclusion ripeness somewhat good two value logical sense conclusion allow since statement colour yellow false reason approximate manner however call fuzzy reason fuzzy reason generalizes inference rule follow part introduces fuzzy reason use generalize modus ponens simplest case generalize modus ponens include single fuzzy rule single antecedent form premise premise conclusion fuzzy set premise induce fuzzy set define equivalently mf use max min composit ion quation max min max min min max min show graphical representation fuzzy reason degree match fuzzy set antecedent fuzzy rule degree fulfil degree fulfillment rule also call fire strength result fuzzy reason fuzzy set whose mf represent blue shade mf equal mf clipped fire strength fuzzy reason single rule single antecedent case single rule two antecedent generalize modus ponens write premise premise conclusion fuzzy set fuzzy rule contains multiple antecedent fuzzy set represent carthesian product already introduce section lead mf define max min max min illustrates fuzzy reason single rule two antecedent degree match degree match fire strength fuzzy rule result fuzzy reason fuzzy set mf represent blue shade fuzzy reason single rule two antecedent extension case two rule two antecedent generalize modus ponens form premise premise premise conclusion fuzzy set multiple rule treat union fuzzy rule since max min composition distributive union operator result fuzzy reason mf calculate analog equation result mf write max illustrates fuzzy reaso ning two ules two antecedent mf result fuzzy set maximum mf fuzzy set extension generalize modus ponens additional antecedent fuzzy rule analog max fuzzy reason two rule two antecedent fuzzy inference system fuzzy inference system fis compute framework utilize already intro duced concept fuzzy set fuzzy rule fuzzy reason fis applicable system performs inference input produce output follow section introduces two commonly use fiss first one mam dani inference system second fis introduce sugeno inference system mamdani inference system originally present mamdani assilian solution control interaction boiler steam engine con struct inference system mamdani ask human operator formulate linguistic control rule reflect experience boiler engine system use control rule fuzzy logic apply utilize operator knowledge inference process mamdani inference system divide two step first step application fuzzy reason show example two fuzzy rule mamdani inference system two antecedent contrary example time input represent crisp value form singleton already introduce section result application fuzzy reason fuzzy set second step mamdani inference process fuzzy set defuzzificated small max centroid area large max mean max defuzzification method obtain crisp value defuzzification method map fuzzy set crisp value present exist defuzzification method common defuzzification method fuzzy set centroid define dz coa dz thus mamdani inference system take crisp value input return crisp value output sugeno inference system propose takagi sugeno idea construct model suit adapt give input output dataset modify model parameter broken optimization problem solve iteratively formerly developed fiss like mamdani inference system well suit iterative optimization due computationally demand task defuzzification iteration step sugeno inference system design depend defuzzification similar mamdani inference system structure consequent part fuzzy rule cause defuzzification change typical rule sugeno inference system form fuzzy set antecedent crisp function consequent sugeno takagi propose first order polynomial crisp function consequent part use function possible visualizes two antecedent two fuzzy rule sugeno inference sys tem calculate output system sum weight consequence func max two rule mamdani fuzzy inference system weight average two rule sugeno fuzzy inference system max tionsiscomputed sfiringstrength sum fire strength rule artificial neural network follow section introduces artificial neural network ann first part section describes history ann property second part enlighten connection fuzzy inference system lead anfis nervous system replicate process information intheirpaper neuroscientist mcculloch logician pitt try replicate human brain work produce highly complex pattern use many interconnect cell cell send signal binary mode either fire signal fire signal basic idea model neuron binary input variable process neuron sum input great equal certain threshold neuron give output sum input less threshold output neuron show conceptual structure mcculloch pitt mcp neuron conceptual structure mcp neuron mcculloch pitt show paper possibility encode logical func tion network appropriately connect mcp neuron mean every operation computable boolean algebra also computable network mcp neuron example show truth basic logical function encode use single two input mcp neuron downside network mcp neuron completely specify use therefore system input output behaviour completely determine fix specification contrast biological system flexible input output behaviour due learn ability input input output input output two input mcp neuron represent logical function overcome limitation fix input output behaviour psychologist rosenblatt propose another attempt model biological neuron call model perceptron perceptron also us threshold give binary output major difference mcp neuron input weight weight modify modify weight input perceptron change input output behaviour modification weight crucial point allows learn enables perceptron recognize pattern single perceptron capa ble learn train example classifier two different group show conceptual structure single perceptron conceptual structure perceptron input weight sum sum compare threshold value sum great threshold value perceptron give output sum small threshold value perceptron give output thus perceptron function parameter map dimensional input binary output rn achieve learn rosenberg randomly modify weight trial error principle although initially promising computational power perceptron ques tioned paper minsky papert show inability single perceptron represent simple nonlinear function xor function note multilayer perceptron mlp connect network perceptrons would able know method train mlp paper find cause significant decline interest funding neural network research decade result many researcher leave field werbos found solution problem training mlp backprop agation method nevertheless mid neural network research gain popularity paper backpropagation method rumelhart hinton williams development pair progress compute technology lead de velopment ann ann generalize idea mlp ann consists multiple layer call node node represent node function contrast perceptrons mlp node ann represent param eterized function input output behaviour entire ann determine connection node parameter node ann train modify parameter node node contain modifiable param eters call adaptive node node contain modifiable parameter call fix node graphical representation thesis use square node represent adaptive node circle node represent fix node layer layer layer layer layer layer layer layer input layer output layer input layer output layer feedforward neural network recurrent neural network comparison anns anns classify two different group depend direction connection ann show feedforward neural network con nections node exclusively direct high layer contrast show recurrent neural network feedback connection node exists form circular path feedforward neural network topological order representation feedforward neural network also represent topological order see fact represent feedforward neural network equivalent one topological order representation helpful later section learn ann explanation ann detailed notation introduce layer ann numbered layer call input layer layer call output layer function give amount node layer node ann represent function call node function th node function layer denote output th node layer denote exemplary show ann notation introduce layer layer layer layer input layer output layer notation ann layer representation adaptive neuro fuzzy inference system ann also use framework fis fis ann representation call adaptive neuro fuzzy inference system anfis represent fis ann learn method anns apply identify parameter system follow example illustrates fis represent ann example contains sugeno inference system include four fuzzy rule rule small slow rule small fast rule large slow rule large fast show surface sugeno inference system visualizes system vertical view additional graph left bottom illustrate mf fuzzy set purple colour function represent mf fuzzy set slow fast green colour function represent mf fuzzy set small large mf divide show input space roughly four area mainly described one first order polynomial define consequent fuzzy rule illustrates four rule fuzzy inference system example anfis layer represent mf four fuzzy set small large slow fast layer fire strength four rule calculate input correspond mf output layer call normalize fire strength ratio rule fire strength sum rule fire strength layer represent four polynomial correspond four rule weight normalize fire strength layer layer weight polynomial sum give final output anfis surface sugeno inference system mf surface sugeno infer ence system sugeno inference system thesis us anfis base sugeno inference system due compu tational advantage avoid defuzzification general structure single output anfis base sugeno inference system described follow layer contains node represent mf node contain parameter accord chosen mf layer contains node function calculate fire strength th rule layer contains node function calculate normalize fire strength th rule layer contains node function represent consequent function th rule layer contains node function sum weight consequent func tions give anfis output single output anfis base sugeno inference system write anfis amount rule denotes input variable anfis layer layer layer layer layer ann representation sugeno inference system anfis learn follow section introduces learn ann ann represent class function suppose solve certain task learn describes use observation find solves task optimally optimal sense minimize cost fun ction first part section describes chosen cost function second part introduces optimization algorithm third part present modification optimization algorithm apply special case ann anfis cost function ann allows model linear well nonlinear relationship input output space order model certain relationship function optimal sense parameter set found well ann reflect sought relationship measure cost function cost function evaluates residual define difference observe output output predict model various different cost function chosen follow jang thesis cost function th observation define sum square error represent case ann multiple output term actual observe output th observation th variable prediction ann th observation th output variable denote equivalent th output layer denote order include cost function observation overall cost function define backpropagation method ultimately ann output determine parameter set show change parameter effect overall cost function therefore optimization optimization respect parameter ann changein changeintheoutput changeintheoutput changeintheoutputof functionparameter ofnodecontaining ofthefinallayerl effect change parameter different method training ann commonly use method backpropagation backpropagation method utilizes gradient descent order minimize cost function understand backpropagation method first intuition behind gradient descent explain gradient generalization one dimensional concept function derivative dimensional vector gradient surface gradient gradient visualisation differentiable scalar value function vector contain partial deriva tives function important property gradient point direction function great rate increase magnitude gradient show examine function exemplary illustrates gradient direct arrow horizontal view arrow length stand magnitude gradient minimization algorithm gradient descent utilizes property gradient us negative gradient point opposite direction great rate increase fact direction great rate decrease function idea create sequence wanders iteration step step direction great rate decrease finally minimum reach minimum reach sequence converge formally sequence define initial value may first guess coordinate minimum value call learn rate determines step size negative gradient iteration element sequence satisfy small enough follow part introduces backpropagation method utilizes present gradient descent first step backpropagation method node ann error signal calculate error signal define derivative cost function respect output th node layer werbos introduce backpropagation method point limitation use ordinary partial derivative network dependent variable quantity result value earlier quantity change order system derivative simple case feedforward network one node per layer translates directeffect indirecteffect example illustrates chain rule order derivative show topological representation simple feedforward neural network direct effect network form partial derivative node function define follow zout zout fout zout feedforward neural network partial derivative goal example measure effect change output network use equation order derivative accord nodeoutputs contrast partial derivative function respect variable derive hold input variable constant lead use partial derivative would assume indirect effect feedforward neural network general case therefore order derivative use examine effect change one variable another order solve equation order derivative network solve backwards begin last element network do equation calculate overall cost function ann first error signal node calculate two different case distinguish first case describes situation error signal node last layer ann last layer output effect due structure ann directly calculate order derivative cost function th output ann use equation simplifies second case describes situation output inner node inner node node layer inner node error signal node effect linear combination error signal succeed layer define errorsignallayerl errorsignal layerl thus error signal layer sum error signal layer weight order calculate error signal node ann error signal equation solve sequentially backwards output layer input layer method call backpropagation due backwards calculation procedure use backpropagation node error signal know already present overall cost function ultimately determine ann parameter therefore first effect change parameter th error signal determine th parameter ann parameter contain node function give output effect overall cost function change define use accord equation gradient vector contain effect change parameter overall cost function accord equation use hybrid learn rule weakness backpropagation method computational intensity cause gradient descent computational intensity reduce use call hybridlearningrule hlr asproposedbyjang descent least square estimation lse however hybrid learn rule applicable ann linear parameter linearity parameter crucial lse set linear parameter subset whole parameter set ann applies contains parameter whole parameter set nonlinear estimate parameter lse equation system build vector contains element matrix row represent observe input value th observation training dataset vector contains observe output data training dataset since usually great system linear equation overdetermined meaning equation unknown solve overdetermined system regression analysis use purpose linear regression model define state th observation relationship input variable output error define deviation observe output conditional mean use observation training dataset linear regression model lead system equation write matrix form equivalent equation system additional error vector equation system solve use method least square estimation minimizes sum square residual ssr ssr respect lead ssr solve calculate inverse large matrix alternative approach compute least square estimate recursive method widely adopt formula literature example astro wittenmark ljung define th row vector th element denote initial condition identity matrix dimension large positive number least square estimate case multiple output anns equation still applies except th row matrix introduction lse hlr described follow hlr operates iteratively update parameter iteration step iteration step divide two part first part call forward pas parameter assume constant parameter estimate accord lse second part call backward pas parameter assume constant parameter identify use gradient descent way parameter set update iteration show two pass iteration step hlr reduction computational intensity hlr comparison use backpropagation method cause reduction dimension although hlr also include gradient descent computationally less demand since parameter space search gradient descent small dimension instead backpropagation method forward pas backward pas parameter fix gradient descent parameter least square estimation fix two pass hybrid learn rule hlr well suit identification parameter anfis base sugeno inference system type anfis contains two group parameter already exemplary show first group include parameter describe fuzzy set mf antecedent fuzzy rule contain second group contains function parameter consequent function fuzzy rule consequent function first order sugeno inference system linear parameter therefore parameter contain application data investigate predictability return dataset provide prof robert shiller economic website yale use dataset contains economic data january december set consists data include stock price dividend earnings additionally set contains economic data consumer price index cpi year treasury yield year treasury yield first step preprocessing data inflation adjust use cpi second step various ratio calculate dataset calculate ratio picked refer several study already mention section lead preprocessed dataset contain seven variable explain follow variable predict log return define log remain six variable use predict log return dividend yield use explanatory variable define divyield another ratio often use ratio interpret estimation many period investment need amortize earnings define weakness ratio volatility cause volatility earnings alternative ratio smooth ratio define smooth earnings less volatile suit reflect average long term earn prospective investment thesis earnings smooth year period another explanatory variable lag log return one period simply define lag year treasury yield take directly shiller dataset year treasury yield take directly shiller dataset follow different model present analyze previous explain dataset go detail method evaluate forecasting performance model present evaluation criterion financial literature popular measure prediction quality sample approach like classical adjust test method prediction however focus interest well model work sample nielsen sperlich introduce measure feature evaluate sample predictive power model define return period forecast model evaluate model evaluate estimate use available observation period historical average available observation period recent literature historical average often use benchmark model predict return instance welch goyal state study know stock prediction model fail outperform historical average sample positive value indicates model able well predict sample benchmark historical average negative value show inability model predict well sample historical average strength directly reflect underperformance benchmark fromcampbell thompson autoregressive model predict return first model evaluate simple autoregressive ar model first order approach also follow fama french focus mean revert property return believe cause negative autocorrelation ar model define model assumes linear relationship return period lag return performance ar evaluate two different time horizon ar use year lag return able outperform historical average asseenintable parameter ar estimate close zero value since use level clearly exceed reject return autocorrelation function acf also show significant autocorrelation lag return show result forecast close historical average forecast ar almost entirely determine estimate constant due parameter estimate close zero estimate constant almost identical historical average second ar model use year lag return also able clearly perform historical average see estimate year ar model also statistically significant also show significant autocor relation lag return forecast return close historical average cause small parameter estimate parameter estimate standard error statistic value estimation result year period parameter estimate standard error statistic value estimation result year period model year period ar ar result forecasting ar acf year lag actual return blue year ar fore acf year lag return cast red historical average green acf year lag actual return blue year ar fore acf year lag return cast red historical average green visualisation ar result anfis model general problem simple ar model able outperform historical average therefore next model study anfis complex high parametric go detail anfis configuration general problem high parametric model address high amount parameter regression model less fix structure impose allows model various kind nonlinear relationship increas ing amount parameter allows regression model increase sensitivity local observation sensitivity make high parametric model vulnerable mse mse oos polynomial order nd mse red mse blue oos order green th order purple model overfitting problem overfitting understand problem important recall objective regression model estimate relationship different variable overfitting occurs model describes fluctuation random error rather relationship illustrates problem black dash line show unknown relationship shall estimate regression model red cross show observation sample obser vations training dataset relationship estimate estimation th order polynomial regression model use compare th order polynomial regression model define xn green line show estimation nd order polynomial purple line show estimation th order polynomial see th order polynomial becomes locally sensitive observation fit observation well comparison nd order polynomial reacts rather inflexible observation evaluate performance model mean square error mse use mse predictor define mse mse estimate polynomial show red line show mse different estimate th order polynomial red cross obser vations see mse decrease increase order polynomial observation plot one dimension observation plot three dimension observation plot two dimension curse dimensionality purple line performs model black dash line true relationship contrast green line nd order polynomial come close black dash line true relationship th order polynomial overfitted model since de scribe also fluctuation random error observation rather relationship thus small mse necessarily imply well statistical model order avoid overfitting validation technique use do test model ability predict data purpose sample technique use call sample since technique use data sample use model estimation assume sample validation dataset training data generate underlie relationship model estimate underlie relationship well able predict observation validation dataset well show observation validation dataset blue dot see th order estimate performs rather poorly predict blue dot contrast nd order polynomial performs well predict blue dot also see sample mse denote mse estimate polynomial model oos validation dataset show blue line nd order polynomial low mse rd order polynomial upwards model begin overfit oos perform bad predict since high parametric model sensitive local observation important locally sufficient amount observation avoid overfitting configure anfis another problem closely connect overfitting take account curse dimensionality describes phenomenon increase dimensionality data becomes sparse due fact distance observation increase illustrates basic intuition behind curse dimensionality three dimensional example example observation three different uni formly distribute variable know show three different setup first setup show observation examine dimension see observation close second setup show observation additionally examine dimension due increase dimension distance ob servations increase third setup show observation three dimension distance observation increase since model need sufficient amount locally close observation estimate without overfitting anfis configuration anfis high parametric model order avoid overfitting amount parameter control thesis anfis base first order sugeno inference system use amount parameter depends several factor amount input variable amount mf per input variable amount parameter chosen mf total amount parameter calculate vu vu vu amount rule anfis first summand contains set parameter define mf second summand contains set parameter define first discuss section since amount rule grows exponentially base power control huge impact total amount parameter anfis model due impact total amount parameter address curse dimensionality anfis model use two input variable additionally amount mf per input variable also set two three parametric generalize bell shape mf use chosen mf therefore total amount pa rameters anfis model chosen configuration anfis forecasting forecasting process explain exemplary next section example input variable use forecast return data plot show observation form colour dot although visualize model initial training dataset white initial observation train maining observation purple anfis initial observation white available observation train anfis train anfis visualisation forecasting process observationsfrom dataset anfis estimation input purple dot represent observation shall use forecast return sample show surface estimate model use forecast return estimation use observation initial training dataset visualizes use observation estimate model vertical perspective follow period model estimate include obser vations period thus size training dataset increase one additional period prediction period remains sample though see local area little none observation mention section cause problem high parametric model like anfis data tends give unreasonably high low estimation address model weakness estimation anfis capped whenever model give high low forecast cap value consider local area enough information meaningful anfis estimation forecast replace sample historical average various cap value test cap value respectively give best sample performance regard mse follow equation lead modify anfis use thesis anfis anfis anfis cap else anfis represent anfis model use parameter identification ob servations period return historical average use observation period show last estimate model predict return utilize observation estimation mse mse oos training period anfis overtraining mse red mse blue oos come training anfis crucial consider amount iteration learn method call training period effect training period anfis mse see similar consideration phenomenon overfitting described section take account show mse decrease additional training period reflect fact anfis fitting observation increase mse however decrease th training period increase afterwards oos reflect fact anfis begin rather fit observation underlie relationship predict phenomenon context training period call overtraining therefore anfis train training period thesis anfis result explain section anfis use limited two input variable data available contains six possible input variable though fully utilize available data combination two pair input variable six possible input variable total combination use build different anfis model year period variable variable replace hist average lag lag five best perform model input pair year period result estimate model year period show display five two input combination high additionally show amount forecast replace historical average amount replacement important evaluate definition equation show model replace forecast historical average would score would counteract goal find alternative historical average therefore reasonable amount forecast replace historical average input combination performs best forecasting return negative indicates model able outperform historical average predictor though show surface estimate model use observation fig ure explains estimate model detail illustrate different property vertical view show white dot observation initial training dataset purple dot observation use input forecasting show first estimate anfis model year use ini tial training dataset represent white dot visualizes square residual forecast return actual return size square surface best perform anfis initial training dataset white initially train anfis initial maining observation purple training dataset white size square residual small white large black erage bad red well green place historical average yellow additional information train anfis residual see indicator area model performs well performs badly observation colour scale white black darker colour dot large size square residual show direct comparison forecast historical average term difference actual return case historical average closer actual return dot marked red case forecast closer actual return dot marked green yellow dot mark case forecast anfis replace historical average see equation conclusion draw information four sub observation initial training dataset locally cluster result large area estimation replace historical average contrast observation onwards far scatter forecast return observation often base information local observation even replace historical average residual show particular area anfis excels impression confirm observation area found perform well comparison historical average year actualreturn blue yearanfisforecast red historicalaverage green display year actual return comparison forecast historical average anfis historical average change little anfis forecast volatile comparison general year period anfis fails year period follow part present estimate model year period show result five two input combination high three model able forecast well historical average follow two best model present variable variable replace hist average lag lag five best perform model input pair year period show surface model high us lag input variable colour code dot identical one use year model amount observation half size previous example due year period show white dot observation initial training dataset purple dot observation use forecast roughly similar cluster area see model performs well term residual size observation less confirms impression since historical average almost always outperform performance forecast observation great however clear anymore display year actual return comparison forecast historical average anfis historical average almost stay unchanged anfis fails predict large negative return able however capture lag surface best perform anfis rlag rlag initial training dataset white initially train anfis initial maining observation purple training dataset white rlag rlag size square residual small white large black erage bad red well green place historical average yellow additional information train anfis year actual return blue year best anfis forecast red historical average green next part describes anfis year period second high us input variable show surface estimate lag model use observation show different property interpret result estimation vertical view lag surface second best perform anfis illustrates observation training dataset half observation locate area value less half observation however value great illustrates situation estimate model almost cover area value less therefore surprising see forecast observation value great replace historical average difficult evaluate model performance compare historical average observation value great observation value less interpretation becomes easy although show performance forecast compare historical average observation still display rather small residual forecast lead conclusion model excels particularly area observation less forecast model historical average actual return see period characterize high year treasury yield clear see model replaces forecast historical average since enough information available reliable anfis forecast rlag rlag initial training dataset white initially train anfis initial maining observation purple training dataset white rlag rlag size square residual small white large black erage bad red well green place historical average yellow additional information train anfis year actual return blue year second best anfis forecast red historical average green summary thesis provide two anfis model clearly able outperform historical average prediction return therefore find welch goyal state superiority historical average predictor return ques tioned nevertheless limitation result thesis discuss total different anfis model examine large number model due lack knowledge possible nonlinear relationship explanatory vari ables return therefore various different combination explanatory variable examine evaluate combination explanatory power anfis model one half process data capture year period half process data capture year period result performance anfis model predict return mixed none model train year period data able beat benchmark sample historical average two model able clearly outperform sample historical average anfis model train data capture year period explanation result might found use explanatory variable well capture time horizon finding thesis consistent argument practitioner value orient investor graham dodd argue valuation ratio indicator prospect asset longer time horizon accord prospect short time horizon rather influence sentiment market include psychological factor well since valuation ratio capture sentiment market able predict price movement short time horizon two best perform year period model include lag return one two explanatory variable might surprising first sight since ar model able detect significant linear influence lag return return nonlinear environment however lag return seem play important role predict return best perform year model additionally include smooth ratio explanatory variable also consistent graham dodd state smooth ratio highly qualify indicator long term performance asset second best perform year model additionally include year trea sury yield finding thesis consistent campbell state influence long term treasury yield return nevertheless found relationship thesis show nonlinear relationship combination lag return assess anns particular anfis suitable model financial application first look anns general necessary anns high parametric model able model nonlinear relationship main problem anns lie difficulty identify parameter close form solution available task therefore iterative approach search parameter space optimal solution gradient descent necessary iterative approach two inherent weakness though first increase parameter space cause large space search result increase computational expense second method distinguish local global minimum therefore minimum found might local partial solution difficulty identify parameter ann reduce identify ann parameter lse therefore parameter space search gradient descent reduce second weakness however remains since parameter still identify iteratively result possibly find local minimum nevertheless hlr reduces computational time training significantly state jang hlr applicable anns linear parameter apply hlr however use software need instruct pa rameters linear easily determine anfis due characteristic anfis structure explain section general however anns characteristic structure therefore linear parameter would state individ ually software user would laborious theoretically possible task nevertheless implement software solution hlr exists far anfis one motivation choose anfis thesis general question arises whether high parametric model anfis suitable model year year return nonlinearly amount parameter anfis grows exponentially power amount use explanatory variable high parametric model might cause overfitting though depend amount observation dataset therefore anfis thesis restrict two explanatory variable due limitation yearly observation general need large datasets increase amount use parameter model model year year return amount observation available limited though restricts use high parametric model anfis well use anfis increase amount explanatory variable crucial analyze large datasets possible field application high frequency trading high frequency trading vast amount observation available price movement area often driven short term factor therefore explanatory variable long term orient variable use thesis consider short term orient variable short term volatility trading volume might fruitful area research use anfis bibliography ang andrew piazzesi monika wei min yield curve tell gdp growth journal econometrics pp astro karl wittenmark bjorn computer control system theory design courier corporation boole george investigation law thought butler alexander grullon gustavo weston james manager forecast aggregate market return journal finance pp campbell john stock return term structure journal finan cial economics pp campbell john shiller robert stock price earnings expect dividend journal finance pp campbell john shiller robert valuation ratio long run stock market outlook journal portfolio management pp campbell john thompson samuel predict excess stock return sample anything beat historical average review financial study pp chen qingqing hong yongmiao predictability equity return dif ferent time horizon nonparametric approach work paper cornell uni versity cochrane john new fact finance tech rep national bureau economic research fama eugene random walk stock market price financial ana lysts journal pp fama eugene efficient capital market review theory empirical work journal finance pp fama eugene french kenneth dividend yield expect stock return journal financial economics pp fama eugene french kenneth permanent temporary compo nents stock price journal political economy pp goyal amit welch ivo predict equity premium dividend ratio management science pp graham benjamin dodd david security analysis principle tech nique st edition new york london mcgraw hill book company inc jang sr anfis adaptive network base fuzzy inference system sys tems man cybernetics ieee transaction pp kendall maurice george hill bradford analysis economic time series part price journal royal statistical society series general pp kothari smitu shanken jay book market dividend yield ex pected market return time series analysis journal financial economics pp lamont owen earnings expect return journal finance pp larsen martin industrial application fuzzy logic control interna tional journal man machine study pp ljung lennart system identification springer ukasiewicz jan logice tr ojwarto sciowej ruch filozoficzny english translation borkowski ed three value logic amsterdam north holland pp ukasiewicz janandtarski alfred untersuchungenu berdenaussagenkalku comptes rendus de sances de la soci de science de lettres de varso vie pp english translation woodger ed logic semantics metamathematics paper alfred tarski hackett publishing company chap investigation sentential calculus pp mamdani ebrahimh assilian sedrak experiment linguistic synthe si fuzzy logic controller international journal man machine study pp mcculloch warren pitt walter logical calculus idea imma nent nervous activity bulletin mathematical biophysics pp minsky marvin papert seymour perceptron introduction compu tational geometry mit press cambridge expand edition nielsen sperlich prediction stock return new way look astin bulletin pontiff jeffrey schall lawrence book market ratio predictor market return journal financial economics pp rosenblatt frank theperceptron organization brain psychological review rumelhart david hinton geoffrey williams ronald learn internal representation error propagation exploration microstruc ture cognition takagi tomohiro sugeno michio fuzzy identification system application model control system man cybernetics ieee transaction pp welch ivoandgoyal amit equity premium prediction review financial study pp werbos paul beyond regression new tool prediction analysis behavioral science ph thesis harvard zadeh lotfi fuzzy set information control pp declaration authorship hereby certify thesis submit entirely original work ex cept otherwise indicate aware regulation concern plagiarism include regulation concern disciplinary action may result plagiarism use work author form properly acknowledge point use david winkel april